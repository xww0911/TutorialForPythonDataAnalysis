{"./":{"url":"./","title":"Introduction","keywords":"","body":"python数据分析攻略 说道python,大家恐怕首先想到的就是数据科学.python有着一系列完善配套的数据科学相关工具. 包括通用的数据结构工具numpy,结构化数据分析表格工具pandas,科学计算算法包scipy以及数据可视化工具matplotlib 数据科学总体上来讲就这么几个步骤: 数据获取 最典型也是最为人所知的就是爬虫技术,说白了爬虫就是http技术的衍生,因此不会在这边讲,同时提供几个常用的数据来源用于学习 数据存储 数据存数涉及数据库技术,这个题目太大了本文也无法全讲,只会涉及一些最基本的操作 数据清洗 一般来说数据并不是拿来就可以用的,会有很多的噪音缺值异常值等,这就需要数据清洗.通常pythoner使用pandas来处理 数据分析 数据分析一般就是将清洗好的数据按一定的算法计算得出一定的结论.这一步一般使用 pandas,numpy,scipy等工具提供的算法计算.也可以使用比如sklearn,Statsmodels等黑箱算法包. 本文只会讲到pandas,numpy,scipy,其他工具则会在相关的文章中结合例子讲解. 数据可视化 最常见的python可视化工具就是matplotlib.数据可视化的作用一来是辅助数据分析, 根据图形判断数据的特征用来挑选合适的分析方式.另一个就是用来让一般客户看懂自己的分析结果. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 20:45:08 "},"numpy/":{"url":"numpy/","title":"科学计算通用数组工具numpy","keywords":"","body":"科学计算通用数组工具numpy numpy是python世界中一切科学计算工具的基础.它提供的数组和基本操作是几乎所有科学计算工具的底层依赖. 由于它的实现是用C语言的,因此非常高效. 本文从以下几个方面介绍: numpy的数组工具 numpy用于多项式与线性代数计算 numpy用于统计学计算 numpy用于财务分析 numpy用于频谱分析 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 20:53:48 "},"numpy/narray_and_universal_function/narray_and_universal_function.html":{"url":"numpy/narray_and_universal_function/narray_and_universal_function.html","title":"humpy数组与universal-function","keywords":"","body":"高性能数组narray及其universaal function numpy最重要的特点就是其N维数组对象(narray) narray是同构数组,也就是说它只能存储相同类型的数据,由于它是由C写的数据类型因此具有非常强的性能 narray实现了Collection,Container和Iterable协议.因此通用的序列操作都可以使用. 下面从一个例子来简单的了解下数组: import numpy as np import matplotlib.pyplot as plt import random %matplotlib inline data=np.array([[random.random() for i in range(3)],[random.random() for j in range(3)]]) data array([[ 0.44099442, 0.49826309, 0.37565053], [ 0.40511946, 0.58691695, 0.37871745]]) data.ndim#维度 2 data.shape#形状2行3列 (2, 3) data.dtype#元素数据类型 dtype('float64') 构建数组 numpy的数组由序列构建而来. 由多维序列构建多维数组 np.array([[1,2,3],[4,5,6],[7,8,9]]) array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) 由一维序列构建多维数组 np.array([1,2,3,4,5,6,7,8,9]).reshape(3,3) array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) 快速构建数组 构建numpy数组除了可以从一个序列构建外,numpy还提供了很多方法快速构建一些特殊数组 全0数组np.zeros() np.zeros((2,2)) array([[ 0., 0.], [ 0., 0.]]) np.zeros_like(data) array([[ 0., 0., 0.], [ 0., 0., 0.]]) 全1数组np.ones() np.ones((2,2)) array([[ 1., 1.], [ 1., 1.]]) np.ones_like(data) array([[ 1., 1., 1.], [ 1., 1., 1.]]) 空数组(只分配内存空间不赋值,也就是说里面可能是无意义数据)np.empty() np.empty((2,2)) array([[ 0., 0.], [ 0., 0.]]) np.empty_like(data) array([[ 0., 0., 0.], [ 0., 0., 0.]]) 等差数列np.arange(dow,up,step) np.arange(1,11,2) array([1, 3, 5, 7, 9]) 均分范围(可以看做等差数列的一种).linspace() np.linspace(-np.pi, np.pi, 6,endpoint=True)#在pi到-pi间等分成6份 array([-3.14159265, -1.88495559, -0.62831853, 0.62831853, 1.88495559, 3.14159265]) 等比数列.logspace() logspace(start, stop, num=num, endpoint=endpoint,base = base) np.logspace(0.1, 1, 10) array([ 1.25892541, 1.58489319, 1.99526231, 2.51188643, 3.16227766, 3.98107171, 5.01187234, 6.30957344, 7.94328235, 10. ]) 可以通过设置base参数来固定底,这样就相当于做乘方了 np.logspace(0, 9,10,base = 2) array([ 1., 2., 4., 8., 16., 32., 64., 128., 256., 512.]) NxN单位矩阵数组np.eye(n) np.eye(3) array([[ 1., 0., 0.], [ 0., 1., 0.], [ 0., 0., 1.]]) np.identity(3) array([[ 1., 0., 0.], [ 0., 1., 0.], [ 0., 0., 1.]]) 对角矩阵数组 .diag() np.diag((1,2,3)) array([[1, 0, 0], [0, 2, 0], [0, 0, 3]]) 我们也可以用对角阵数组操作提取一个数组的对角线元素 org = np.arange(9).reshape(3,3) org array([[0, 1, 2], [3, 4, 5], [6, 7, 8]]) np.diag(org) array([0, 4, 8]) 使用函数生成矩阵.fromfunction() 有的时候我们希望可以自定义的生成一个矩阵 比如我们希望生成一个各项值等于10i+j的矩阵 a = np.fromfunction(lambda i,j:10*i+j,(3,4)) a array([[ 0., 1., 2., 3.], [ 10., 11., 12., 13.], [ 20., 21., 22., 23.]]) 数组的形状 事实上numpy的数组在物理存储上是一维的,而shape是作为属性规定其访问规则的东西.我们可以通过reshape方法调整数组的形状 改变数组结构形状.reshape() np.arange(1,10) array([1, 2, 3, 4, 5, 6, 7, 8, 9]) np.arange(1,10).reshape(3,3) array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) 数组的切片与元素存取 索引与切片 一维数组的索引为第一位是列 二维数组的索引为第一位是行,第二位是列,以此类推 np.array([1,2,3],dtype=np.uint16) array([1, 2, 3], dtype=uint16) np.array([1,2,3],dtype=np.uint16)[:2]#一维数组 array([1, 2], dtype=uint16) np.arange(1,10).reshape(3,3) array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) np.arange(1,10).reshape(3,3)[1:,1:] array([[5, 6], [8, 9]]) 花式索引 花式索引是指用利用整数数组做索引提取对应行 arr=np.empty((10,4)) for i in range(10): arr[i]=i arr array([[ 0., 0., 0., 0.], [ 1., 1., 1., 1.], [ 2., 2., 2., 2.], [ 3., 3., 3., 3.], [ 4., 4., 4., 4.], [ 5., 5., 5., 5.], [ 6., 6., 6., 6.], [ 7., 7., 7., 7.], [ 8., 8., 8., 8.], [ 9., 9., 9., 9.]]) arr[[2,4,8,6,-1]] array([[ 2., 2., 2., 2.], [ 4., 4., 4., 4.], [ 8., 8., 8., 8.], [ 6., 6., 6., 6.], [ 9., 9., 9., 9.]]) arr[[2,4,8,6,-1],0] array([ 2., 4., 8., 6., 9.]) 元素存取 只要找到对应的位置(下标拿就可以直接改变对应位置的值) A=np.arange(1,10).reshape(3,3) A array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) A[2,2] 9 A[2,2]=10 A array([[ 1, 2, 3], [ 4, 5, 6], [ 7, 8, 10]]) 结构数组 在numpy中可以定义结构数组来表现结构化数据,虽然这个功能现在有pandas这个更好的实现,但如果只是轻量级的使用,numpy的结构数组或许更有效率 persontype=np.dtype({'names':['name','age','weight'],'formats':['S32','i','f']},align=True)#先创建一个人物类型 a = np.array([(\"Huang\",27,75),(\"Hao\",25,55),(\"Li\",26,80)],dtype=persontype) 结构数组内部看着是个元组,但其实是类似结构体的东西,使用的时候有点像用字典 a[0][\"name\"] b'Huang' filter(lambda x: x[\"age\"]>26,a) 也可以直接获取某一列属性构成的数组 a[\"name\"] array([b'Huang', b'Hao', b'Li'], dtype='|S32') universal function 除了通用的序列操作外,还支持ufunc ufunc是universal function的简写,它是一种对数组中每个元素做相同操作的函数,概念上类似原生python的map,但在实际的运算中又不同. 原生map实际上是运行迭代器一个一个操作,而universal function则是向量化的执行函数,即一个函数不同的数据一起运行,这样就大大提高了效率. 内置的ufunc运算 test = np.arange(int(1e5)) %timeit -n 3 map(lambda x:x**2,test) 3 loops, best of 3: 170 ns per loop %timeit -n 3 test**2 3 loops, best of 3: 85.6 µs per loop numpy内置了许多ufunc. 四则运算 numpy的四则运算也是ufunc,只要使用与python一样的运算符即可 为了效率,最好不要把多步写在一起 np.arange(1,10).reshape(3,3)*4+2 array([[ 6, 10, 14], [18, 22, 26], [30, 34, 38]]) %timeit np.arange(1,10).reshape(3,3)*4+2 The slowest run took 13.74 times longer than the fastest. This could mean that an intermediate result is being cached. 1000000 loops, best of 3: 1.97 µs per loop def a(): A = np.arange(1,10).reshape(3,3)*4 return A+2 %timeit a() The slowest run took 32.74 times longer than the fastest. This could mean that an intermediate result is being cached. 100000 loops, best of 3: 2.02 µs per loop (17.17-10.46)/17.17 0.39079790331974373 可见分步计算效率比单步合起来计算快了近40% 比较运算 numpy中比较运算也是ufunc,可以看下面的例子 np.arange(1,10).reshape(3,3)>5 array([[False, False, False], [False, False, True], [ True, True, True]], dtype=bool) 比较运算会返回其中每个值的比较结果 其他的内置函数 排序操作如使用键序列执行间接排序的lexsort,和一般的排序argsort,sort 求沿给定轴的元素的累积积或和的cumprod和cumsum(默认flatten后) 求沿给定轴的第n个离散差分diff(常用在时间序列) 统计方法如平均值得average,mean,median,方差的var,标准差std,求协方差矩阵的cov,两个数组间Pearson乘积矩相关系数的corrcoef,最值的argmax, argmin,max, maximum, min, minimum,求和的sum 取近似值或限制取值的方法如ceil,floor, clip,round 数组间的向量,矩阵操作如cross,inner,dot,transpose,outer,数组元素在给定轴上的乘积prod,沿着数组的对角线返回总和的trace,vdot, 针对某个轴做向量化操作apply_along_axis(func1d, axis, arr, *args, **kwargs) 类似collections.counter的bincount 针对复数求共轭的conj 判断元素特点的nonzero,all,any 将函数向量化的vectorize,frompyfunc 根据条件返回元素的where 计算卷积的convolve等 自定义ufunc 有的时候自带的ufunc不能满足需要,numpy允许自定义ufunc 例:用一个分段函数描述三角波 def triangle_wave(x,c,c0,hc): x = x - int(x) if x >= c: r = 0.0 elif x x = np.linspace(0,2,1000) y1 = np.array([triangle_wave(t,0.6,0.4,1.0) for t in x]) triangl_ufunc1 = np.frompyfunc(triangle_wave,4,1) y2 = triangl_ufunc1(x,0.6,0.4,1.0) plt.plot(range(len(y2)),y2) plt.show() 广播 当ufunc对两个数组进行计算时,ufunc函数会对这俩数组对应元素进行计算: np.arange(1,10).reshape(3,3)+np.arange(2,11).reshape(3,3) array([[ 3, 5, 7], [ 9, 11, 13], [15, 17, 19]]) 当俩数组形状不同的时候,那就会进行广播处理 让所有数组向其中维数最多的数组看齐,shape不足的部分通过在前面加1补齐 输出数组的shape属性是输入数组shape属性在各轴上的最大值 如果输入数组的某个轴长度是1或输出数组对应数组对应轴的长度相同,这个数组就够用来计算,否则出错 当输入数组的某个轴长度为1时,沿着该轴运算时都用此轴上的额第一组值 看例子 a = np.arange(0,60,10).reshape(-1,1) a array([[ 0], [10], [20], [30], [40], [50]]) a.shape (6, 1) b = np.arange(0,5) b array([0, 1, 2, 3, 4]) b.shape (5,) c = a+b c array([[ 0, 1, 2, 3, 4], [10, 11, 12, 13, 14], [20, 21, 22, 23, 24], [30, 31, 32, 33, 34], [40, 41, 42, 43, 44], [50, 51, 52, 53, 54]]) c.shape (6, 5) a和b维数不同,所以根据规则1,让b的shape属性向a对齐,将b前加1,及b.shape=1,5 之后再计算 快速产生能进行广播的数组ogrid() x,y = np.ogrid[:5,:5] x array([[0], [1], [2], [3], [4]]) y array([[0, 1, 2, 3, 4]]) 利用ogrid的返回值可以很容易的计算出二元函数在等间距网格上的值 例:画出 f(x,y)=xe^{x^2-y^2} x,y = np.ogrid[-2:2:20j,-2:2:20j] x array([[-2. ], [-1.78947368], [-1.57894737], [-1.36842105], [-1.15789474], [-0.94736842], [-0.73684211], [-0.52631579], [-0.31578947], [-0.10526316], [ 0.10526316], [ 0.31578947], [ 0.52631579], [ 0.73684211], [ 0.94736842], [ 1.15789474], [ 1.36842105], [ 1.57894737], [ 1.78947368], [ 2. ]]) y array([[-2. , -1.78947368, -1.57894737, -1.36842105, -1.15789474, -0.94736842, -0.73684211, -0.52631579, -0.31578947, -0.10526316, 0.10526316, 0.31578947, 0.52631579, 0.73684211, 0.94736842, 1.15789474, 1.36842105, 1.57894737, 1.78947368, 2. ]]) z = x*np.exp(-x**2-y**2) from mpl_toolkits.mplot3d import Axes3D fig = plt.figure() ax = Axes3D(fig) ax.plot_surface(x, y, z, rstride=1, cstride=1, cmap='hot') plt.show() 针对ufunc的函数 针对ufunc本身还有一些方法,这些是针对两个输入一个输出的unfunc对象. reduce reduce和原生python中的reduce差不多,就是rfold,折叠操作的特化 np.add.reduce([1,2,3]) 6 np.subtract.reduce([1,2,3]) -4 np.add.reduce([[1,2,3],[6,7,8]],axis=1) array([ 6, 21]) np.add.reduce([[1,2,3],[6,7,8]],axis=0) array([ 7, 9, 11]) accumulate accumulate和python3中functiontools新增的累积函数accumulate一样 np.add.accumulate([1,2,3]) array([1, 3, 6], dtype=int32) np.subtract.accumulate([1,2,3]) array([ 1, -1, -4], dtype=int32) outer outer,会对俩数组中每两对元素组合进行运算. np.multiply.outer([1,2,3,4,5],[2,3,4]) array([[ 2, 3, 4], [ 4, 6, 8], [ 6, 9, 12], [ 8, 12, 16], [10, 15, 20]]) np.add.outer([1,2,3,4,5],[2,3,4]) array([[3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9]]) 数组对象操作是不是copy numpy的数组在进行简单任务时,比如赋值,比如变化shape等时不是copy,参与python的function运算作为参数时也不是copy, 使用numpy数组对象的view()方法可以获得原对象的一个浅拷贝(新的指针指向原数据),而切片操作也是如此,它也是浅拷贝 numpy数组对象的copy()可以获得一份原数据的深拷贝 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 20:06:06 "},"numpy/element_type_op_and_random/element_type_op_and_random.html":{"url":"numpy/element_type_op_and_random/element_type_op_and_random.html","title":"numpy数组的元素类型和随机操作","keywords":"","body":"元素数据类型,内置数学运算和随机数 数值和随机部分是numpy的基础,这篇将学习以下3个方面 内置数据类型 内置数学运算 随机数生成方法 均匀分布 正态分布 import numpy as np import matplotlib.pyplot as plt import random %matplotlib inline 内置数据类型 numpy可以特化其中元素的类型来获得更高的效率 类型 类型代码 说明 int8/uint8 i1/u1 有符号/无符号8位整型 int16/uint16 i2/u2 有符号/无符号16位整型 int32/uint32 i4/u4 有符号/无符号32位整型 int64/uint64 i8/u8 有符号/无符号64位整型 float16 f2 半精度浮点数 float32 f4或f 标准单精度浮点数 float64 f8或d 标准双精度浮点数 float128 f16或g 扩展精度浮点数 complex64 c8 32为浮点数表示的复数 complex128 c16 64为浮点数表示的复数 complex256 c32 128为浮点数表示的复数 bool ? 布尔值 object O python对象类型 string_ SX 固定长度字符串,比如长度为10,则S10 unicode_ UX 固定长度unicode,比如长度为10,则U10 np.ones((2,2),dtype=\"S1\") array([[b'1', b'1'], [b'1', b'1']], dtype='|S1') numpy内置运算函数: 函数 说明 一元运算 abs/fabs 绝对值 sqrt 平方根 square 平方 exp 指数 log/log10/log2/log1p 分别为自然对数(e为底数)/底数为10的log/底数为2的log/log(1+x) sign 求符号 ceil 大于等于该值的最小整数 floor 小于等于该值的最大整数 rint 四舍五入到最近的整数,dtype不变 modf 小数整数部分分离 isnan --- isfinite/isinf --- sin/sinh/cos/cosh/tan/tanh 三角函数,双曲三角函数 arcsin/arcsinh/arccos/arccosh/arctan/arctanh 反三角函数,反双曲三角函数 logical_not 计算各元素not x的真值 二元运算 add 加 subtract 减 multiply 乘 divide/floor_divide 除 power 乘方 maximun/fmax 最大值 minimum/fmin 最小值 mod 求模 copysign 将后面的符号付给前面 随机数生成函数 numpy有自己的随机数生成器,它可以作为标准库的补充,其接口基本和标准库的一致 随机种子设置 np.random.seed(3) 洗牌 np.random.permutation([1,2,3]) # 返回一个新序列 array([2, 1, 3]) a=np.array([1,2,3]) np.random.shuffle(a)#就地洗牌 a array([1, 3, 2]) 均匀分布 np.random.rand() #[0,1)间均匀分布 0.2909047389129443 np.random.rand(2,3) #生成均匀分布的数组 array([[ 0.51082761, 0.89294695, 0.89629309], [ 0.12558531, 0.20724288, 0.0514672 ]]) np.random.uniform(2,3) # 范围[2,3)中的均匀分布 2.4408098436506362 np.random.uniform(2,3,size=(3,4)) # 范围[2,3)中的均匀分布的3X4数组 array([[ 2.02987621, 2.45683322, 2.64914405, 2.27848728], [ 2.6762549 , 2.59086282, 2.02398188, 2.55885409], [ 2.25925245, 2.4151012 , 2.28352508, 2.69313792]]) np.random.randint(1,9)#上下限范围[1,9)内的整数 7 np.random.randint(1,9,size=(3,3))#上下限范围[1,9)内的整数数组 array([[8, 1, 4], [2, 4, 8], [1, 6, 5]]) l=np.random.rand(1000) r1=[len(list(filter(lambda x:i+0.005>x>i-0.005,l))) for i in map(lambda x:round(x*0.01,3),range(0,100,1))] plt.plot(list(map(lambda x:round(x*0.01,3),range(0,100,1))),r1) plt.show() 正态分布 np.random.normal(1,0.5)#均值为1,标准差差是0.5 1.4976562274678098 np.random.normal(1,0.5,size=(3,3))#均值为1,标准差差是0.5 array([[ 1.20455962, 1.62913661, 0.10931642], [ 1.24831185, 0.92775481, 1.43346156], [ 1.11850458, 0.63128245, 1.10479407]]) np.random.randn(2,3)#均值为0,标准差差是1的标准正态分布的2X3数组 array([[ 0.80698364, -1.66132958, 0.24282147], [ 0.64382288, 1.35099208, -1.24669106]]) l=np.random.randn(100000) r1=[len(list(filter(lambda x:i+0.05>x>i-0.05,l))) for i in map(lambda x:round(x*0.1,2),range(-40,40,1))] plt.plot(list(map(lambda x:round(x*0.1,2),range(-40,40,1))),r1) plt.show() *二项分布 二项分布是n个独立的是/非试验中成功的次数的离散概率分布，其中每次试验的成功概率为p。这样的单次成功/失败试验又称为伯努利试验。实际上，当n = 1时，二项分布就是伯努利分布。二项分布是显著性差异的二项试验的基础。 Poisson分布是二项分布n很大而P很小时的特殊形式，是两分类资料在n次实验中发生x次某种结果的概率分布。其概率密度函数为：P(x)=e-µ*µx/x! x=0,1,2...n，其中e为自然对数的底，µ为总体均数，x为事件发生的阳性数。 sum(np.random.binomial(10,0.1,1000)==0)/1000.0# 10个样本成功率为0.1,验证1000次全部都失败的概率 0.35499999999999998 Beta分布 np.random.beta(0.5,0.3) 0.3470417362539864 np.random.beta(0.5,0.3,[2,3]) array([[ 0.05610158, 0.29834244, 0.77032789], [ 0.94635763, 0.96394357, 0.02252188]]) l0=np.random.beta(0.5,1,100000) l1=np.random.beta(2,3,100000) l2=np.random.beta(3,4,100000) l3=np.random.beta(2,5,100000) r0=[len(list(filter(lambda x:i+0.005>x>i-0.005,l0))) for i in map(lambda x:round(x*0.01,3),range(0,100,1))] r1=[len(list(filter(lambda x:i+0.005>x>i-0.005,l1))) for i in map(lambda x:round(x*0.01,3),range(0,100,1))] r2=[len(list(filter(lambda x:i+0.005>x>i-0.005,l2))) for i in map(lambda x:round(x*0.01,3),range(0,100,1))] r3=[len(list(filter(lambda x:i+0.005>x>i-0.005,l3))) for i in map(lambda x:round(x*0.01,3),range(0,100,1))] plt.plot(list(map(lambda x:round(x*0.01,3),range(0,100,1))),r0,color=\"red\") plt.plot(list(map(lambda x:round(x*0.01,3),range(0,100,1))),r1,color=\"blue\") plt.plot(list(map(lambda x:round(x*0.01,3),range(0,100,1))),r2,color=\"green\") plt.plot(list(map(lambda x:round(x*0.01,3),range(0,100,1))),r3,color=\"yellow\") plt.show() min(l) -4.5696665976275819 *卡方分布 若k个随机变量$Z_1、……、Z_k$是相互独立，符合标准正态分布的随机变量（数学期望为0、方差为1），则随机变量Z的平方和 X=\\sum_{i=1}^k Z_i^2 被称为服从自由度为 k 的卡方分布，记作 X\\sim\\chi^2(k) X\\sim\\chi^2_k np.random.chisquare(2,(2,3)) array([[ 0.61277216, 2.27149958, 0.96366957], [ 2.19105947, 3.13205076, 0.37353015]]) 伽马分布 np.random.gamma(1,2) 0.6135197929089496 np.random.gamma(1,2,(2,3)) array([[ 0.66365723, 1.2891411 , 1.28417052], [ 0.77566813, 2.99185886, 2.11405567]]) l0=np.random.gamma(0.5,1,100000) l1=np.random.gamma(9,0.5,100000) l2=np.random.gamma(7,1,100000) r0=[len(list(filter(lambda x:i+0.05>x>i-0.05,l0))) for i in map(lambda x:round(x*0.1,3),range(0,200,1))] r1=[len(list(filter(lambda x:i+0.05>x>i-0.05,l1))) for i in map(lambda x:round(x*0.1,3),range(0,200,1))] r2=[len(list(filter(lambda x:i+0.05>x>i-0.05,l2))) for i in map(lambda x:round(x*0.1,3),range(0,200,1))] plt.plot(list(map(lambda x:round(x*0.1,3),range(0,200,1))),r0,color=\"red\") plt.plot(list(map(lambda x:round(x*0.1,3),range(0,200,1))),r1,color=\"blue\") plt.plot(list(map(lambda x:round(x*0.1,3),range(0,200,1))),r2,color=\"green\") plt.show() 随机游走 定义一个100步的随机游走 position = 0 walk=[position] steps = 100 for i in range(steps): step = 1 if random.randint(0,1) else -1 position += step walk.append(position) plt.plot(range(steps+1),walk) plt.show() Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 19:21:04 "},"numpy/Polynomials_and_Linear_algebra/Polynomials_and_Linear_algebra.html":{"url":"numpy/Polynomials_and_Linear_algebra/Polynomials_and_Linear_algebra.html","title":"多项式与线性代数计算","keywords":"","body":"多项式 多项式函数是变量的整数次幂与系数的乘积之和 $ f(x)=anx^n+a{n-1}x^{n-1}+...+a_2x^2+a_1x+a_0 $ 在numpy中可以用一个一维数组表示x各项的系数 numpy提供了polynomial模块专门处理多项式的 基本用法: import numpy as np import matplotlib.pyplot as plt import random %matplotlib inline 多项式求值 可以用polynomia.polynomia()将系数转化为一元多项式对象,之后就可以像用函数一样用它了,比如下面的函数: f(x)=1+2x+3x^2 v1 = np.array([1,2,]) from numpy.polynomial import Polynomial as P p = P(v1) p Polynomial([ 1., 2.], [-1, 1], [-1, 1]) 注意，长版本的打印输出有三个部分。 第一个是系数，第二个是域，第三个是窗口：,他们分别可以通过访问属性p.coef,p.domain和p.window获得 要求x在某个值时f(x)的值,只要简单的代入就行 p(0) 1.0 p(1) 3.0 多项式是天生的universal function,他的参数可以是一个序列 p(np.array([1,2,3,4])) array([ 3., 5., 7., 9.]) 多项式运算 初等变换 一个多项式可以通过与一个非字符串的数值序列相加或者乘以一个标量来获得一个新的多项式 p*2 #与标量相乘,多项式系数全部与标量相乘,类似向量与标量乘法 Polynomial([ 2., 4.], [-1., 1.], [-1., 1.]) p+p # 与多项式相加,对应系数相加 Polynomial([ 2., 4.], [-1., 1.], [-1., 1.]) p+(2,5) # 与另一个序列相加,相当于把序列作为多项式,对应系数相加 Polynomial([ 3., 7.], [-1., 1.], [-1., 1.]) p*p # 与多项式相乘各项一一相乘,然后相同次数的系数相加 Polynomial([ 1., 4., 4.], [-1., 1.], [-1., 1.]) p**2 # 幂,与乘法规则相同 Polynomial([ 1., 4., 4.], [-1., 1.], [-1., 1.]) 除法: //是多项式类的除法运算符，在这方面，多项式被视为整数.与之对应的是求余%,表示除后余下的项 p//P([-1,1]) #相当于多项式分解 Polynomial([ 2.], [-1., 1.], [-1., 1.]) p%P([-1,1]) Polynomial([ 3.], [-1., 1.], [-1., 1.]) P([ 5., 3.])*P([-1,1])+[6] Polynomial([ 1., 2., 3.], [-1., 1.], [-1., 1.]) 如果要一次求出,可以使用divmod方法 quo, rem = divmod(p, P([-1, 1])) quo Polynomial([ 2.], [-1., 1.], [-1., 1.]) rem Polynomial([ 3.], [-1., 1.], [-1., 1.]) 微积分 用deriv()和integ()可以分别计算多项式的微分和积分 $f(x)=3x^2+2x+1$ 做微分是 $f^{'}(x)=6x+2$ p.deriv() Polynomial([ 2.], [-1., 1.], [-1., 1.]) $f(x)=3x^2+2x+1$ 做积分是 $F(x)=x^3+x^2+x+N$ N是无法预测的所以置0 p.integ() Polynomial([ 0., 1., 1.], [-1., 1.], [-1., 1.]) 多项式因式分解 多项式的根可以使用np.roots()方法获得 其意义是令该多项式等于0,则当变量为这些根时满足该等式 r = p.roots() r array([-0.5]) p(r) array([ 0.]) np.poly(r) array([ 1. , 0.5]) 多项式拟合 多项式的拟合使用Chebyshev模块 的fit(x,y,deg),来做 其中deg为最高次数 我们用1000个在${-\\pi\\over 2} \\sim{\\pi \\over 2}$间的值拟合sin(x) from numpy.polynomial import Chebyshev as T x = np.linspace(-np.pi/2,np.pi/2,20) y = np.sin(x) a = T.fit(x,y,5) xx,yy=a.linspace() plt.plot(x,y,'o',color=\"red\") plt.plot(xx,yy,\"--\",lw=2,color = \"blue\") plt.show() error = np.abs(a(x)-y)#polyval计算多项式的值 plt.plot(x,error) plt.show() 做3,5,7次多项式的拟合,比较结果误差 x = np.linspace(-np.pi/2,np.pi/2,1000) y = np.sin(x) for i in (3,5,7): a = T.fit(x,y,i) if i == 3: color = \"red\" elif i == 5: color = \"blue\" else : color = \"yellow\" error = np.abs(a(x)-y) plt.plot(x,error,color = color) plt.show() 实现一个分段函数 上面的多项式,我们实现了连续函数. 而分段函数简单说就是实现一个模式匹配,不同的状态对应不同的表达式,在python中有条件表达式,可以实现简单的模式匹配 a = lambda x: x**2 if abs(x)>3 else 3*x plt.plot(list(range(10)),list(map(a,range(10)))) plt.show() 使用where实现三角波 T=1#定义周期T为1 x = np.linspace(0, 2,201,endpoint=True) C = 0.7#定义为0的部分 up = 0.5#定义上升的持续时间 top = 1.0#定义最大y值 #y=Kx+B K_up = lambda : top/up K_down = lambda : top/(up-C) B_down = top-K_down()*up y = np.where(np.modf(x)[0] >= C ,0,np.where(np.modf(x)[0] 明显的,where表现多条件并不直观,因此有了select方法 select(condlist,choicelist,default=0) condlist是一个长度为N的布尔数组列表,choicelist是个长度为N的候选值数组列表,看例子 使用select实现三角波 y1 = np.select([np.modf(x)[0] >= C,np.modf(x)[0] plt.plot(x,y1) plt.show() 这两个方法可以很好的完成任务,但会产生大量的中间值,因此效率并不高,numpy又提供了一个更加高效的方法 piecewise(x,condilist,funclist) 还是再看例子 使用piecewise实现三角波 y2 = np.piecewise(x,[np.modf(x)[0] >= C,np.modf(x)[0] plt.plot(x,y2) plt.show() 线性代数 线性代数的产生便是为了解决求解多项式的工作,因此与多项式有着千丝万缕的联系,虽然现在线性代数早已抽象到了更高的层次,成了研究向量和向量空间的学科,但落地到计算上,它解决的也还是运算的问题 线性代数使用numpy.linalg模块,主要函数有 向量,矩阵运算: 函数 说明 dot 向量乘法 vdot 向量点乘 inner 向量内积 outer 向量外积 matmul 矩阵乘法 trnsordot 张量乘法 einsum 评估操作数上的爱因斯坦求和约定 linalg.matrix_power 矩阵幂 kron 克罗内克积 矩阵分解 函数 说明 linalg.cholesky(a) Cholesky 分解 linalg.qr(a[, mode]) QR分解 linalg.svd(a[, full_matrices, compute_uv]) 奇异值分解 矩阵征值操作 函数 说明 linalg.norm(x[, ord, axis, keepdims]) 矩阵或向量范数 linalg.cond(x[, p]) 计算矩阵的条件数 linalg.det(a) 计算矩阵行列式 linalg.matrix_rank(M[, tol]) 使用SVD方法返回阵列的矩阵秩 linalg.slogdet(a) 计算数组行列式的符号和（自然）对数 trace(a[, offset, axis1, axis2, dtype, out]) 计算对角线元素的和 diag 以一维数组的形式返回方阵的对角线(或非对角线)元素,或将一维数组转换为方阵(非对角线元素为0) eig 计算方阵的本征值和本征向量 求解方程和求逆矩阵 函数 说明 linalg.solve(a, b) 解线性方程组Ax=b linalg.tensorsolve(a, b[, axes]) 解张量表达式Ax = b linalg.lstsq(a, b[, rcond]) 计算Ax=b的最小二乘解 linalg.inv(a) 计算方阵的逆 linalg.pinv(a[, rcond]) 计算矩阵的Moore-Penrose伪逆 linalg.tensorinv(a[, ind]) 计算N维数组的“逆”。 行列式 一般线性代数开篇就是讲的行列式,往往会讲2阶3阶的行列式计算,用numpy的话只是简单的一行 A_1 = np.array([[3,-2],[2,1]]) A_1 array([[ 3, -2], [ 2, 1]]) round(np.linalg.det(A_1),2) 7.0 线性方程组 在numpy中求解线性方程组非常简单 A = np.array([[1,0],[2,-1]]) b=np.array([2,0]) np.linalg.solve(A,b) array([ 2., 4.]) 求逆序数 同济大学线性代数第5版有道题: 按自然数由小到大为标准顺序,求下列各排列的逆序数: 1,2,3,4 4,1,3,2 3,4,2,1 2,4,1,3 std = range(1,5) std range(1, 5) a = [1,2,3,4] b = [4,1,3,2] c = [3,4,2,1] d = [2,4,1,3] def ron(std,a): a = [std.index(i) for i in a] b = np.array(a) nums = [np.sum(b[:1]>bb) for i,bb in enumerate(a)] return np.sum(nums) ron(std,c) 2 矩阵 到重点了,numpy提供一个非常强大的矩阵类型,可以做许多矩阵运算. 可以用如下的方法在matrix和array间相互转化 A_0=np.arange(9).reshape(3,3) A_0 array([[0, 1, 2], [3, 4, 5], [6, 7, 8]]) M_0=np.matrix(A_0) M_0 matrix([[0, 1, 2], [3, 4, 5], [6, 7, 8]]) np.array(M_0) array([[0, 1, 2], [3, 4, 5], [6, 7, 8]]) 虽然matrix很有用,但其实array中也可以执行许多矩阵的方法,因此matrix往往反倒不常用 矩阵运算 M_s1=np.matrix(np.arange(3,12).reshape(3,3)) M_s1 matrix([[ 3, 4, 5], [ 6, 7, 8], [ 9, 10, 11]]) M_s2=np.matrix(np.arange(13,22).reshape(3,3)) M_s2 matrix([[13, 14, 15], [16, 17, 18], [19, 20, 21]]) 矩阵的和和差 M_s1+M_s2 matrix([[16, 18, 20], [22, 24, 26], [28, 30, 32]]) 矩阵的倍数(与标量的积) 3*M_s1 matrix([[ 9, 12, 15], [18, 21, 24], [27, 30, 33]]) M_s1-M_s2 matrix([[-10, -10, -10], [-10, -10, -10], [-10, -10, -10]]) 矩阵的乘法 矩阵的乘法必须前一个矩阵的行数与后一个举证的列数相同 numpy为矩阵有提供了多种乘法计算 积dot matrix中: M_1=np.matrix(np.arange(9).reshape(3,3)) M_2=np.matrix(np.array([11,12,13]).reshape(-1,1)) M_1.dot(M_2) matrix([[ 38], [146], [254]]) M_1*M_2 matrix([[ 38], [146], [254]]) array中积必须使用dot方法 A_1 = np.arange(9).reshape(3,3) A_2 = np.array([11,12,13]).reshape(-1,1) A_1.dot(A_2) array([[ 38], [146], [254]]) A_1*A_2 array([[ 0, 11, 22], [ 36, 48, 60], [ 78, 91, 104]]) inner, 数组a和b最后一维的内积 a = np.arange(12).reshape(2,3,2) b = np.arange(12,24).reshape(2,3,2) c = np.inner(a,b) c.shape (2, 3, 2, 3) outer,只按一维数组进行计算 np.outer([1,2,3],[4,5,6,7]) array([[ 4, 5, 6, 7], [ 8, 10, 12, 14], [12, 15, 18, 21]]) 矩阵特性 矩阵的秩 矩阵的秩就是 M_1 = np.matrix(np.arange(1,5).reshape(2,2)) M_1 matrix([[1, 2], [3, 4]]) np.linalg.matrix_rank(M_1) 2 方阵的迹 迹就是方阵主对角线元素之和,目前不知道有啥用 np.trace(M_1) 5 转置矩阵(transpose) M_1.T matrix([[1, 3], [2, 4]]) 共轭矩阵(hermitian) M_2 = np.matrix([[1+1j,2-4j],[3-1j,2+3j]]) M_2 matrix([[ 1.+1.j, 2.-4.j], [ 3.-1.j, 2.+3.j]]) M_2.H matrix([[ 1.-1.j, 3.+1.j], [ 2.+4.j, 2.-3.j]]) 逆矩阵(inverse) M_1.I matrix([[-2. , 1. ], [ 1.5, -0.5]]) 伴随矩阵(adjoint) np.dot(np.linalg.det(M_1),M_1.I) matrix([[ 4., -2.], [-3., 1.]]) 矩阵的范数(matrix norms) np.linalg.norm(M_1) 5.4772255750516612 矩阵QR分解 X = np.random.randn(5,5) X array([[-0.5320189 , -1.19891311, 0.92396147, 0.56487442, 0.22180163], [ 0.95132989, 1.03601126, -1.15607831, 0.49701824, 0.51231611], [ 1.76521565, 1.03661832, -0.25669223, -1.17190004, 1.49667204], [ 0.19603648, 1.14515212, 0.12837353, -0.08032806, 0.52600719], [-1.70138732, -0.5344671 , 1.66191277, 1.30185401, 0.40628467]]) mat = X.T.dot(X) mat array([[ 7.23720807, 4.58711491, -4.84688537, -4.12705698, 2.42319687], [ 4.58711491, 5.18231795, -3.312782 , -2.16491788, 2.20153449], [-4.84688537, -3.312782 , 5.03454657, 2.40140363, -0.02879038], [-4.12705698, -2.16491788, 2.40140363, 3.64073638, -0.8873593 ], [ 2.42319687, 2.20153449, -0.02879038, -0.8873593 , 2.99344176]]) q,r=np.linalg.qr(mat) q array([[-0.66117193, 0.31291312, -0.13137528, -0.30036115, -0.59788024], [-0.41906652, -0.83962446, 0.08392856, 0.30173558, -0.14603305], [ 0.44279845, -0.09973548, -0.66540102, 0.2662986 , -0.52944207], [ 0.37703686, -0.38417471, 0.23944018, -0.75337103, -0.2921532 ], [-0.22137677, -0.19894415, -0.68964224, -0.42456562, 0.50552069]]) r array([[-10.94603052, -7.97512472, 7.73398119, 6.26840917, -3.5347331 ], [ 0. , -2.19170626, -0.15411504, -0.93534132, -1.34196742], [ 0. , 0. , -2.39642094, 0.24629742, -2.39129275], [ 0. , 0. , 0. , -1.14021784, -0.67362139], [ 0. , 0. , 0. , 0. , 0.0174561 ]]) 计算两个同型矩阵的欧几里得距离 a = np.array([[ 0, 1.], [ 1., 0.]]) a array([[ 0., 1.], [ 1., 0.]]) b = np.array([[1,1],[1,1]]) b array([[1, 1], [1, 1]]) c = a-b c#距离矩阵 array([[-1., 0.], [ 0., -1.]]) np.sqrt(np.trace(c.dot(c)))#欧几里得距离 1.4142135623730951 求特征值特征向量 M_lamida=np.matrix([[3,0,-1],[2,4,2],[-1,0,3]]) np.linalg.eig(M_lamida) (array([ 4., 4., 2.]), matrix([[ 0. , 0.70710678, 0.40824829], [ 1. , 0. , -0.81649658], [ 0. , -0.70710678, 0.40824829]])) 第一项是特征值,第二项是特征向量 判断正定矩阵 正定矩阵的定义是：设M是n阶方阵，如果对任何非零向量z，都有 z'Mz > 0，其中z' 表示z的转置，就称M正定矩阵。 M_4=np.arange(16).reshape(4,4) M_4 array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15]]) M_4 = M_4+M_4.T#将方阵转换成对称阵 M_4 array([[ 0, 5, 10, 15], [ 5, 10, 15, 20], [10, 15, 20, 25], [15, 20, 25, 30]]) lambdas,_ = np.linalg.eig(M_4) lambdas array([ 6.74165739e+01, -7.41657387e+00, 1.82694656e-15, -1.72637110e-15]) #判断是否所有特征值都大于0 True if np.all(lambdas > 0) else False False 因此矩阵不是正定矩阵 还有一种方式是使用cholesky分解的方法: Cholesky 分解是把一个对称正定的矩阵表示成一个下三角矩阵L和其转置的乘积的分解。它要求矩阵的所有特征值必须大于零，故分解的下三角的对角元也是大于零的。 np.linalg.cholesky(np.arange(16).reshape(4,4)) --------------------------------------------------------------------------- LinAlgError Traceback (most recent call last) in () ----> 1 np.linalg.cholesky(np.arange(16).reshape(4,4)) C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py in cholesky(a) 610 t, result_t = _commonType(a) 611 signature = 'D->D' if isComplexType(t) else 'd->d' --> 612 r = gufunc(a, signature=signature, extobj=extobj) 613 return wrap(r.astype(result_t, copy=False)) 614 C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py in _raise_linalgerror_nonposdef(err, flag) 91 92 def _raise_linalgerror_nonposdef(err, flag): ---> 93 raise LinAlgError(\"Matrix is not positive definite\") 94 95 def _raise_linalgerror_eigenvalues_nonconvergence(err, flag): LinAlgError: Matrix is not positive definite np.linalg.cholesky(M_4) --------------------------------------------------------------------------- LinAlgError Traceback (most recent call last) in () ----> 1 np.linalg.cholesky(M_4) C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py in cholesky(a) 610 t, result_t = _commonType(a) 611 signature = 'D->D' if isComplexType(t) else 'd->d' --> 612 r = gufunc(a, signature=signature, extobj=extobj) 613 return wrap(r.astype(result_t, copy=False)) 614 C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py in _raise_linalgerror_nonposdef(err, flag) 91 92 def _raise_linalgerror_nonposdef(err, flag): ---> 93 raise LinAlgError(\"Matrix is not positive definite\") 94 95 def _raise_linalgerror_eigenvalues_nonconvergence(err, flag): LinAlgError: Matrix is not positive definite 报错了,因此可以看出不是正定的 我们试试测试一个单位矩阵 i=np.eye(4) np.linalg.cholesky(i) array([[ 1., 0., 0., 0.], [ 0., 1., 0., 0.], [ 0., 0., 1., 0.], [ 0., 0., 0., 1.]]) 奇异值分解 arr = np.arange(9).reshape((3, 3)) + np.diag([1, 0, 1]) arr array([[1, 1, 2], [3, 4, 5], [6, 7, 9]]) uarr, spec, vharr = np.linalg.svd(arr) uarr array([[-0.1617463 , -0.98659196, 0.02178164], [-0.47456365, 0.09711667, 0.87484724], [-0.86523261, 0.13116653, -0.48390895]]) spec array([ 14.88982544, 0.45294236, 0.29654967]) vharr array([[-0.45513179, -0.54511245, -0.70406496], [ 0.20258033, 0.70658087, -0.67801525], [-0.86707339, 0.45121601, 0.21115836]]) 向量 向量是向量空间的元素,形式上向量就是一个一维的矩阵,而一组n个向量就是一个n列的矩阵 按照同济大学线性代数第5版的定义,一般向量都是指的列向量即 v_1 = np.array([1,2,3]).reshape(-1,1) v_1 array([[1], [2], [3]]) 向量的乘法 叉乘(外积) $|C| = | v_1 \\times v_2 |= |v_1| |v_2|sin $ C的方向用右手定则,右手4指从v_1不超过180度转向v_2时大拇指的方向即为C的方向 v_1 = np.array([3,5]) v_2 = np.array([4,2]) l_v1 = np.sqrt(sum(v_1**2))#计算v1v2的长度(模) l_v2 = np.sqrt(sum(v_2**2)) 计算向量夹角 theta=np.arccos((v_1.dot(v_2))/(l_v1*l_v2)) C_value= (l_v1*l_v2)*np.sin(theta) C_value 14.000000000000002 几道线代题: 1.同一向量空间中的矩阵经过线性变换后是相似矩阵: $ R^2 \\to R^2$的映射矩阵: $ F_1:\\begin{pmatrix}x\\ y\\end{pmatrix} \\to \\begin{pmatrix}2x-y\\ x+2y\\end{pmatrix} \\Rightarrow \\begin{pmatrix}2 , 1\\ 1 , 2\\end{pmatrix} \\begin{pmatrix}x\\ y\\end{pmatrix}$ 然后我们要求的是一个在非标准基下的映射矩阵 $ F_2:\\begin{pmatrix}f_1\\ f_2\\end{pmatrix} \\to \\begin{pmatrix}2x-y\\ x+2y\\end{pmatrix} \\Rightarrow M \\begin{pmatrix}f_1\\ f_2\\end{pmatrix} $ $ F_1和F_2 $是相似矩阵,因为他们其实只是进行了线性变化而已,有一样的特征值,因此有 $ P^{-1}F_1P = F_2 $ 其中$B_2$就是新定义的基向量到原向量的过渡矩阵 $\\begin{pmatrix}1,2\\ 5,0\\end{pmatrix}^T $ $ F_1 $就是之前的标准基下的矩阵 $\\begin{pmatrix}2,-1\\ 1,2\\end{pmatrix} $ 证明: 设开始的基为$ A $,后来的基为$ B $ 则有 $ B = AP $ $ A = BP^{-1} $ 以及 $ T(A) = AF_1 $ $ T(B) = BF_2 $ 则 $ BF_2 = TB = T(AP) = T(A)P=AF_1P=BP^{-1}F_1P $ 约掉B可得 $ F_2 = P^{-1}F_1P $ F_1 = np.matrix([[2,-1],[1,2]]) B_2 = np.matrix([[1,2],[5,0]]).T F_2 = B_2.I.dot(F_1).dot(B_2) F_2 matrix([[ 2.5, 2.5], [-0.5, 1.5]]) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 21:09:30 "},"numpy/statistics/statistics.html":{"url":"numpy/statistics/statistics.html","title":"numpy的统计学工具","keywords":"","body":"用numpy做简单的统计 numpy有方便的数组,因此统计分析也是其很重要的一个功能 基本统计运算 统计运算 说明 sum 统计求和 mean 均值 average 加权求均值 median 中值 std 标准差 var 方差 min 最小值 argmin 最小值下标 max 最大值 argmax 最大值下标 ptp 最大值和最小值之差 sort 排序 argsort 排序下标 unique 找出所有整数(不会出现重复),并排序,可选参数return_index=True,会额外返回一个记录下标的数组可选return_inverse=True,会额外返回一个下标数组,数组长度为原始数组,表示原始数组中对应的下标 bincount 对整数数组个元素出现次数统计,可选参数weight,可以对各个元素加权 其中很多运算还有个nanxxx版本,用来求相应函数去掉nan值得结果 import numpy as np import matplotlib.pyplot as plt import random %matplotlib inline 统计频数bincount a = np.random.randint(0,5,10) a array([3, 3, 4, 1, 0, 1, 2, 4, 4, 2]) np.bincount(a) array([1, 2, 2, 2, 3], dtype=int64) len(filter(lambda x : x == 0,a)) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) in () ----> 1 len(filter(lambda x : x == 0,a)) TypeError: object of type 'filter' has no len() np.bincount(a,np.random.rand(10)) array([ 0.19711768, 1.18850072, 1.80437954, 0.94394277, 1.34664336]) 卷积 卷积运算符经常出现在信号处理中，其中它模拟线性时不变系统对信号的影响。在概率理论中，两个独立随机变量的和根据它们各自的分布的卷积来分布。 离散卷积运算定义为: (a * v)[n] = \\sum_{m = -\\infty}^{\\infty} a[m] v[n - m] 可以看出，在适当的填充（需要填充以防止循环卷积）之后，时间/空间中的卷积等价于傅立叶域中的乘法。由于乘法比卷积更有效（更快），函数scipy.signal.fftconvolve可以利用FFT来计算大数据集的卷积 numpy提供了通用的卷积操作convolve(a, v, mode='full') 其中前两个参数都是一维的输入向量,而mode则提供了可选的三种运算规则,它可以有3种选项 full 默认情况下，模式为“full”。这在每个重叠点处返回卷积，其输出形状为(N M-1,).在卷积的端点，信号不完全重叠，并且可以看到边界效应。 same 模式same返回长度max（M，N）的输出。边界效应仍然可见。 valid 模式'valid'返回长度为max(M,N)-min(M,N)+1.卷积产物仅针对信号完全重叠的点给出。信号边界外的值没有效果。 np.convolve([1, 2, 3], [0, 1, 0.5]) array([ 0. , 1. , 2.5, 4. , 1.5]) np.convolve([1,2,3],[0,1,0.5], 'same') array([ 1. , 2.5, 4. ]) np.convolve([1,2,3],[0,1,0.5], 'valid') array([ 2.5]) 相关性 numpy提供了3种算相关性的操作 corrcoef(x, y=None, rowvar=1) Pearson乘积矩相关系数。 其中rowvar=1表示向量是横置的,即每一列为向量的一个属性,每行是一个向量.为0则说明向量为竖置 np.corrcoef([[1,1,0,1,1],[0,1,0,1,1]]) array([[ 1. , 0.61237244], [ 0.61237244, 1. ]]) np.corrcoef([[1,1,0,1,1],[0,1,0,1,1]],rowvar=0) C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2569: RuntimeWarning: invalid value encountered in true_divide c /= stddev[:, None] C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2570: RuntimeWarning: invalid value encountered in true_divide c /= stddev[None, :] array([[ 1., nan, nan, nan, nan], [ nan, nan, nan, nan, nan], [ nan, nan, nan, nan, nan], [ nan, nan, nan, nan, nan], [ nan, nan, nan, nan, nan]]) correlate(a, v, mode='valid')[source]两个1维序列的互相关。该函数计算信号处理文本中通常定义的相关性 $ c_{av}[k] = sum_n a[n+k] * conj(v[n]) $ 其中a和v序列在必要时被填零，conj是共轭。mode 可选{‘valid’, ‘same’, ‘full’} np.correlate([1, 2, 3], [0, 1, 0.5]) array([ 3.5]) np.correlate([1, 2, 3], [0, 1, 0.5], \"same\") array([ 2. , 3.5, 3. ]) np.correlate([1, 2, 3], [0, 1, 0.5], \"full\") array([ 0.5, 2. , 3.5, 3. , 0. ]) cov(m, y=None, rowvar=True, bias=False, ddof=None, fweights=None, aweights=None)估计协方差矩阵，给定数据和权重。 协方差表示两个变量一起变化的水平。 如果我们检查N维样本，则协方差矩阵元素$C{ij}$是$x_i$和$x_j$的协方差。$C{ii}$元素是$x_i$的方差。 其中rowvar一样是代表向量的是横置还是竖置 在概率论和统计学中，协方差Cov(X，Y)用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况，即当两个变量是相同的情况。 期望值分别为$E(X)=\\mu$与$E(Y)=\\nu$的两个实数随机变量X 与Y 之间的协方差定义为： $\\operatorname{cov}(X, Y) = \\operatorname{E}((X - \\mu) (Y - \\nu))$ $\\operatorname{cov}(X, Y) = \\operatorname{E}(X \\cdot Y) - \\mu \\nu$ 协方差矩阵是一个矩阵，其每个元素是各个向量元素之间的协方差。是从标量随机变量到高维度随机向量的自然推广。 persontype=np.dtype({'names':['name','height','weight'],'formats':['S32','f','f']},align=True)#先创建一个人物类型 a = np.array([(\"Huang\",175,70),(\"Hao\",170,60),(\"Li\",180,75)],dtype=persontype) data = np.array([a[\"height\"],a[\"weight\"]]) data array([[ 175., 170., 180.], [ 70., 60., 75.]], dtype=float32) data_cov = np.cov(data) data_cov #协方差矩阵 array([[ 25. , 37.5 ], [ 37.5 , 58.33333333]]) #相关系数矩阵 data_corr = np.corrcoef(data) data_corr array([[ 1. , 0.98198051], [ 0.98198051, 1. ]]) 也就是说身高与体重相关系数高达98.19% 直方图 直方图统计histogram 最基础的直方图,计算一组数据各个区间中的数据统计 用法: histogram(a,bins=10,range=None,normed=False,weights=None) 其中 bin指定统计区间个数, range是一个长为2的元组,分别表示统计范围的最小值和最大值(None表示由数据决定) normed=False表示返回在每个区间的个数,为True则表示返回一个在各个区间的概率密度 weight表示权值和前面一样用法 c = np.random.rand(100) y,x = np.histogram(c,bins=5,range=(0,1)) x array([ 0. , 0.2, 0.4, 0.6, 0.8, 1. ]) float(y[0])/sum(y) 0.20000000000000001 xticks = [str(x[i])+'~'+str(x[i+1]) for i in range(len(y)) ] xticks ['0.0~0.2', '0.2~0.4', '0.4~0.6', '0.6~0.8', '0.8~1.0'] plt.axes([0.025,0.025,0.95,0.95]) plt.bar(range(len(y)), y, facecolor='#9999ff', edgecolor='white') for i,j in zip(range(len(y)), y): plt.text(i,j,str(float(y[i])/sum(y)*100)+\"%\") plt.xlim(-0.4,5) plt.xticks(np.arange(5)+0.4,xticks) plt.show() histogram2d(x, y[, bins, range, normed, weights])计算两个数据样本的二维直方图。 xedges = [0, 1, 1.5, 3, 5] yedges = [0, 2, 3, 4, 6] x = np.random.normal(3, 1, 100) y = np.random.normal(1, 1, 100) H, xedges, yedges = np.histogram2d(y, x, bins=(xedges, yedges)) H = np.ones((4, 4)).cumsum().reshape(4, 4) print(H[::-1]) [[ 13. 14. 15. 16.] [ 9. 10. 11. 12.] [ 5. 6. 7. 8.] [ 1. 2. 3. 4.]] fig = plt.figure(figsize=(7, 3)) ax = fig.add_subplot(131) ax.set_title('imshow: equidistant') im = plt.imshow(H, interpolation='nearest', origin='low', extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]]) histogramdd(sample, bins=10, range=None, normed=False, weights=None)计算多维直方图 r = np.random.randn(100,3) H, edges = np.histogramdd(r, bins = (5, 8, 4)) H.shape, edges[0].size, edges[1].size, edges[2].size ((5, 8, 4), 6, 9, 5) digitize(x, bins, right=False)返回输入数组中每个值所属的bin的索引 x = np.array([0.2, 6.4, 3.0, 1.6]) bins = np.array([0.0, 1.0, 2.5, 4.0, 10.0]) inds = np.digitize(x, bins) inds array([1, 4, 3, 2], dtype=int64) for n in range(x.size): print(bins[inds[n]-1], \" 0.0 x = np.array([1.2, 10.0, 12.4, 15.5, 20.]) bins = np.array([0, 5, 10, 15, 20]) np.digitize(x,bins,right=True) array([1, 2, 3, 4, 4], dtype=int64) np.digitize(x,bins,right=False) array([1, 3, 3, 4, 5], dtype=int64) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 20:10:10 "},"numpy/Financial_functions.html":{"url":"numpy/Financial_functions.html","title":"numpy的财务分析工具","keywords":"","body":"numpy的财务分析函数 numpy提供了简单的财务分析函数: import numpy as np fv(rate, nper, pmt, pv[, when]) 求按比率计算n步后的值 例如:现在存100美元,且每月存100美元,假设利率是5%,6%,7%（每月）复利,求10年后的未来价值是多少 a = np.array((0.05, 0.06, 0.07))/12 np.fv(a, 10*12, -100, -100) array([ 15692.92889434, 16569.87435405, 17509.44688102]) pv(rate, nper, pmt[, fv, when])求按比率计算n步前的值 其实就是前一方法的反面 b = np.array([ 15692.92889434, 16569.87435405, 17509.44688102]) np.pv(a, 10*12, -100, b) array([-100., -100., -100.]) npv(rate, values)净现值 values为现金流量时间序列的价值。 现金流“事件”之间的（固定）时间间隔必须与给出费率的时间间隔相同（即，如果费率是每年，则恰好一年被理解为在每个现金流事件之间流逝）。 按惯例，投资或“存款”是负数，收入或“提款”是正数; 值必须以初始投资开始，因此值[0]通常为负值。 净现值是一项投资所产生的未来现金流的折现值与项目投资成本之间的差值。 净现值指标是反映项目投资获利能力的指标。 决策标准： 净现值≥0 方案可行； 净现值＜0 方案不可行； 净现值均＞0 净现值最大的方案为最优方案。 优点： 考虑了资金时间价值，增强了投资经济性的评价； 考虑了全过程的净现金流量，体现了流动性与收益性的统一； 考虑了投资风险，风险大则采用高折现率，风险小则采用低折现率。 缺点： 净现值的计算较麻烦，难掌握； 净现金流量的测量和折现率较难确定； 不能从动态角度直接反映投资项目的实际收益水平； 项目投资额不等时，无法准确判断方案的优劣。 numpy中的净现值使用这个公式 $\\sum_{t=0}^{M-1}{\\frac{values_t}{(1+rate)^{t}}}$ np.npv(0.281,[-100, 39, 59, 55, 20]) -0.0084785916384548798 pmt(rate, nper, pv, fv=0, when='end')[source]计算贷款本金加利息的付款 nper是计算次数 pv是本金 np.pmt(0.075/12, 12*15, 200000) -1854.0247200054619 ppmt(rate, per, nper, pv, fv=0.0, when='end')计算贷款本金的付款。 ipmt(rate, per, nper, pv, fv=0.0, when='end')[source]¶计算付款的利息部分。 irr(values)[source]返回内部收益率（IRR） numpy使用公式 $\\sum_{t=0}^M{\\frac{v_t}{(1+irr)^{t}}} = 0$ print(round(np.irr([-100, 39, 59, 55, 20]), 5)) print(round(np.irr([-100, 0, 0, 74]), 5)) print(round(np.irr([-100, 100, 0, -7]), 5)) print(round(np.irr([-100, 100, 0, 7]), 5)) print(round(np.irr([-5, 10.5, 1, -8, 1]), 5)) 0.28095 -0.0955 -0.0833 0.06206 0.0886 mirr(values, finance_rate, reinvest_rate)修改后的内部收益率。 nper(rate, pmt, pv, fv=0, when='end')计算定期付款的数量。 计算公式为: $fv + pv(1+rate)**nper + pmt(1+ratewhen)/rate((1+rate)**nper-1) = 0$ 如果rate = 0,那么: $fv + pv + pmt*nper = 0$ print(round(np.nper(0.07/12, -150, 8000), 5)) 64.07335 rate(nper, pmt, pv, fv, when='end', guess=0.1, tol=1e-06, maxiter=100)计算每个周期的利率。 通过迭代求解（非线性）方程来计算利息率: $ fv + pv(1+rate)**nper + pmt(1+ratewhen)/rate ((1+rate)**nper - 1) = 0$ Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 19:23:09 "},"numpy/frequency_analysis/frequency_analysis.html":{"url":"numpy/frequency_analysis/frequency_analysis.html","title":"频谱分析","keywords":"","body":"频谱分析 将时域信号变换至频域加以分析的方法称为频谱分析。频谱分析的目的是把复杂的时间历程波形，经过傅里叶变换分解为若干单一的谐波分量来研究，以获得信号的频率结构以及各谐波和相位信息。 对信号进行频谱分析可以获得更多有用信息，如求得动态信号中的各个频率成分和频率分布范围，求出各个频率成分的幅值分布和能量分布，从而得到主要幅度和能量分布的频率值。 由时间函数求频谱函数的傅里叶变换公式就是将该时间函数乘以以频率为系数的指数函数之后，在从负无限大到正无限大的整个区间内，对时间进行积分，这样就得到了与这个时间函数对应的，以频率为自变量的频谱函数。频谱函数是信号的频域表示方式。根据上述傅里叶变换公式，可以求出常数（直流信号）的频谱函数为频域中位于零频率处的一个冲激函数，表示直流信号就是一个频率等于零的信号。与此相反，冲激函数的频谱函数等于常数，表示冲激函数含有无限多个、频率无限密集的正弦成分。同样的，单个正弦波的频谱函数就是频域中位于该正弦波频率处的一对冲激函数。 傅里叶变换 傅里叶变换是信号处理的基础之一,它可以将函数在时域和频域间转换 np中用np.fft模块可以做傅里叶变换 import numpy as np import matplotlib.pyplot as plt import random %matplotlib inline 傅里叶级数 假设:关于一个变量的任意一个周期函数 $f(x)$ ，不论连续或不连续,且函数 $f(x)$ 必须平方可积的，则 $f(x)$ 都可以近似的展开为正弦函数的级数，而正弦函数的参数为变量的倍数,大约就是: f(x)=\\sum_k c_k sin kx 最常见的表达形式 周期为T的函数f(x)有： \\begin{align} f(x)&=a_0+\\sum_{k=1}^\\infty{[a_k sin (k{2\\pi\\over T}x)+b_k cos(k{2\\pi\\over T}x)]}\\\\ &=a_0+\\sum_{k=1}^\\infty{\\sqrt{a_k^2+b_k^2} [sin(k{2\\pi\\over T}x+\\theta)]} \\end{align} 然后因为有欧拉公式: \\cos x={\\frac {e^{ix}+e^{-ix}} 2} \\sin x={\\frac {e^{ix}-e^{-ix}} 2i} 所以有: f(x) = \\sum_{k=-\\infty}^{+\\infty}a_k e^{ik({2\\pi\\over T})t} 傅里叶变换: 假设一个函数（信号）是周期的，但是它的周期是无穷大,可以得出: 傅里叶正变换: F(\\omega)=\\int_{-\\infty}^\\infty f(t) e^{-i\\omega t}dt 傅里叶反变换: f(t)={1\\over {2\\pi}}\\int_{-\\infty}^\\infty F(\\omega) e^{-i\\omega t}d\\omega 于是,我们可以利用傅里叶正变换变到分解状态（或者说频域），然后把它的分量分别处理，再利用反变换回去了. 傅里叶变换的支持方法 实域变频域后,函数表现形式有了变化,各个分量有了频率,周期. numpy中获取和处理频率的工具有 fftfreq(n[, d]) 获取连续傅里叶变换分量频率 rfftfreq(n[, d]) 获取离散傅里叶变换分量频率 fftshift(x[, axes]) 将0频分量移动到中心 ifftshift(x[, axes]) The inverse of fftshift. 上一操作的反操作 离散时间信号 在时间上依次出现的数值序列,例如，{…，0.5，1，2，-1，0，5，…}。相邻两个数之间的时间间隔可以是相等的，也可以是不等的。在前一情况下，设时间间隔为T秒,则离散信号可用符号x(nT)来表示（图1）。在间隔T归一化为1的条件下,T可以省略,即将x(nT)表示为x(n)。x(n)既可表示整个序列, 也可表示离散信号在nT瞬间的值。 离散傅里叶变换 简称DFT, python的numpy里的fft模块就是用的这种变换 对于N点序列 $\\left{x[n]\\right}_{0\\le n \\hat{x}[k]=\\sum_{n=0}^{N-1} e^{-i\\frac{2\\pi}{N}nk}x[n] \\qquad k = 0,1,\\ldots,N-1. 其中i是虚数单位 其逆变换为: x\\left[n\\right]={1 \\over N}\\sum_{k=0}^{N-1} e^{ i\\frac{2\\pi}{N}nk}\\hat{x}[k] \\qquad n = 0,1,\\ldots,N-1. 标准快速傅里叶变换: numpy中实现了标准快速傅里叶变换 方法 说明 fft(a[, n, axis, norm]) 一维空间离散傅里叶变换 ifft(a[, n, axis, norm]) 一维空间离散傅里叶反变换 fft2(a[, s, axes, norm]) 二维空间离散傅里叶变换 ifft2(a[, s, axes, norm]) 二维空间离散傅里叶反变换 fftn(a[, s, axes, norm]) N维空间离散傅里叶变换 ifftn(a[, s, axes, norm]) N维空间离散傅里叶反变换 fft的参数是一个数组,这个数组可以理解为一个连续函数按一定周期采样的结果.而这个数组一般都是2的整数次幂.比如256,128,64这样 以下是标准傅里叶变换的例子 一维空间 我们以一个矩形波为例子 t = np.linspace(-1, 1, 128,endpoint=True) tz = list(map(lambda x: 1 if (x > -0.5 and x plt.plot(t,tz) plt.show() sp = np.fft.fft(tz) re = np.fft.ifft(sp)#傅里叶逆变换 plt.plot(t,re) plt.show() C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py:482: ComplexWarning: Casting complex values to real discards the imaginary part return array(a, dtype, copy=False, order=order) freq = np.fft.fftfreq(t.shape[-1])#获取频率 plt.plot(freq, sp.real) plt.show() plt.plot(freq, sp.imag) plt.show() 二维空间(常用图像处理) a = np.mgrid[:5, :5][0] a array([[0, 0, 0, 0, 0], [1, 1, 1, 1, 1], [2, 2, 2, 2, 2], [3, 3, 3, 3, 3], [4, 4, 4, 4, 4]]) np.fft.fft2(a) array([[ 50.0 +0.j , 0.0 +0.j , 0.0 +0.j , 0.0 +0.j , 0.0 +0.j ], [-12.5+17.20477401j, 0.0 +0.j , 0.0 +0.j , 0.0 +0.j , 0.0 +0.j ], [-12.5 +4.0614962j , 0.0 +0.j , 0.0 +0.j , 0.0 +0.j , 0.0 +0.j ], [-12.5 -4.0614962j , 0.0 +0.j , 0.0 +0.j , 0.0 +0.j , 0.0 +0.j ], [-12.5-17.20477401j, 0.0 +0.j , 0.0 +0.j , 0.0 +0.j , 0.0 +0.j ]]) n维空间 b = np.mgrid[:3, :3, :3][0] b array([[[0, 0, 0], [0, 0, 0], [0, 0, 0]], [[1, 1, 1], [1, 1, 1], [1, 1, 1]], [[2, 2, 2], [2, 2, 2], [2, 2, 2]]]) np.fft.fftn(b, axes=(1, 2)) array([[[ 0.+0.j, 0.+0.j, 0.+0.j], [ 0.+0.j, 0.+0.j, 0.+0.j], [ 0.+0.j, 0.+0.j, 0.+0.j]], [[ 9.+0.j, 0.+0.j, 0.+0.j], [ 0.+0.j, 0.+0.j, 0.+0.j], [ 0.+0.j, 0.+0.j, 0.+0.j]], [[ 18.+0.j, 0.+0.j, 0.+0.j], [ 0.+0.j, 0.+0.j, 0.+0.j], [ 0.+0.j, 0.+0.j, 0.+0.j]]]) np.fft.fftn(b, (2, 2), axes=(0, 1)) array([[[ 2.+0.j, 2.+0.j, 2.+0.j], [ 0.+0.j, 0.+0.j, 0.+0.j]], [[-2.+0.j, -2.+0.j, -2.+0.j], [ 0.+0.j, 0.+0.j, 0.+0.j]]]) [X, Y] = np.meshgrid(2 * np.pi * np.arange(200) / 12, 2 * np.pi * np.arange(200) / 34) S = np.sin(X) + np.cos(Y) + np.random.uniform(0, 1, X.shape) FS = np.fft.fftn(S) plt.imshow(np.log(np.abs(np.fft.fftshift(FS))**2)) plt.show() numpy中其他的傅里叶变换还有 实数快速傅里叶变换: 方法 说明 rfft(a[, n, axis, norm]) 实数输入的一维空间离散傅里叶变换 irfft(a[, n, axis, norm]) 实数输入的一维空间离散傅里叶反变换 rfft2(a[, s, axes, norm]) 实数输入的二维空间离散傅里叶变换 irfft2(a[, s, axes, norm]) 实数输入的二维空间离散傅里叶反变换 rfftn(a[, s, axes, norm]) 实数输入的N维空间离散傅里叶变换 irfftn(a[, s, axes, norm]) 实数输入的N维空间离散傅里叶反变换 Hermitian傅里叶变换: 方法 说明 hfft(a[, n, axis, norm]) 计算实域中埃尔米特对称的信号的快速傅里叶变换 ihfft(a[, n, axis, norm]) 计算实域中埃尔米特对称的信号的快速傅里叶反变换 他们用法与上面的相同就不一一描述了 窗函数 在信号处理中，窗函数(window function)是一种除在给定区间之外取值均为0的实函数。譬如：在给定区间内为常数而在区间外为0的窗函数被形象地称为矩形窗。任何函数与窗函数之积仍为窗函数，所以相乘的结果就像透过窗口“看”其他函数一样。窗函数在频谱分析、滤波器设计、波束形成、以及音频数据压缩（如在Ogg Vorbis音频格式中）等方面有广泛的应用。 numpy中提供了几种常见的窗函数 函数 说明 bartlett(M) Bartlett窗口函数 blackman(M) Blackman 窗口函数 hamming(M) Hamming窗口函数 hanning(M) Hanning窗口函数 kaiser(M, beta) Kaiser窗口函数 bartlett窗 $w(n)=\\frac{2}{N-1}\\cdot\\left(\\frac{N-1}{2}-\\left |n-\\frac{N-1}{2}\\right |\\right)\\,$ window = np.bartlett(51) plt.plot(window) plt.title(\"Bartlett window\") plt.ylabel(\"Amplitude\") plt.xlabel(\"Sample\") plt.show() Blackman窗 w(n)=a_0 - a_1 \\cos \\left ( \\frac{2 \\pi n}{N-1} \\right) + a_2 \\cos \\left ( \\frac{4 \\pi n}{N-1} \\right) {\\displaystyle a_{0}=0.42;\\quad a_{1}=0.5;\\quad a_{2}=0.08\\,} a_0=0.42;\\quad a_1=0.5;\\quad a_2=0.08\\, window = np.blackman(51) plt.plot(window) plt.title(\"Blackman window\") plt.ylabel(\"Amplitude\") plt.xlabel(\"Sample\") plt.show() Hamming窗 $ w(n)=0.53836 - 0.46164\\; \\cos \\left ( \\frac{2 \\pi n}{N-1} \\right)$ window = np.hamming(51) plt.plot(window) plt.title(\"Hamming window\") plt.ylabel(\"Amplitude\") plt.xlabel(\"Sample\") plt.show() Hanning窗 $w(n)= 0.5\\; \\left(1 - \\cos \\left ( \\frac{2 \\pi n}{N-1} \\right) \\right)$ window = np.hanning(51) plt.plot(window) plt.title(\"Hanning window\") plt.ylabel(\"Amplitude\") plt.xlabel(\"Sample\") plt.show() Kaiser窗 w(n)=\\frac{I_0\\Bigg (\\pi\\alpha \\sqrt{1 - (\\begin{matrix} \\frac{2 n}{N-1} \\end{matrix}-1)^2}\\Bigg )} {I_0(\\pi\\alpha)} window = np.kaiser(51, 14) plt.plot(window) plt.title(\"Kaiser window\") plt.ylabel(\"Amplitude\") plt.xlabel(\"Sample\") plt.show() Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 21:32:07 "},"pandas/":{"url":"pandas/","title":"结构化数据处理工具pandas","keywords":"","body":"结构化数据处理工具pandas pandas是一个对numpy的封装,它的灵感来源于R语言的dataframe.并且提供了一系列简单高效的工具用于处理结构话数据. 除去数据分析的算法部分可以说pandas是个一站式数据处理工具. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 22:50:19 "},"pandas/basic_operation.html":{"url":"pandas/basic_operation.html","title":"表格基本操作","keywords":"","body":"表格基本操作 pandas的操作都比较傻瓜,只要引入包后调用对应类或者函数即可,可以在任何交互界面中执行(当然最推荐的还是Jupyter 即原 ipython)这也是有的人更加喜欢pandas而不喜欢excel的原因.我们以之前的iris作为例子 import pandas as pd iris_data = pd.read_csv(\"source/iris.csv\") iris_data[:5] sepal_length sepal_width petal_length petal_width class 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa 数据过滤 就像透视表一样,我们可以有选择性的查看表格 iris_data[iris_data[\"class\"]==\"Iris-virginica\"][::10] sepal_length sepal_width petal_length petal_width class 100 6.3 3.3 6.0 2.5 Iris-virginica 110 6.5 3.2 5.1 2.0 Iris-virginica 120 6.9 3.2 5.7 2.3 Iris-virginica 130 7.4 2.8 6.1 1.9 Iris-virginica 140 6.7 3.1 5.6 2.4 Iris-virginica iris_data[iris_data[\"petal_width\"]>iris_data[\"petal_width\"].mean()][::10] sepal_length sepal_width petal_length petal_width class 50 7.0 3.2 4.7 1.4 Iris-versicolor 63 6.1 2.9 4.7 1.4 Iris-versicolor 75 6.6 3.0 4.4 1.4 Iris-versicolor 88 5.6 3.0 4.1 1.3 Iris-versicolor 100 6.3 3.3 6.0 2.5 Iris-virginica 110 6.5 3.2 5.1 2.0 Iris-virginica 120 6.9 3.2 5.7 2.3 Iris-virginica 130 7.4 2.8 6.1 1.9 Iris-virginica 140 6.7 3.1 5.6 2.4 Iris-virginica 排序sort 比如我们根据sepal_length做降序排列 biggest5_sl_iris = iris_data.sort('sepal_length',ascending=False)[:5] C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....) if __name__ == '__main__': biggest5_sl_iris sepal_length sepal_width petal_length petal_width class 131 7.9 3.8 6.4 2.0 Iris-virginica 135 7.7 3.0 6.1 2.3 Iris-virginica 122 7.7 2.8 6.7 2.0 Iris-virginica 117 7.7 3.8 6.7 2.2 Iris-virginica 118 7.7 2.6 6.9 2.3 Iris-virginica 再把序号排排序 biggest5_sl_iris.sort(ascending=False) C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: sort(....) is deprecated, use sort_index(.....) if __name__ == '__main__': sepal_length sepal_width petal_length petal_width class 135 7.7 3.0 6.1 2.3 Iris-virginica 131 7.9 3.8 6.4 2.0 Iris-virginica 122 7.7 2.8 6.7 2.0 Iris-virginica 118 7.7 2.6 6.9 2.3 Iris-virginica 117 7.7 3.8 6.7 2.2 Iris-virginica 排名rank biggest5_sl_iris.rank(method=\"min\",numeric_only = True) sepal_length sepal_width petal_length petal_width 131 5.0 4.0 2.0 1.0 135 1.0 3.0 1.0 4.0 122 1.0 2.0 3.0 1.0 117 1.0 4.0 3.0 3.0 118 1.0 1.0 5.0 4.0 选择,切片操作 切片可以用来准确的提取需要的数据 pandas支持多种切片方式 间隔切片 iris_data[::20]#每20行取一次 sepal_length sepal_width petal_length petal_width class 0 5.1 3.5 1.4 0.2 Iris-setosa 20 5.4 3.4 1.7 0.2 Iris-setosa 40 5.0 3.5 1.3 0.3 Iris-setosa 60 5.0 2.0 3.5 1.0 Iris-versicolor 80 5.5 2.4 3.8 1.1 Iris-versicolor 100 6.3 3.3 6.0 2.5 Iris-virginica 120 6.9 3.2 5.7 2.3 Iris-virginica 140 6.7 3.1 5.6 2.4 Iris-virginica 连续数据段提取 iris_data[5:10]#取第5到第9行 sepal_length sepal_width petal_length petal_width class 5 5.4 3.9 1.7 0.4 Iris-setosa 6 4.6 3.4 1.4 0.3 Iris-setosa 7 5.0 3.4 1.5 0.2 Iris-setosa 8 4.4 2.9 1.4 0.2 Iris-setosa 9 4.9 3.1 1.5 0.1 Iris-setosa 提取某一行 iris_data.loc[5] #取第5行的数据 sepal_length 5.4 sepal_width 3.9 petal_length 1.7 petal_width 0.4 class Iris-setosa Name: 5, dtype: object 或者 iris_data.ix[5] #取第5行的数据 sepal_length 5.4 sepal_width 3.9 petal_length 1.7 petal_width 0.4 class Iris-setosa Name: 5, dtype: object 投影操作 所谓投影和数据库中差不多,就是取列(取属性),简单的方式就是用[]圈住需要的列号或者列名 iris_data[\"sepal_length\"][:5]#取某列 0 5.1 1 4.9 2 4.7 3 4.6 4 5.0 Name: sepal_length, dtype: float64 iris_data.sepal_length[:5]#同样地取某列 0 5.1 1 4.9 2 4.7 3 4.6 4 5.0 Name: sepal_length, dtype: float64 iris_data[[\"sepal_length\",\"petal_width\"]][:5]#取两列 sepal_length petal_width 0 5.1 0.2 1 4.9 0.2 2 4.7 0.2 3 4.6 0.2 4 5.0 0.2 iloc 位置坐标操作 简单粗暴的直接查看对应坐标,第一位参数是行,第二位是列 iris_data.iloc[5]#取第5行的数据 sepal_length 5.4 sepal_width 3.9 petal_length 1.7 petal_width 0.4 class Iris-setosa Name: 5, dtype: object iris_data.iloc[0,2:4]#取第一行第3个数据和第四个数据 petal_length 1.4 petal_width 0.2 Name: 0, dtype: object 增加一列元素 增加一列只需要在原数据上后面用[]填入要新增的元素即可,注意这个操作是对源数据的修改,如果希望源数据不变,先copy再增加 people_fromExcel = pd.read_excel('./source/people.xlsx', u'工作表1', index_col=None, na_values=['NA']) people_Data = people_fromExcel.append(pd.DataFrame([[\"Hao\",24]],columns = [\"name\",\"age\"])).reset_index(drop=True) people_Data name age 0 Michael NaN 1 Andy 30.0 2 Justin 19.0 3 Hao 24.0 people_Data[\"nation\"] = [\"USA\",\"UK\",\"AUS\",\"PRC\"] people_Data name age nation 0 Michael NaN USA 1 Andy 30.0 UK 2 Justin 19.0 AUS 3 Hao 24.0 PRC 也可以只输入一个值,这样就全部都是都是它了 people_Data[u\"星球\"] = u\"地球\" people_Data name age nation 星球 0 Michael NaN USA 地球 1 Andy 30.0 UK 地球 2 Justin 19.0 AUS 地球 3 Hao 24.0 PRC 地球 pandas的函数操作 由于python本身对函数式编程的支持,以及pandas底层依赖的numpy优秀的向量化计算能力,pandas可以使用类似Universal Function的方式向量化的求值. 例:求出iris三类的信息熵 import scipy as sp slogs = lambda x:sp.log(x)*x entropy = lambda x:sp.exp((slogs(x.sum())-x.map(slogs).sum())/x.sum()) iris_data.groupby(\"class\").agg(entropy) sepal_length sepal_width petal_length petal_width class Iris-setosa 49.878745 49.695242 49.654909 45.810069 Iris-versicolor 49.815081 49.680665 49.694505 49.452305 Iris-virginica 49.772059 49.714500 49.761700 49.545918 广播 所谓广播就是一个矢量和一个标量的运算,所有矢量中元素都被同样的操作,pandas可以支持这种操作 data1 = iris_data[:10].copy() data1 sepal_length sepal_width petal_length petal_width class 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa 5 5.4 3.9 1.7 0.4 Iris-setosa 6 4.6 3.4 1.4 0.3 Iris-setosa 7 5.0 3.4 1.5 0.2 Iris-setosa 8 4.4 2.9 1.4 0.2 Iris-setosa 9 4.9 3.1 1.5 0.1 Iris-setosa data1*10 sepal_length sepal_width petal_length petal_width class 0 51.0 35.0 14.0 2.0 Iris-setosaIris-setosaIris-setosaIris-setosaIr... 1 49.0 30.0 14.0 2.0 Iris-setosaIris-setosaIris-setosaIris-setosaIr... 2 47.0 32.0 13.0 2.0 Iris-setosaIris-setosaIris-setosaIris-setosaIr... 3 46.0 31.0 15.0 2.0 Iris-setosaIris-setosaIris-setosaIris-setosaIr... 4 50.0 36.0 14.0 2.0 Iris-setosaIris-setosaIris-setosaIris-setosaIr... 5 54.0 39.0 17.0 4.0 Iris-setosaIris-setosaIris-setosaIris-setosaIr... 6 46.0 34.0 14.0 3.0 Iris-setosaIris-setosaIris-setosaIris-setosaIr... 7 50.0 34.0 15.0 2.0 Iris-setosaIris-setosaIris-setosaIris-setosaIr... 8 44.0 29.0 14.0 2.0 Iris-setosaIris-setosaIris-setosaIris-setosaIr... 9 49.0 31.0 15.0 1.0 Iris-setosaIris-setosaIris-setosaIris-setosaIr... data1[\"sepal_length\"]*10 0 51.0 1 49.0 2 47.0 3 46.0 4 50.0 5 54.0 6 46.0 7 50.0 8 44.0 9 49.0 Name: sepal_length, dtype: float64 universal functiion import numpy as np np.exp(data1[\"sepal_length\"]) f_npexp = np.frompyfunc(lambda x :np.exp(x)+1,1,1) f_npexp(data1[\"sepal_length\"]) 0 165.022 1 135.29 2 110.947 3 100.484 4 149.413 5 222.406 6 100.484 7 149.413 8 82.4509 9 135.29 Name: sepal_length, dtype: object 基本的统计功能 pandas内置基本的统计功能 函数 作用 count 非NA值数量 describe 汇总统计 mean 求均值 min/max 最小最大值 argmin/argmax 获取最小最大值的index位置 idxmin/idxmax 获取最小最大值的index quantile 计算分位数 sum 求和 median 中位数 mad 根据均值计算平局绝对离差 var 方差 std 标准差 skew 偏度(三阶矩) kurt 锋度(四阶矩) cumsum 累计和 cummin/cummax 累计最小值累计最大值 cumprod 累计积 diff 一阶差分(对时间序列很有用) pct_change 百分数变化 corr 相关系数 cov 协方差 iris_data.describe() sepal_length sepal_width petal_length petal_width count 150.000000 150.000000 150.000000 150.000000 mean 5.843333 3.054000 3.758667 1.198667 std 0.828066 0.433594 1.764420 0.763161 min 4.300000 2.000000 1.000000 0.100000 25% 5.100000 2.800000 1.600000 0.300000 50% 5.800000 3.000000 4.350000 1.300000 75% 6.400000 3.300000 5.100000 1.800000 max 7.900000 4.400000 6.900000 2.500000 iris_data[[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"]].pct_change()[1:].tail() sepal_length sepal_width petal_length petal_width 145 0.000000 -0.090909 -0.087719 -0.080000 146 -0.059701 -0.166667 -0.038462 -0.173913 147 0.031746 0.200000 0.040000 0.052632 148 -0.046154 0.133333 0.038462 0.150000 149 -0.048387 -0.117647 -0.055556 -0.217391 iris_data[[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"]].pct_change()[1:].sepal_length.corr(iris_data.petal_length) 0.15569820981689295 iris_data[[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"]].corr() sepal_length sepal_width petal_length petal_width sepal_length 1.000000 -0.109369 0.871754 0.817954 sepal_width -0.109369 1.000000 -0.420516 -0.356544 petal_length 0.871754 -0.420516 1.000000 0.962757 petal_width 0.817954 -0.356544 0.962757 1.000000 iris_data[[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"]].cov() sepal_length sepal_width petal_length petal_width sepal_length 0.685694 -0.039268 1.273682 0.516904 sepal_width -0.039268 0.188004 -0.321713 -0.117981 petal_length 1.273682 -0.321713 3.113179 1.296387 petal_width 0.516904 -0.117981 1.296387 0.582414 抽样 抽样的话,pandas提供了sample()方法可以做简单的抽样 你可以选择是有放回还是无放回的 iris_data_test=iris_data.sample(frac=0.4) iris_data_test = iris_data_test.sort() iris_data_test[:5] C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: FutureWarning: sort(....) is deprecated, use sort_index(.....) from ipykernel import kernelapp as app sepal_length sepal_width petal_length petal_width class 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 5 5.4 3.9 1.7 0.4 Iris-setosa 剩余的数据可以这样得到 iris_data_train=iris_data.drop(iris_data_test.index) iris_data_train[:5] sepal_length sepal_width petal_length petal_width class 4 5.0 3.6 1.4 0.2 Iris-setosa 7 5.0 3.4 1.5 0.2 Iris-setosa 8 4.4 2.9 1.4 0.2 Iris-setosa 9 4.9 3.1 1.5 0.1 Iris-setosa 10 5.4 3.7 1.5 0.2 Iris-setosa 也可以设定别的你自己的抽样方式,比如我觉得我希望用每行数据摇色子的方式确定是否进入样本,那么可以这样 import random temp = iris_data.copy() temp[\"cc\"]=[random.random() for i in range(len(iris_data))] len(iris_data[temp[\"cc\"]>0.3]) 110 len(iris_data[temp[\"cc\"] 40 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 21:41:15 "},"pandas/Munging_Data.html":{"url":"pandas/Munging_Data.html","title":"数据清洗","keywords":"","body":"数据清洗 数据清洗是处理数据的第一步.我们的数据一般都是由不同来源汇总得来,因此难免会有 重复值 缺值 异常值和极端值 插值操作 等问题.数据清洗就是处理这些问题,使原始数据成为可用于进一步分析的数据 import pandas as pd import numpy as np dirty = pd.read_csv(\"source/dirty.csv\",sep=\",\") dirty name age weight height sex 0 Bob 12.0 69 175.0 m 1 Jessica NaN 89 195.0 f 2 Mary 15.0 49 169.0 f 3 John 18.0 79 184.0 m 4 Bob 12.0 69 175.0 m 5 Mel 11.0 45 NaN f 6 Mary 14.0 56 176.0 f 7 Jessica 25555.0 44 149.0 f 8 Bob 18.0 69 178.0 m 9 Marila 17.0 48 164.0 f 10 Johana 16.0 57 162.0 f 11 Melenda 15.0 42 153.0 f 12 Maryre 1977.0 300 NaN f 13 Jeson -25555.0 200 NaN m 14 Bobee 16.0 63 173.0 m 15 Jesa NaN 89 NaN m 重复值处理 首先我们要观察数据是否有重复值 dirty.duplicated() 0 False 1 False 2 False 3 False 4 True 5 False 6 False 7 False 8 False 9 False 10 False 11 False 12 False 13 False 14 False 15 False dtype: bool 从第4行就有重复 去除重复 dirty.drop_duplicates() name age weight height sex 0 Bob 12.0 69 175.0 m 1 Jessica NaN 89 195.0 f 2 Mary 15.0 49 169.0 f 3 John 18.0 79 184.0 m 5 Mel 11.0 45 NaN f 6 Mary 14.0 56 176.0 f 7 Jessica 25555.0 44 149.0 f 8 Bob 18.0 69 178.0 m 9 Marila 17.0 48 164.0 f 10 Johana 16.0 57 162.0 f 11 Melenda 15.0 42 153.0 f 12 Maryre 1977.0 300 NaN f 13 Jeson -25555.0 200 NaN m 14 Bobee 16.0 63 173.0 m 15 Jesa NaN 89 NaN m 这两个方法默认会判断全部列，你也可以指定部分列进行重复项判断。比如我们以names作为key，且只根据key列过滤重复项： dirty.duplicated([\"name\"]) 0 False 1 False 2 False 3 False 4 True 5 False 6 True 7 True 8 True 9 False 10 False 11 False 12 False 13 False 14 False 15 False dtype: bool dirty.drop_duplicates([\"name\"]) name age weight height sex 0 Bob 12.0 69 175.0 m 1 Jessica NaN 89 195.0 f 2 Mary 15.0 49 169.0 f 3 John 18.0 79 184.0 m 5 Mel 11.0 45 NaN f 9 Marila 17.0 48 164.0 f 10 Johana 16.0 57 162.0 f 11 Melenda 15.0 42 153.0 f 12 Maryre 1977.0 300 NaN f 13 Jeson -25555.0 200 NaN m 14 Bobee 16.0 63 173.0 m 15 Jesa NaN 89 NaN m duplicated和drop_duplicates默认保留的是第一个出现的值组合。传入keep='last'则保留最后一个： dirty.drop_duplicates([\"name\"],keep='last') name age weight height sex 3 John 18.0 79 184.0 m 5 Mel 11.0 45 NaN f 6 Mary 14.0 56 176.0 f 7 Jessica 25555.0 44 149.0 f 8 Bob 18.0 69 178.0 m 9 Marila 17.0 48 164.0 f 10 Johana 16.0 57 162.0 f 11 Melenda 15.0 42 153.0 f 12 Maryre 1977.0 300 NaN f 13 Jeson -25555.0 200 NaN m 14 Bobee 16.0 63 173.0 m 15 Jesa NaN 89 NaN m 缺值处理 有的时候读出来的数据是有缺值的,所有缺值都会在pandas中表现为numpy.NaN. 使用isnull方法查看 dirty.isnull() name age weight height sex 0 False False False False False 1 False True False False False 2 False False False False False 3 False False False False False 4 False False False False False 5 False False False True False 6 False False False False False 7 False False False False False 8 False False False False False 9 False False False False False 10 False False False False False 11 False False False False False 12 False False False True False 13 False False False True False 14 False False False False False 15 False True False True False dirty[\"age\"].isnull() 0 False 1 True 2 False 3 False 4 False 5 False 6 False 7 False 8 False 9 False 10 False 11 False 12 False 13 False 14 False 15 True Name: age, dtype: bool 用dropna()方法来做删除处理 可以设定how=\"all\"来丢弃全部为空的行, 要丢弃列加入参数axis = 1即可 dirty.dropna() name age weight height sex 0 Bob 12.0 69 175.0 m 2 Mary 15.0 49 169.0 f 3 John 18.0 79 184.0 m 4 Bob 12.0 69 175.0 m 6 Mary 14.0 56 176.0 f 7 Jessica 25555.0 44 149.0 f 8 Bob 18.0 69 178.0 m 9 Marila 17.0 48 164.0 f 10 Johana 16.0 57 162.0 f 11 Melenda 15.0 42 153.0 f 14 Bobee 16.0 63 173.0 m 缺值填充 有时我们并不想删除,而是会希望用其他数据去填充,这时可以用fillna方法 dirty.fillna(0) name age weight height sex 0 Bob 12.0 69 175.0 m 1 Jessica 0.0 89 195.0 f 2 Mary 15.0 49 169.0 f 3 John 18.0 79 184.0 m 4 Bob 12.0 69 175.0 m 5 Mel 11.0 45 0.0 f 6 Mary 14.0 56 176.0 f 7 Jessica 25555.0 44 149.0 f 8 Bob 18.0 69 178.0 m 9 Marila 17.0 48 164.0 f 10 Johana 16.0 57 162.0 f 11 Melenda 15.0 42 153.0 f 12 Maryre 1977.0 300 0.0 f 13 Jeson -25555.0 200 0.0 m 14 Bobee 16.0 63 173.0 m 15 Jesa 0.0 89 0.0 m 参数同样可以是一个pandas对象,比如用均值填充 dirty.fillna(dirty.mean()) name age weight height sex 0 Bob 12.000000 69 175.000000 m 1 Jessica 152.928571 89 195.000000 f 2 Mary 15.000000 49 169.000000 f 3 John 18.000000 79 184.000000 m 4 Bob 12.000000 69 175.000000 m 5 Mel 11.000000 45 171.083333 f 6 Mary 14.000000 56 176.000000 f 7 Jessica 25555.000000 44 149.000000 f 8 Bob 18.000000 69 178.000000 m 9 Marila 17.000000 48 164.000000 f 10 Johana 16.000000 57 162.000000 f 11 Melenda 15.000000 42 153.000000 f 12 Maryre 1977.000000 300 171.083333 f 13 Jeson -25555.000000 200 171.083333 m 14 Bobee 16.000000 63 173.000000 m 15 Jesa 152.928571 89 171.083333 m fillna方式中参数可以是一个列为key的字典,来实现不同列填入不同数据 dirty.fillna({\"age\":dirty[\"age\"].mean(), \"height\":dirty[\"height\"].mean()}) name age weight height sex 0 Bob 12.000000 69 175.000000 m 1 Jessica 152.928571 89 195.000000 f 2 Mary 15.000000 49 169.000000 f 3 John 18.000000 79 184.000000 m 4 Bob 12.000000 69 175.000000 m 5 Mel 11.000000 45 171.083333 f 6 Mary 14.000000 56 176.000000 f 7 Jessica 25555.000000 44 149.000000 f 8 Bob 18.000000 69 178.000000 m 9 Marila 17.000000 48 164.000000 f 10 Johana 16.000000 57 162.000000 f 11 Melenda 15.000000 42 153.000000 f 12 Maryre 1977.000000 300 171.083333 f 13 Jeson -25555.000000 200 171.083333 m 14 Bobee 16.000000 63 173.000000 m 15 Jesa 152.928571 89 171.083333 m 如果希望向前或向后填补空白,那么可以加入参数method= 可以有这些关键字: 'backfill'和 'bfill' 使用下一个有效的观察来填补前面的缺口 'pad'和'ffill' 传播最后一个观察到的有效的数据到下一个 使用method,如果我们只希望连续的空白填充到一定数量的数据点，我们可以使用limit=关键字 dirty.fillna(method='bfill',limit=1 ) name age weight height sex 0 Bob 12.0 69 175.0 m 1 Jessica 15.0 89 195.0 f 2 Mary 15.0 49 169.0 f 3 John 18.0 79 184.0 m 4 Bob 12.0 69 175.0 m 5 Mel 11.0 45 176.0 f 6 Mary 14.0 56 176.0 f 7 Jessica 25555.0 44 149.0 f 8 Bob 18.0 69 178.0 m 9 Marila 17.0 48 164.0 f 10 Johana 16.0 57 162.0 f 11 Melenda 15.0 42 153.0 f 12 Maryre 1977.0 300 NaN f 13 Jeson -25555.0 200 173.0 m 14 Bobee 16.0 63 173.0 m 15 Jesa NaN 89 NaN m 异常值和极端值 像25555.0,-25555,还有weight里面的200,300这些值可能是一个表示缺失数据的标记值,也可能是录入时候出错了,属于异常值.要将其替换为pandas能够理解的NA值，我们可以利用replace来产生一个新的dataframe dirty.replace(25555.0, np.nan) name age weight height sex 0 Bob 12.0 69 175.0 m 1 Jessica NaN 89 195.0 f 2 Mary 15.0 49 169.0 f 3 John 18.0 79 184.0 m 4 Bob 12.0 69 175.0 m 5 Mel 11.0 45 NaN f 6 Mary 14.0 56 176.0 f 7 Jessica NaN 44 149.0 f 8 Bob 18.0 69 178.0 m 9 Marila 17.0 48 164.0 f 10 Johana 16.0 57 162.0 f 11 Melenda 15.0 42 153.0 f 12 Maryre 1977.0 300 NaN f 13 Jeson -25555.0 200 NaN m 14 Bobee 16.0 63 173.0 m 15 Jesa NaN 89 NaN m 如果你希望一次性替换多个值，可以传入一个由待替换值组成的列表以及一个替换值： dirty.replace([25555.0,-25555.0], np.nan) name age weight height sex 0 Bob 12.0 69 175.0 m 1 Jessica NaN 89 195.0 f 2 Mary 15.0 49 169.0 f 3 John 18.0 79 184.0 m 4 Bob 12.0 69 175.0 m 5 Mel 11.0 45 NaN f 6 Mary 14.0 56 176.0 f 7 Jessica NaN 44 149.0 f 8 Bob 18.0 69 178.0 m 9 Marila 17.0 48 164.0 f 10 Johana 16.0 57 162.0 f 11 Melenda 15.0 42 153.0 f 12 Maryre 1977.0 300 NaN f 13 Jeson NaN 200 NaN m 14 Bobee 16.0 63 173.0 m 15 Jesa NaN 89 NaN m 如果希望对不同的值进行不同的替换，则传入一个由替换关系组成的列表即可： dirty.replace([25555.0,-25555.0], [np.nan, 0]) name age weight height sex 0 Bob 12.0 69 175.0 m 1 Jessica NaN 89 195.0 f 2 Mary 15.0 49 169.0 f 3 John 18.0 79 184.0 m 4 Bob 12.0 69 175.0 m 5 Mel 11.0 45 NaN f 6 Mary 14.0 56 176.0 f 7 Jessica NaN 44 149.0 f 8 Bob 18.0 69 178.0 m 9 Marila 17.0 48 164.0 f 10 Johana 16.0 57 162.0 f 11 Melenda 15.0 42 153.0 f 12 Maryre 1977.0 300 NaN f 13 Jeson 0.0 200 NaN m 14 Bobee 16.0 63 173.0 m 15 Jesa NaN 89 NaN m 传入的参数也可以是字典： dirty.replace({25555.0: np.nan, -25555.0: 0}) name age weight height sex 0 Bob 12.0 69 175.0 m 1 Jessica NaN 89 195.0 f 2 Mary 15.0 49 169.0 f 3 John 18.0 79 184.0 m 4 Bob 12.0 69 175.0 m 5 Mel 11.0 45 NaN f 6 Mary 14.0 56 176.0 f 7 Jessica NaN 44 149.0 f 8 Bob 18.0 69 178.0 m 9 Marila 17.0 48 164.0 f 10 Johana 16.0 57 162.0 f 11 Melenda 15.0 42 153.0 f 12 Maryre 1977.0 300 NaN f 13 Jeson 0.0 200 NaN m 14 Bobee 16.0 63 173.0 m 15 Jesa NaN 89 NaN m 更加常见的是针对不同列给出不同的替换方案 nan_dirty = dirty.replace({\"age\":[25555.0,-25555.0,1977], \"weight\":[300,200]},np.nan) nan_dirty name age weight height sex 0 Bob 12.0 69.0 175.0 m 1 Jessica NaN 89.0 195.0 f 2 Mary 15.0 49.0 169.0 f 3 John 18.0 79.0 184.0 m 4 Bob 12.0 69.0 175.0 m 5 Mel 11.0 45.0 NaN f 6 Mary 14.0 56.0 176.0 f 7 Jessica NaN 44.0 149.0 f 8 Bob 18.0 69.0 178.0 m 9 Marila 17.0 48.0 164.0 f 10 Johana 16.0 57.0 162.0 f 11 Melenda 15.0 42.0 153.0 f 12 Maryre NaN NaN NaN f 13 Jeson NaN NaN NaN m 14 Bobee 16.0 63.0 173.0 m 15 Jesa NaN 89.0 NaN m 更常见的情况是数据非常多,我们无法确定哪些是需要替换的离群点,这种时候我们只能手动的找出是否是离群点 States = ['NY', 'NY', 'NY', 'NY', 'FL', 'FL', 'GA', 'GA', 'FL', 'FL'] data = [1.0, 2, 3, 4, 5, 6, 7, 8, 9, 10] idx = pd.date_range('1/1/2012', periods=10, freq='MS') df1 = pd.DataFrame(data, index=idx, columns=['Revenue']) df1['State'] = States df1 Revenue State 2012-01-01 1.0 NY 2012-02-01 2.0 NY 2012-03-01 3.0 NY 2012-04-01 4.0 NY 2012-05-01 5.0 FL 2012-06-01 6.0 FL 2012-07-01 7.0 GA 2012-08-01 8.0 GA 2012-09-01 9.0 FL 2012-10-01 10.0 FL data2 = [10.0, 10.0, 9, 9, 8, 8, 7, 7, 6, 6] idx2 = pd.date_range('1/1/2013', periods=10, freq='MS') df2 = pd.DataFrame(data2, index=idx2, columns=['Revenue']) df2['State'] = States df2 Revenue State 2013-01-01 10.0 NY 2013-02-01 10.0 NY 2013-03-01 9.0 NY 2013-04-01 9.0 NY 2013-05-01 8.0 FL 2013-06-01 8.0 FL 2013-07-01 7.0 GA 2013-08-01 7.0 GA 2013-09-01 6.0 FL 2013-10-01 6.0 FL df = pd.concat([df1,df2]) df Revenue State 2012-01-01 1.0 NY 2012-02-01 2.0 NY 2012-03-01 3.0 NY 2012-04-01 4.0 NY 2012-05-01 5.0 FL 2012-06-01 6.0 FL 2012-07-01 7.0 GA 2012-08-01 8.0 GA 2012-09-01 9.0 FL 2012-10-01 10.0 FL 2013-01-01 10.0 NY 2013-02-01 10.0 NY 2013-03-01 9.0 NY 2013-04-01 9.0 NY 2013-05-01 8.0 FL 2013-06-01 8.0 FL 2013-07-01 7.0 GA 2013-08-01 7.0 GA 2013-09-01 6.0 FL 2013-10-01 6.0 FL 以上就是我们的例子使用的源数据,接着我们来根据他的均值和标准差来判断是不是离群点 方法一 使用针对整体的统计特点,最终确定是否是离群点 newdf = df.copy() newdf['x-Mean'] = abs(newdf['Revenue'] - newdf['Revenue'].mean()) newdf Revenue State x-Mean 2012-01-01 1.0 NY 5.75 2012-02-01 2.0 NY 4.75 2012-03-01 3.0 NY 3.75 2012-04-01 4.0 NY 2.75 2012-05-01 5.0 FL 1.75 2012-06-01 6.0 FL 0.75 2012-07-01 7.0 GA 0.25 2012-08-01 8.0 GA 1.25 2012-09-01 9.0 FL 2.25 2012-10-01 10.0 FL 3.25 2013-01-01 10.0 NY 3.25 2013-02-01 10.0 NY 3.25 2013-03-01 9.0 NY 2.25 2013-04-01 9.0 NY 2.25 2013-05-01 8.0 FL 1.25 2013-06-01 8.0 FL 1.25 2013-07-01 7.0 GA 0.25 2013-08-01 7.0 GA 0.25 2013-09-01 6.0 FL 0.75 2013-10-01 6.0 FL 0.75 newdf['1.96*std'] = 1.96*newdf['Revenue'].std() newdf Revenue State x-Mean 1.96*std 2012-01-01 1.0 NY 5.75 5.200273 2012-02-01 2.0 NY 4.75 5.200273 2012-03-01 3.0 NY 3.75 5.200273 2012-04-01 4.0 NY 2.75 5.200273 2012-05-01 5.0 FL 1.75 5.200273 2012-06-01 6.0 FL 0.75 5.200273 2012-07-01 7.0 GA 0.25 5.200273 2012-08-01 8.0 GA 1.25 5.200273 2012-09-01 9.0 FL 2.25 5.200273 2012-10-01 10.0 FL 3.25 5.200273 2013-01-01 10.0 NY 3.25 5.200273 2013-02-01 10.0 NY 3.25 5.200273 2013-03-01 9.0 NY 2.25 5.200273 2013-04-01 9.0 NY 2.25 5.200273 2013-05-01 8.0 FL 1.25 5.200273 2013-06-01 8.0 FL 1.25 5.200273 2013-07-01 7.0 GA 0.25 5.200273 2013-08-01 7.0 GA 0.25 5.200273 2013-09-01 6.0 FL 0.75 5.200273 2013-10-01 6.0 FL 0.75 5.200273 newdf['Outlier'] = abs(newdf['Revenue'] - newdf['Revenue'].mean()) > 1.96*newdf['Revenue'].std() newdf Revenue State x-Mean 1.96*std Outlier 2012-01-01 1.0 NY 5.75 5.200273 True 2012-02-01 2.0 NY 4.75 5.200273 False 2012-03-01 3.0 NY 3.75 5.200273 False 2012-04-01 4.0 NY 2.75 5.200273 False 2012-05-01 5.0 FL 1.75 5.200273 False 2012-06-01 6.0 FL 0.75 5.200273 False 2012-07-01 7.0 GA 0.25 5.200273 False 2012-08-01 8.0 GA 1.25 5.200273 False 2012-09-01 9.0 FL 2.25 5.200273 False 2012-10-01 10.0 FL 3.25 5.200273 False 2013-01-01 10.0 NY 3.25 5.200273 False 2013-02-01 10.0 NY 3.25 5.200273 False 2013-03-01 9.0 NY 2.25 5.200273 False 2013-04-01 9.0 NY 2.25 5.200273 False 2013-05-01 8.0 FL 1.25 5.200273 False 2013-06-01 8.0 FL 1.25 5.200273 False 2013-07-01 7.0 GA 0.25 5.200273 False 2013-08-01 7.0 GA 0.25 5.200273 False 2013-09-01 6.0 FL 0.75 5.200273 False 2013-10-01 6.0 FL 0.75 5.200273 False 方法二 使用groupby+transform,针对各个组别的统计特点,确定是否是离群点 newdf = df.copy() State = newdf.groupby('State') State.groups {'FL': DatetimeIndex(['2012-05-01', '2012-06-01', '2012-09-01', '2012-10-01', '2013-05-01', '2013-06-01', '2013-09-01', '2013-10-01'], dtype='datetime64[ns]', freq=None), 'GA': DatetimeIndex(['2012-07-01', '2012-08-01', '2013-07-01', '2013-08-01'], dtype='datetime64[ns]', freq=None), 'NY': DatetimeIndex(['2012-01-01', '2012-02-01', '2012-03-01', '2012-04-01', '2013-01-01', '2013-02-01', '2013-03-01', '2013-04-01'], dtype='datetime64[ns]', freq=None)} newdf['Outlier'] = State.transform( lambda x: abs(x-x.mean()) > 1.96*x.std() ) newdf Revenue State Outlier 2012-01-01 1.0 NY False 2012-02-01 2.0 NY False 2012-03-01 3.0 NY False 2012-04-01 4.0 NY False 2012-05-01 5.0 FL False 2012-06-01 6.0 FL False 2012-07-01 7.0 GA False 2012-08-01 8.0 GA False 2012-09-01 9.0 FL False 2012-10-01 10.0 FL False 2013-01-01 10.0 NY False 2013-02-01 10.0 NY False 2013-03-01 9.0 NY False 2013-04-01 9.0 NY False 2013-05-01 8.0 FL False 2013-06-01 8.0 FL False 2013-07-01 7.0 GA False 2013-08-01 7.0 GA False 2013-09-01 6.0 FL False 2013-10-01 6.0 FL False newdf['x-Mean'] = State.transform( lambda x: abs(x-x.mean()) ) newdf['1.96*std'] = State.transform( lambda x: 1.96*x.std() ) newdf Revenue State Outlier x-Mean 1.96*std 2012-01-01 1.0 NY False 5.00 7.554813 2012-02-01 2.0 NY False 4.00 7.554813 2012-03-01 3.0 NY False 3.00 7.554813 2012-04-01 4.0 NY False 2.00 7.554813 2012-05-01 5.0 FL False 2.25 3.434996 2012-06-01 6.0 FL False 1.25 3.434996 2012-07-01 7.0 GA False 0.25 0.980000 2012-08-01 8.0 GA False 0.75 0.980000 2012-09-01 9.0 FL False 1.75 3.434996 2012-10-01 10.0 FL False 2.75 3.434996 2013-01-01 10.0 NY False 4.00 7.554813 2013-02-01 10.0 NY False 4.00 7.554813 2013-03-01 9.0 NY False 3.00 7.554813 2013-04-01 9.0 NY False 3.00 7.554813 2013-05-01 8.0 FL False 0.75 3.434996 2013-06-01 8.0 FL False 0.75 3.434996 2013-07-01 7.0 GA False 0.25 0.980000 2013-08-01 7.0 GA False 0.25 0.980000 2013-09-01 6.0 FL False 1.25 3.434996 2013-10-01 6.0 FL False 1.25 3.434996 方法三 使用Group by item,通过groupby+apply,根据分组的统计特征判断是否是离群点 newdf = df.copy() State = newdf.groupby('State') def s(group): group['x-Mean'] = abs(group['Revenue'] - group['Revenue'].mean()) group['1.96*std'] = 1.96*group['Revenue'].std() group['Outlier'] = abs(group['Revenue'] - group['Revenue'].mean()) > 1.96*group['Revenue'].std() return group Newdf2 = State.apply(s) Newdf2 Revenue State x-Mean 1.96*std Outlier 2012-01-01 1.0 NY 5.00 7.554813 False 2012-02-01 2.0 NY 4.00 7.554813 False 2012-03-01 3.0 NY 3.00 7.554813 False 2012-04-01 4.0 NY 2.00 7.554813 False 2012-05-01 5.0 FL 2.25 3.434996 False 2012-06-01 6.0 FL 1.25 3.434996 False 2012-07-01 7.0 GA 0.25 0.980000 False 2012-08-01 8.0 GA 0.75 0.980000 False 2012-09-01 9.0 FL 1.75 3.434996 False 2012-10-01 10.0 FL 2.75 3.434996 False 2013-01-01 10.0 NY 4.00 7.554813 False 2013-02-01 10.0 NY 4.00 7.554813 False 2013-03-01 9.0 NY 3.00 7.554813 False 2013-04-01 9.0 NY 3.00 7.554813 False 2013-05-01 8.0 FL 0.75 3.434996 False 2013-06-01 8.0 FL 0.75 3.434996 False 2013-07-01 7.0 GA 0.25 0.980000 False 2013-08-01 7.0 GA 0.25 0.980000 False 2013-09-01 6.0 FL 1.25 3.434996 False 2013-10-01 6.0 FL 1.25 3.434996 False 根据多个item观察 newdf = df.copy() StateMonth = newdf.groupby(['State', lambda x: x.month]) StateMonth.groups {('FL', 5): DatetimeIndex(['2012-05-01', '2013-05-01'], dtype='datetime64[ns]', freq=None), ('FL', 6): DatetimeIndex(['2012-06-01', '2013-06-01'], dtype='datetime64[ns]', freq=None), ('FL', 9): DatetimeIndex(['2012-09-01', '2013-09-01'], dtype='datetime64[ns]', freq=None), ('FL', 10): DatetimeIndex(['2012-10-01', '2013-10-01'], dtype='datetime64[ns]', freq=None), ('GA', 7): DatetimeIndex(['2012-07-01', '2013-07-01'], dtype='datetime64[ns]', freq=None), ('GA', 8): DatetimeIndex(['2012-08-01', '2013-08-01'], dtype='datetime64[ns]', freq=None), ('NY', 1): DatetimeIndex(['2012-01-01', '2013-01-01'], dtype='datetime64[ns]', freq=None), ('NY', 2): DatetimeIndex(['2012-02-01', '2013-02-01'], dtype='datetime64[ns]', freq=None), ('NY', 3): DatetimeIndex(['2012-03-01', '2013-03-01'], dtype='datetime64[ns]', freq=None), ('NY', 4): DatetimeIndex(['2012-04-01', '2013-04-01'], dtype='datetime64[ns]', freq=None)} def s(group): group['x-Mean'] = abs(group['Revenue'] - group['Revenue'].mean()) group['1.96*std'] = 1.96*group['Revenue'].std() group['Outlier'] = abs(group['Revenue'] - group['Revenue'].mean()) > 1.96*group['Revenue'].std() return group Newdf2 = StateMonth.apply(s) Newdf2 Revenue State x-Mean 1.96*std Outlier 2012-01-01 1.0 NY 4.5 12.473364 False 2012-02-01 2.0 NY 4.0 11.087434 False 2012-03-01 3.0 NY 3.0 8.315576 False 2012-04-01 4.0 NY 2.5 6.929646 False 2012-05-01 5.0 FL 1.5 4.157788 False 2012-06-01 6.0 FL 1.0 2.771859 False 2012-07-01 7.0 GA 0.0 0.000000 False 2012-08-01 8.0 GA 0.5 1.385929 False 2012-09-01 9.0 FL 1.5 4.157788 False 2012-10-01 10.0 FL 2.0 5.543717 False 2013-01-01 10.0 NY 4.5 12.473364 False 2013-02-01 10.0 NY 4.0 11.087434 False 2013-03-01 9.0 NY 3.0 8.315576 False 2013-04-01 9.0 NY 2.5 6.929646 False 2013-05-01 8.0 FL 1.5 4.157788 False 2013-06-01 8.0 FL 1.0 2.771859 False 2013-07-01 7.0 GA 0.0 0.000000 False 2013-08-01 7.0 GA 0.5 1.385929 False 2013-09-01 6.0 FL 1.5 4.157788 False 2013-10-01 6.0 FL 2.0 5.543717 False 插值 Series和Dataframe对象有一个插值方法interpolate()，默认情况下，可以在Nan的数据点位置进行线性插值。 插值是用来填补空缺值得,一般是估计来的值,个人认为最好不要用 可以使用预设的几种方法插值: 'linear': 忽略索引，并将值视为等间隔的。这是支持多指标的唯一方法。 'time': 针对每日并且高频率数据,插值给给定区间的长度 'index', 'values': 用索引的数值 'nearest', 'zero', 'slinear', 'quadratic', 'cubic','barycentric', 'polynomial','krogh', 'piecewise_polynomial', 'spline', 'pchip'和 'akima','piecewise_polynomial'都是scipy中的对应方法 nan_dirty.interpolate() name age weight height sex 0 Bob 12.000000 69.0 175.000000 m 1 Jessica 13.500000 89.0 195.000000 f 2 Mary 15.000000 49.0 169.000000 f 3 John 18.000000 79.0 184.000000 m 4 Bob 12.000000 69.0 175.000000 m 5 Mel 11.000000 45.0 175.500000 f 6 Mary 14.000000 56.0 176.000000 f 7 Jessica 16.000000 44.0 149.000000 f 8 Bob 18.000000 69.0 178.000000 m 9 Marila 17.000000 48.0 164.000000 f 10 Johana 16.000000 57.0 162.000000 f 11 Melenda 15.000000 42.0 153.000000 f 12 Maryre 15.333333 49.0 159.666667 f 13 Jeson 15.666667 56.0 166.333333 m 14 Bobee 16.000000 63.0 173.000000 m 15 Jesa 16.000000 89.0 173.000000 m Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 22:02:39 "},"pandas/Grouping_and_clustering.html":{"url":"pandas/Grouping_and_clustering.html","title":"分组与集聚","keywords":"","body":"分组与集聚 我们处理数据有时候会有分组的需求,比如统计的是全年龄段的人的,但我们可能会按年龄分组成老中青三组,可能会分成男女两组. 也有时候我们统计一份问卷,需要将数据转置 import pandas as pd import numpy as np 转置 比如我们有这样的一组多选问卷结果统计 d = {'a':[1,0,0,1,0,1,1,0,1,0], 'b':[0,0,1,1,1,0,1,0,1,0], \"c\":[1,0,0,0,0,1,0,1,0,0], \"d\":[1,0,0,1,0,1,1,0,1,1]} i = [\"no.{n}\".format(n=i) for i in range(10)] df = pd.DataFrame(data = d, index = i) df a b c d no.0 1 0 1 1 no.1 0 0 0 0 no.2 0 1 0 0 no.3 1 1 0 1 no.4 0 1 0 0 no.5 1 0 1 1 no.6 1 1 0 1 no.7 0 0 1 0 no.8 1 1 0 1 no.9 0 0 0 1 转置只需要使用T方法 df.T no.0 no.1 no.2 no.3 no.4 no.5 no.6 no.7 no.8 no.9 a 1 0 0 1 0 1 1 0 1 0 b 0 0 1 1 1 0 1 0 1 0 c 1 0 0 0 0 1 0 1 0 0 d 1 0 0 1 0 1 1 0 1 1 堆积操作 还是之前的多选问题,如果我们想把它堆积起来成为一个有多重索引的序列,可以使用stack()方法 stack = df.stack() stack no.0 a 1 b 0 c 1 d 1 no.1 a 0 b 0 c 0 d 0 no.2 a 0 b 1 c 0 d 0 no.3 a 1 b 1 c 0 d 1 no.4 a 0 b 1 c 0 d 0 no.5 a 1 b 0 c 1 d 1 no.6 a 1 b 1 c 0 d 1 no.7 a 0 b 0 c 1 d 0 no.8 a 1 b 1 c 0 d 1 no.9 a 0 b 0 c 0 d 1 dtype: int64 stack[\"no.0\"] a 1 b 0 c 1 d 1 dtype: int64 也可以使用unstack汇总每个选项不同题目的结果 unstack = df.unstack() unstack a no.0 1 no.1 0 no.2 0 no.3 1 no.4 0 no.5 1 no.6 1 no.7 0 no.8 1 no.9 0 b no.0 0 no.1 0 no.2 1 no.3 1 no.4 1 no.5 0 no.6 1 no.7 0 no.8 1 no.9 0 c no.0 1 no.1 0 no.2 0 no.3 0 no.4 0 no.5 1 no.6 0 no.7 1 no.8 0 no.9 0 d no.0 1 no.1 0 no.2 0 no.3 1 no.4 0 no.5 1 no.6 1 no.7 0 no.8 1 no.9 1 dtype: int64 unstack[\"a\"] no.0 1 no.1 0 no.2 0 no.3 1 no.4 0 no.5 1 no.6 1 no.7 0 no.8 1 no.9 0 dtype: int64 groupby groupby的功能类似SQL的group by关键字: Split-Apply-Combine Split,就是按照规则分组 Apply,通过⼀一定的agg函数来获得输⼊入pd.Series返回⼀一个值的效果 Combine,把结果收集起来 Pandas的groupby的灵活性: 分组的关键字可以来⾃自于index,也可以来⾃自于真实的列数据 分组规则可以通过⼀一列或者多列 iris_data = pd.read_csv(\"./source/iris.data\",header = None,encoding = \"utf-8\", names=[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\",\"class\"]) iris_data[:5] sepal_length sepal_width petal_length petal_width class 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa iris_group = iris_data.groupby(\"class\") iris_group.sum() sepal_length sepal_width petal_length petal_width class Iris-setosa 250.3 170.9 73.2 12.2 Iris-versicolor 296.8 138.5 213.0 66.3 Iris-virginica 329.4 148.7 277.6 101.3 iris_group.mean() sepal_length sepal_width petal_length petal_width class Iris-setosa 5.006 3.418 1.464 0.244 Iris-versicolor 5.936 2.770 4.260 1.326 Iris-virginica 6.588 2.974 5.552 2.026 for level,subset in iris_group: print(level) print(subset[:5]) Iris-setosa sepal_length sepal_width petal_length petal_width class 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa Iris-versicolor sepal_length sepal_width petal_length petal_width class 50 7.0 3.2 4.7 1.4 Iris-versicolor 51 6.4 3.2 4.5 1.5 Iris-versicolor 52 6.9 3.1 4.9 1.5 Iris-versicolor 53 5.5 2.3 4.0 1.3 Iris-versicolor 54 6.5 2.8 4.6 1.5 Iris-versicolor Iris-virginica sepal_length sepal_width petal_length petal_width class 100 6.3 3.3 6.0 2.5 Iris-virginica 101 5.8 2.7 5.1 1.9 Iris-virginica 102 7.1 3.0 5.9 2.1 Iris-virginica 103 6.3 2.9 5.6 1.8 Iris-virginica 104 6.5 3.0 5.8 2.2 Iris-virginica 由此可见实际上groupby将表格拆分成了一组(分组名,子表)的键值对 之后的操作可以有: agg()方法 agg方法 是将由子表构成的序列作为参数操作,要求操作可以每个子表返回一个非序列的返回值,操作完成后生成新的表格 iris_group.agg(lambda x :\"好\") sepal_length sepal_width petal_length petal_width class Iris-setosa 好 好 好 好 Iris-versicolor 好 好 好 好 Iris-virginica 好 好 好 好 transform() transform方法对子表序列运算方法,分别运算完后结果放回对应的行,也就是说原来的表什么样算完结构一样但内容不一样了,和map有点像,但运算的时候序列不是1个总序列而是多个分开的子序列 iris_group.transform(lambda x:x - x.mean())[:5] sepal_length sepal_width petal_length petal_width 0 0.094 0.082 -0.064 -0.044 1 -0.106 -0.418 -0.064 -0.044 2 -0.306 -0.218 -0.164 -0.044 3 -0.406 -0.318 0.036 -0.044 4 -0.006 0.182 -0.064 -0.044 Categorical类型 现在pandas可以使用Categorical类型了, iris_data[:5] sepal_length sepal_width petal_length petal_width class 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa iris_data[\"class\"] = iris_data[\"class\"].astype(\"category\") iris_data[\"class\"][::20] 0 Iris-setosa 20 Iris-setosa 40 Iris-setosa 60 Iris-versicolor 80 Iris-versicolor 100 Iris-virginica 120 Iris-virginica 140 Iris-virginica Name: class, dtype: category Categories (3, object): [Iris-setosa, Iris-versicolor, Iris-virginica] 聚集 聚集操作一般是将多组数据合并到一张表格中 比如连接表格,我们可以使用函数concat([tables...]) df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'], 'B': ['B0', 'B1', 'B2', 'B3'], 'C': ['C0', 'C1', 'C2', 'C3'], 'D': ['D0', 'D1', 'D2', 'D3']}, index=[0, 1, 2, 3]) df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'], 'B': ['B4', 'B5', 'B6', 'B7'], 'C': ['C4', 'C5', 'C6', 'C7'], 'D': ['D4', 'D5', 'D6', 'D7']}, index=[4, 5, 6, 7]) df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'], 'B': ['B8', 'B9', 'B10', 'B11'], 'C': ['C8', 'C9', 'C10', 'C11'], 'D': ['D8', 'D9', 'D10', 'D11']}, index=[8, 9, 10, 11]) df1 A B C D 0 A0 B0 C0 D0 1 A1 B1 C1 D1 2 A2 B2 C2 D2 3 A3 B3 C3 D3 df2 A B C D 4 A4 B4 C4 D4 5 A5 B5 C5 D5 6 A6 B6 C6 D6 7 A7 B7 C7 D7 df3 A B C D 8 A8 B8 C8 D8 9 A9 B9 C9 D9 10 A10 B10 C10 D10 11 A11 B11 C11 D11 result = pd.concat([df1,df2,df3]) result A B C D 0 A0 B0 C0 D0 1 A1 B1 C1 D1 2 A2 B2 C2 D2 3 A3 B3 C3 D3 4 A4 B4 C4 D4 5 A5 B5 C5 D5 6 A6 B6 C6 D6 7 A7 B7 C7 D7 8 A8 B8 C8 D8 9 A9 B9 C9 D9 10 A10 B10 C10 D10 11 A11 B11 C11 D11 concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False,keys=None, levels=None, names=None,verify_integrity=False,copy=True)是concat的完整参数说明, objs：一个序列或dict，dataframe，或Panel对象。 axis：{ 0，1，…}，默认值0。将沿哪个轴操作。 join：{'inner', 'outer'}，默认为'outer'。如何处理其他轴的索引,outer为求并,inner为求交集. ignore_index：布尔值，默认为False。如果是True，则不使用索引值用于连接轴。由此产生的轴将被标记为(0，…，N - 1).常用于连接对象，连接轴为没有意义的索引信息。注意,其他轴上的索引值仍然在联接中有用. join_axes：索引对象的列表。用于其他n - 1轴而不执行内/外集逻辑的特定索引. keys：序列，默认无。使用传递key作为最外层级别构造分层索引.。如果多个层面通过，应包含元组。级别：序列列表，默认没有。具体水平（独特价值）用于构建多指标。否则，他们将从key推断。 names：列表，默认无。生成层次索引中的level的名称。 verify_integrity：布尔值，默认为false。检查新的连接轴是否包含重复。这相对真实的数据连接开销很大。 拷贝：布尔值，默认值为。如果FALSE，不复制数据 为每组添加外层索引 pd.concat([df1,df2,df3], keys=['x', 'y', 'z']) A B C D x 0 A0 B0 C0 D0 1 A1 B1 C1 D1 2 A2 B2 C2 D2 3 A3 B3 C3 D3 y 4 A4 B4 C4 D4 5 A5 B5 C5 D5 6 A6 B6 C6 D6 7 A7 B7 C7 D7 z 8 A8 B8 C8 D8 9 A9 B9 C9 D9 10 A10 B10 C10 D10 11 A11 B11 C11 D11 pd.concat({'x': df1, 'y': df2, 'z': df3}) A B C D x 0 A0 B0 C0 D0 1 A1 B1 C1 D1 2 A2 B2 C2 D2 3 A3 B3 C3 D3 y 4 A4 B4 C4 D4 5 A5 B5 C5 D5 6 A6 B6 C6 D6 7 A7 B7 C7 D7 z 8 A8 B8 C8 D8 9 A9 B9 C9 D9 10 A10 B10 C10 D10 11 A11 B11 C11 D11 设置索引 df4 = pd.DataFrame({'B': ['B2', 'B3', 'B6', 'B7'], 'D': ['D2', 'D3', 'D6', 'D7'], 'F': ['F2', 'F3', 'F6', 'F7']}, index=[2, 3, 6, 7]) df4 B D F 2 B2 D2 F2 3 B3 D3 F3 6 B6 D6 F6 7 B7 D7 F7 横向聚集 pd.concat([df1, df4], axis=1) A B C D B D F 0 A0 B0 C0 D0 NaN NaN NaN 1 A1 B1 C1 D1 NaN NaN NaN 2 A2 B2 C2 D2 B2 D2 F2 3 A3 B3 C3 D3 B3 D3 F3 6 NaN NaN NaN NaN B6 D6 F6 7 NaN NaN NaN NaN B7 D7 F7 使用交集 pd.concat([df1, df4], axis=1, join='inner') A B C D B D F 2 A2 B2 C2 D2 B2 D2 F2 3 A3 B3 C3 D3 B3 D3 F3 只合并特定的索引 pd.concat([df1, df4], axis=1, join_axes=[df1.index]) A B C D B D F 0 A0 B0 C0 D0 NaN NaN NaN 1 A1 B1 C1 D1 NaN NaN NaN 2 A2 B2 C2 D2 B2 D2 F2 3 A3 B3 C3 D3 B3 D3 F3 除了向下连接行,同样可以向右连接列序列 s3 = pd.Series([0, 1, 2, 3], name='foo') s4 = pd.Series([0, 1, 2, 3]) s5 = pd.Series([0, 1, 4, 5]) pd.concat([s3, s4, s5], axis=1) foo 0 1 0 0 0 0 1 1 1 1 2 2 2 4 3 3 3 5 pd.concat([s3, s4, s5], axis=1, keys=['red','blue','yellow']) red blue yellow 0 0 0 0 1 1 1 1 2 2 2 4 3 3 3 5 使用append方法链式集聚 append(other, ignore_index=False, verify_integrity=False)并不想contact那样可以自己设定很多 df1.append(df2).append(df3) A B C D 0 A0 B0 C0 D0 1 A1 B1 C1 D1 2 A2 B2 C2 D2 3 A3 B3 C3 D3 4 A4 B4 C4 D4 5 A5 B5 C5 D5 6 A6 B6 C6 D6 7 A7 B7 C7 D7 8 A8 B8 C8 D8 9 A9 B9 C9 D9 10 A10 B10 C10 D10 11 A11 B11 C11 D11 df1.append([df2,df3]) A B C D 0 A0 B0 C0 D0 1 A1 B1 C1 D1 2 A2 B2 C2 D2 3 A3 B3 C3 D3 4 A4 B4 C4 D4 5 A5 B5 C5 D5 6 A6 B6 C6 D6 7 A7 B7 C7 D7 8 A8 B8 C8 D8 9 A9 B9 C9 D9 10 A10 B10 C10 D10 11 A11 B11 C11 D11 df1.append(df4) A B C D F 0 A0 B0 C0 D0 NaN 1 A1 B1 C1 D1 NaN 2 A2 B2 C2 D2 NaN 3 A3 B3 C3 D3 NaN 2 NaN B2 NaN D2 F2 3 NaN B3 NaN D3 F3 6 NaN B6 NaN D6 F6 7 NaN B7 NaN D7 F7 使用joining/merging类似在数据中一样的操作 merging 有经验的关系型数据库用户都熟悉用于描述连接两个SQL表的术语merging。有几种情况要考虑： 一对一的连接 多对一的连接 多对多联接 pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None,left_index=False, right_index=False, sort=True,suffixes=('_x', '_y'), copy=True, indicator=False) on 连接的列名。必须同时在左边和右边的df对象中。 left_on/right_on 用左边/右边的某列作为key。可以是列名或长度等于DataFrame长度的列 left_index/right_index 如果是真的，使用索引（行标签）从左/右边的key加入。在一个多指标数据帧的情况下，数量必须匹配从右/左变key加入的数量 how 如何merging,有“left”，“right”，“outer”，“inner”可选。默认为inner Merge method SQL Join Name Description left LEFT OUTER JOIN Use keys from left frame only right RIGHT OUTER JOIN Use keys from right frame only outer FULL OUTER JOIN Use union of keys from both frames inner INNER JOIN Use intersection of keys from both frames sort 将结果排序。默认为true，通常设置为FALSE将大大改善性能 suffixes 后缀 indicator 用于指示merge的行为,如果是真的，一个范畴类型列为_merge将被添加到输出对象需要的值 Observation Origin _merge value Merge key only in 'left' frame left_only Merge key only in 'right' frame right_only Merge key in both frames both 最一般的连接,通过key列连接 left = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'], 'A': ['A0', 'A1', 'A2', 'A3'], 'B': ['B0', 'B1', 'B2', 'B3']}) left A B key 0 A0 B0 K0 1 A1 B1 K1 2 A2 B2 K2 3 A3 B3 K3 right = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'], 'C': ['C0', 'C1', 'C2', 'C3'], 'D': ['D0', 'D1', 'D2', 'D3']}) right C D key 0 C0 D0 K0 1 C1 D1 K1 2 C2 D2 K2 3 C3 D3 K3 result = pd.merge(left, right, on='key') result A B key C D 0 A0 B0 K0 C0 D0 1 A1 B1 K1 C1 D1 2 A2 B2 K2 C2 D2 3 A3 B3 K3 C3 D3 不同连接方式的不同结果 left = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'], 'key2': ['K0', 'K1', 'K0', 'K1'], 'A': ['A0', 'A1', 'A2', 'A3'], 'B': ['B0', 'B1', 'B2', 'B3']}) left A B key1 key2 0 A0 B0 K0 K0 1 A1 B1 K0 K1 2 A2 B2 K1 K0 3 A3 B3 K2 K1 right = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'], 'key2': ['K0', 'K0', 'K0', 'K0'], 'C': ['C0', 'C1', 'C2', 'C3'], 'D': ['D0', 'D1', 'D2', 'D3']}) right C D key1 key2 0 C0 D0 K0 K0 1 C1 D1 K1 K0 2 C2 D2 K1 K0 3 C3 D3 K2 K0 pd.merge(left, right, on=['key1', 'key2']) A B key1 key2 C D 0 A0 B0 K0 K0 C0 D0 1 A2 B2 K1 K0 C1 D1 2 A2 B2 K1 K0 C2 D2 pd.merge(left, right, how='left', on=['key1', 'key2']) A B key1 key2 C D 0 A0 B0 K0 K0 C0 D0 1 A1 B1 K0 K1 NaN NaN 2 A2 B2 K1 K0 C1 D1 3 A2 B2 K1 K0 C2 D2 4 A3 B3 K2 K1 NaN NaN pd.merge(left, right, how='right', on=['key1', 'key2']) A B key1 key2 C D 0 A0 B0 K0 K0 C0 D0 1 A2 B2 K1 K0 C1 D1 2 A2 B2 K1 K0 C2 D2 3 NaN NaN K2 K0 C3 D3 pd.merge(left, right, how='outer', on=['key1', 'key2']) A B key1 key2 C D 0 A0 B0 K0 K0 C0 D0 1 A1 B1 K0 K1 NaN NaN 2 A2 B2 K1 K0 C1 D1 3 A2 B2 K1 K0 C2 D2 4 A3 B3 K2 K1 NaN NaN 5 NaN NaN K2 K0 C3 D3 pd.merge(left, right, how='inner', on=['key1', 'key2']) A B key1 key2 C D 0 A0 B0 K0 K0 C0 D0 1 A2 B2 K1 K0 C1 D1 2 A2 B2 K1 K0 C2 D2 df1 = pd.DataFrame({'col1': [0, 1], 'col_left':['a', 'b']}) df1 col1 col_left 0 0 a 1 1 b df2 = pd.DataFrame({'col1': [1, 2, 2],'col_right':[2, 2, 2]}) df2 col1 col_right 0 1 2 1 2 2 2 2 2 pd.merge(df1, df2, on='col1', how='outer', indicator=True) col1 col_left col_right _merge 0 0 a NaN left_only 1 1 b 2.0 both 2 2 NaN 2.0 right_only 3 2 NaN 2.0 right_only pd.merge(df1, df2, on='col1', how='outer', indicator='indicator_column') col1 col_left col_right indicator_column 0 0 a NaN left_only 1 1 b 2.0 both 2 2 NaN 2.0 right_only 3 2 NaN 2.0 right_only join方法 join之于merge就像上面的append之于contact,是一种简便方法 left = pd.DataFrame({'A': ['A0', 'A1', 'A2'], 'B': ['B0', 'B1', 'B2']}, index=['K0', 'K1', 'K2']) right = pd.DataFrame({'C': ['C0', 'C2', 'C3'], 'D': ['D0', 'D2', 'D3']}, index=['K0', 'K2', 'K3']) left A B K0 A0 B0 K1 A1 B1 K2 A2 B2 right C D K0 C0 D0 K2 C2 D2 K3 C3 D3 left.join(right) A B C D K0 A0 B0 C0 D0 K1 A1 B1 NaN NaN K2 A2 B2 C2 D2 left.join(right, how='outer') A B C D K0 A0 B0 C0 D0 K1 A1 B1 NaN NaN K2 A2 B2 C2 D2 K3 NaN NaN C3 D3 left.join(right, how='inner') A B C D K0 A0 B0 C0 D0 K2 A2 B2 C2 D2 除了使用index索引作为key外,join也可以指定key left.join(right, on=key_or_keys) left = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'], 'B': ['B0', 'B1', 'B2', 'B3'], 'key': ['K0', 'K1', 'K0', 'K1']}) right = pd.DataFrame({'C': ['C0', 'C1'], 'D': ['D0', 'D1']}, index=['K0', 'K1']) left A B key 0 A0 B0 K0 1 A1 B1 K1 2 A2 B2 K0 3 A3 B3 K1 right C D K0 C0 D0 K1 C1 D1 left.join(right, on='key') A B key C D 0 A0 B0 K0 C0 D0 1 A1 B1 K1 C1 D1 2 A2 B2 K0 C0 D0 3 A3 B3 K1 C1 D1 针对多索引的join left = pd.DataFrame({'A': ['A0', 'A1', 'A2'], 'B': ['B0', 'B1', 'B2']}, index=pd.Index(['K0', 'K1', 'K2'], name='key')) index = pd.MultiIndex.from_tuples([('K0', 'Y0'), ('K1', 'Y1'), ('K2', 'Y2'), ('K2', 'Y3')], names=['key', 'Y']) right = pd.DataFrame({'C': ['C0', 'C1', 'C2', 'C3'], 'D': ['D0', 'D1', 'D2', 'D3']}, index=index) left A B key K0 A0 B0 K1 A1 B1 K2 A2 B2 right C D key Y K0 Y0 C0 D0 K1 Y1 C1 D1 K2 Y2 C2 D2 Y3 C3 D3 index MultiIndex(levels=[['K0', 'K1', 'K2'], ['Y0', 'Y1', 'Y2', 'Y3']], labels=[[0, 1, 2, 2], [0, 1, 2, 3]], names=['key', 'Y']) left.join(right, how='inner') A B C D key Y K0 Y0 A0 B0 C0 D0 K1 Y1 A1 B1 C1 D1 K2 Y2 A2 B2 C2 D2 Y3 A2 B2 C3 D3 index = pd.MultiIndex.from_tuples([('K0', 'X0'), ('K0', 'X1'), ('K1', 'X2')], names=['key', 'X']) left = pd.DataFrame({'A': ['A0', 'A1', 'A2'], 'B': ['B0', 'B1', 'B2']}, index=index) left A B key X K0 X0 A0 B0 X1 A1 B1 K1 X2 A2 B2 pd.merge(left.reset_index(), right.reset_index(), on=['key'], how='inner').set_index(['key','X','Y']) A B C D key X Y K0 X0 Y0 A0 B0 C0 D0 X1 Y0 A1 B1 C0 D0 K1 X2 Y1 A2 B2 C1 D1 \"打补丁\" 另一个相当普遍的情况是有两个像索引（或类似的索引）系列或数据帧的对象，一个想在另一个上\"打补丁\",把空值填上,这时候可以使用.combine_first方法 df1 = pd.DataFrame([[np.nan, 3., 5.], [-4.6, np.nan, np.nan], [np.nan, 7., np.nan]]) df2 = pd.DataFrame([[-42.6, np.nan, -8.2], [-5., 1.6, 4]], index=[1, 2]) df1 0 1 2 0 NaN 3.0 5.0 1 -4.6 NaN NaN 2 NaN 7.0 NaN df2 0 1 2 1 -42.6 NaN -8.2 2 -5.0 1.6 4.0 df1.combine_first(df2) 0 1 2 0 NaN 3.0 5.0 1 -4.6 NaN -8.2 2 -5.0 7.0 4.0 注意这时候原来有值得地方并不会被替换 也可以使用update方法用df2的值替换df1中的对应值,这时是修改df1而不是生成新的表 df1.update(df2) df1 0 1 2 0 NaN 3.0 5.0 1 -42.6 NaN -8.2 2 -5.0 1.6 4.0 时间序列处理 merge_ordered merge_ordered()函数允许组合时间序列和其他有序数据。特别是它有一个可选的fill_method关键字来填充/内插缺失的数据： left = pd.DataFrame({'k': ['K0', 'K1', 'K1', 'K2'], 'lv': [1, 2, 3, 4], 's': ['a', 'b', 'c', 'd']}) right = pd.DataFrame({'k': ['K1', 'K2', 'K4'], 'rv': [1, 2, 3]}) left k lv s 0 K0 1 a 1 K1 2 b 2 K1 3 c 3 K2 4 d right k rv 0 K1 1 1 K2 2 2 K4 3 pd.merge_ordered(left, right, fill_method='ffill', left_by='s') k lv s rv 0 K0 1.0 a NaN 1 K1 1.0 a 1.0 2 K2 1.0 a 2.0 3 K4 1.0 a 3.0 4 K1 2.0 b 1.0 5 K2 2.0 b 2.0 6 K4 2.0 b 3.0 7 K1 3.0 c 1.0 8 K2 3.0 c 2.0 9 K4 3.0 c 3.0 10 K1 NaN d 1.0 11 K2 4.0 d 2.0 12 K4 4.0 d 3.0 merge_asof merge_asof()在行为上,除了匹配最相近的值而不是相等的值这点外,类似left-join. asof合并可以执行分组合并。除了on键上最接近的匹配之外，这与by键地位相似。 trades = pd.DataFrame({ 'time': pd.to_datetime(['20160525 13:30:00.023', '20160525 13:30:00.038', '20160525 13:30:00.048', '20160525 13:30:00.048', '20160525 13:30:00.048']), 'ticker': ['MSFT', 'MSFT', 'GOOG', 'GOOG', 'AAPL'], 'price': [51.95, 51.95, 720.77, 720.92, 98.00], 'quantity': [75, 155, 100, 100, 100]}, columns=['time', 'ticker', 'price', 'quantity']) quotes = pd.DataFrame({ 'time': pd.to_datetime(['20160525 13:30:00.023', '20160525 13:30:00.023', '20160525 13:30:00.030', '20160525 13:30:00.041', '20160525 13:30:00.048', '20160525 13:30:00.049', '20160525 13:30:00.072', '20160525 13:30:00.075']), 'ticker': ['GOOG', 'MSFT', 'MSFT', 'MSFT', 'GOOG', 'AAPL', 'GOOG', 'MSFT'], 'bid': [720.50, 51.95, 51.97, 51.99, 720.50, 97.99, 720.50, 52.01], 'ask': [720.93, 51.96, 51.98, 52.00, 720.93, 98.01, 720.88, 52.03]}, columns=['time', 'ticker', 'bid', 'ask']) trades time ticker price quantity 0 2016-05-25 13:30:00.023 MSFT 51.95 75 1 2016-05-25 13:30:00.038 MSFT 51.95 155 2 2016-05-25 13:30:00.048 GOOG 720.77 100 3 2016-05-25 13:30:00.048 GOOG 720.92 100 4 2016-05-25 13:30:00.048 AAPL 98.00 100 quotes time ticker bid ask 0 2016-05-25 13:30:00.023 GOOG 720.50 720.93 1 2016-05-25 13:30:00.023 MSFT 51.95 51.96 2 2016-05-25 13:30:00.030 MSFT 51.97 51.98 3 2016-05-25 13:30:00.041 MSFT 51.99 52.00 4 2016-05-25 13:30:00.048 GOOG 720.50 720.93 5 2016-05-25 13:30:00.049 AAPL 97.99 98.01 6 2016-05-25 13:30:00.072 GOOG 720.50 720.88 7 2016-05-25 13:30:00.075 MSFT 52.01 52.03 pd.merge_asof(trades, quotes, on='time', by='ticker') time ticker price quantity bid ask 0 2016-05-25 13:30:00.023 MSFT 51.95 75 51.95 51.96 1 2016-05-25 13:30:00.038 MSFT 51.95 155 51.97 51.98 2 2016-05-25 13:30:00.048 GOOG 720.77 100 720.50 720.93 3 2016-05-25 13:30:00.048 GOOG 720.92 100 720.50 720.93 4 2016-05-25 13:30:00.048 AAPL 98.00 100 NaN NaN pd.merge_asof(trades, quotes, on='time', by='ticker', tolerance=pd.Timedelta('2ms')) time ticker price quantity bid ask 0 2016-05-25 13:30:00.023 MSFT 51.95 75 51.95 51.96 1 2016-05-25 13:30:00.038 MSFT 51.95 155 NaN NaN 2 2016-05-25 13:30:00.048 GOOG 720.77 100 720.50 720.93 3 2016-05-25 13:30:00.048 GOOG 720.92 100 720.50 720.93 4 2016-05-25 13:30:00.048 AAPL 98.00 100 NaN NaN pd.merge_asof(trades, quotes, on='time', by='ticker', tolerance=pd.Timedelta('10ms'), allow_exact_matches=False) time ticker price quantity bid ask 0 2016-05-25 13:30:00.023 MSFT 51.95 75 NaN NaN 1 2016-05-25 13:30:00.038 MSFT 51.95 155 51.97 51.98 2 2016-05-25 13:30:00.048 GOOG 720.77 100 NaN NaN 3 2016-05-25 13:30:00.048 GOOG 720.92 100 NaN NaN 4 2016-05-25 13:30:00.048 AAPL 98.00 100 NaN NaN Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 22:01:13 "},"pandas/MultiIndex.html":{"url":"pandas/MultiIndex.html","title":"复合索引","keywords":"","body":"复合索引 除了常规的索引方式,pandas还可以定义复合索引 import pandas as pd import numpy as np 分层索引 分层/多级索引是非常令人兴奋的，因为它打开了一些非常复杂的数据分析和操作的门，尤其是对于更高维数据的处理。 实质上，它使你能够在诸如Series（1d）和DataFrame（2d）的低维数据结构中存储和操作具有任意数量维度的数据。 创建分层索引 创建分层索引可以使用 pd.MultiIndex.from_tuples 从元祖创建 pd.MultiIndex.from_product当你想要在两个迭代中的每个元素的配对时可以使用 为了方便，可以将数组列表直接传递到Series或DataFrame，以自动构建MultiIndex： arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'], ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']] tuples = list(zip(*arrays)) tuples [('bar', 'one'), ('bar', 'two'), ('baz', 'one'), ('baz', 'two'), ('foo', 'one'), ('foo', 'two'), ('qux', 'one'), ('qux', 'two')] index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second']) index MultiIndex(levels=[['bar', 'baz', 'foo', 'qux'], ['one', 'two']], labels=[[0, 0, 1, 1, 2, 2, 3, 3], [0, 1, 0, 1, 0, 1, 0, 1]], names=['first', 'second']) s = pd.Series(np.random.randn(8), index=index) s first second bar one 1.924541 two -2.127108 baz one 0.417056 two -0.378908 foo one 0.780429 two 1.540210 qux one 0.689353 two 1.101065 dtype: float64 iterables = [['bar', 'baz', 'foo', 'qux'], ['one', 'two']] pd.MultiIndex.from_product(iterables, names=['first', 'second']) MultiIndex(levels=[['bar', 'baz', 'foo', 'qux'], ['one', 'two']], labels=[[0, 0, 1, 1, 2, 2, 3, 3], [0, 1, 0, 1, 0, 1, 0, 1]], names=['first', 'second']) arrays = [np.array(['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux']), np.array(['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two'])] s = pd.Series(np.random.randn(8), index=arrays) s bar one -1.221834 two -0.816061 baz one 0.134687 two 0.143186 foo one 0.990110 two 0.208515 qux one 1.150871 two 0.546428 dtype: float64 df = pd.DataFrame(np.random.randn(8, 4), index=arrays) df 0 1 2 3 bar one -1.690183 0.271540 -0.519416 -0.109875 two 1.144788 0.429944 -0.466847 -0.475691 baz one -1.384935 0.359243 0.443673 0.283476 two -0.922243 -0.731361 0.955463 -0.315289 foo one -0.725888 0.455123 -0.978464 -0.340143 two -0.147488 -0.077069 0.386868 -0.910659 qux one -0.360796 1.773004 -0.088235 0.107931 two -0.107048 0.659507 -0.983554 1.220696 将复合索引应用于列 df = pd.DataFrame(np.random.randn(3, 8), index=['A', 'B', 'C'], columns=index) df first bar baz foo qux second one two one two one two one two A -0.623886 -1.210745 -1.247687 -1.775733 0.071501 -0.559662 -1.227424 0.048207 B 0.539847 1.144010 -0.602236 0.712611 1.933703 0.761082 0.873890 -0.211337 C -0.360050 0.518990 -0.336434 -1.005913 1.455619 -0.156915 -0.131643 -1.106066 MultiIndex的重要性在于，它允许您进行分组，选择和重塑操作，我们将在下面和文档的后续部分中进行描述。正如你将在后面部分看到的，你可以发现自己使用分层索引的数据，而不需要自己创建一个MultiIndex。但是，从文件加载数据时，您可能希望在准备数据集时生成自己的MultiIndex。请注意，如何通过使用pandas.set_printoptions中的multi_sparse选项进行控制来显示索引： pd.set_option('display.multi_sparse', False) df first bar bar baz baz foo foo qux qux second one two one two one two one two A -0.623886 -1.210745 -1.247687 -1.775733 0.071501 -0.559662 -1.227424 0.048207 B 0.539847 1.144010 -0.602236 0.712611 1.933703 0.761082 0.873890 -0.211337 C -0.360050 0.518990 -0.336434 -1.005913 1.455619 -0.156915 -0.131643 -1.106066 pd.set_option('display.multi_sparse', True) 重建级别标签 方法get_level_values将返回特定级别上每个位置的标签的向量 index.get_level_values(0) Index(['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'], dtype='object', name='first') index.get_level_values('second') Index(['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two'], dtype='object', name='second') 使用MultiIndex在轴上进行基本索引 分层索引的一个重要特征是您可以通过标识数据中子组的“部分”标签来选择数据。部分选择“丢弃”层次索引的水平在结果中以一种完全类似的方式选择常规DataFrame中的列： df['bar'] second one two A -0.623886 -1.210745 B 0.539847 1.144010 C -0.360050 0.518990 df['bar', 'one'] A -0.623886 B 0.539847 C -0.360050 Name: (bar, one), dtype: float64 df['bar']['one'] A -0.623886 B 0.539847 C -0.360050 Name: one, dtype: float64 s['qux'] one 1.150871 two 0.546428 dtype: float64 df.columns MultiIndex(levels=[['bar', 'baz', 'foo', 'qux'], ['one', 'two']], labels=[[0, 0, 1, 1, 2, 2, 3, 3], [0, 1, 0, 1, 0, 1, 0, 1]], names=['first', 'second']) df[['foo','qux']].columns MultiIndex(levels=[['bar', 'baz', 'foo', 'qux'], ['one', 'two']], labels=[[2, 2, 3, 3], [0, 1, 0, 1]], names=['first', 'second']) 这样做是为了避免重新计算水平以便使切片具有高性能。如果你想看到实际使用的水平。 df[['foo','qux']].columns.values array([('foo', 'one'), ('foo', 'two'), ('qux', 'one'), ('qux', 'two')], dtype=object) df[['foo','qux']].columns.get_level_values(0) Index(['foo', 'foo', 'qux', 'qux'], dtype='object', name='first') pd.MultiIndex.from_tuples(df[['foo','qux']].columns.values) MultiIndex(levels=[['foo', 'qux'], ['one', 'two']], labels=[[0, 0, 1, 1], [0, 1, 0, 1]]) 数据对齐和使用reindex 在轴上具有多索引的不同索引对象之间的操作将如期望地工作;数据对齐将像元组索引一样工作： s + s[:-2] bar one -2.443668 two -1.632123 baz one 0.269374 two 0.286373 foo one 1.980220 two 0.417029 qux one NaN two NaN dtype: float64 s + s[::2] bar one -2.443668 two NaN baz one 0.269374 two NaN foo one 1.980220 two NaN qux one 2.301741 two NaN dtype: float64 reindex可以用另一个MultiIndex或甚至一个元组的列表或数组调用： s.reindex(index[:3]) first second bar one -1.221834 two -0.816061 baz one 0.134687 dtype: float64 s.reindex([('foo', 'two'), ('bar', 'one'), ('qux', 'one'), ('baz', 'one')]) foo two 0.208515 bar one -1.221834 qux one 1.150871 baz one 0.134687 dtype: float64 高级索引与层次索引 使用.loc / .ix在高级索引中语法集成MultiIndex有点具有挑战性，但我们已尽一切努力这样做。例如下面的工作，你会期望： df = df.T df A B C first second bar one -0.623886 0.539847 -0.360050 two -1.210745 1.144010 0.518990 baz one -1.247687 -0.602236 -0.336434 two -1.775733 0.712611 -1.005913 foo one 0.071501 1.933703 1.455619 two -0.559662 0.761082 -0.156915 qux one -1.227424 0.873890 -0.131643 two 0.048207 -0.211337 -1.106066 df.loc['bar'] A B C second one -0.623886 0.539847 -0.36005 two -1.210745 1.144010 0.51899 df.loc['bar', 'two'] A -1.210745 B 1.144010 C 0.518990 Name: (bar, two), dtype: float64 df.loc['baz':'foo'] A B C first second baz one -1.247687 -0.602236 -0.336434 two -1.775733 0.712611 -1.005913 foo one 0.071501 1.933703 1.455619 two -0.559662 0.761082 -0.156915 你可以通过提供一个元组的切片，使用一个“范围”的值。 df.loc[('baz', 'two'):('qux', 'one')] A B C first second baz two -1.775733 0.712611 -1.005913 foo one 0.071501 1.933703 1.455619 two -0.559662 0.761082 -0.156915 qux one -1.227424 0.873890 -0.131643 df.loc[('baz', 'two'):'foo'] A B C first second baz two -1.775733 0.712611 -1.005913 foo one 0.071501 1.933703 1.455619 two -0.559662 0.761082 -0.156915 传递标签或元组的列表与重建索引类似： df.ix[[('bar', 'two'), ('qux', 'one')]] A B C first second bar two -1.210745 1.14401 0.518990 qux one -1.227424 0.87389 -0.131643 使用swaplevel（）交换级别 df[:5] A B C first second bar one -0.623886 0.539847 -0.360050 two -1.210745 1.144010 0.518990 baz one -1.247687 -0.602236 -0.336434 two -1.775733 0.712611 -1.005913 foo one 0.071501 1.933703 1.455619 df[:5].swaplevel(0, 1, axis=0) A B C second first one bar -0.623886 0.539847 -0.360050 two bar -1.210745 1.144010 0.518990 one baz -1.247687 -0.602236 -0.336434 two baz -1.775733 0.712611 -1.005913 one foo 0.071501 1.933703 1.455619 使用reorder_levels（）重新排序级别 df[:5].reorder_levels([1,0], axis=0) A B C second first one bar -0.623886 0.539847 -0.360050 two bar -1.210745 1.144010 0.518990 one baz -1.247687 -0.602236 -0.336434 two baz -1.775733 0.712611 -1.005913 one foo 0.071501 1.933703 1.455619 CategoricalIndex 我们介绍一个CategoricalIndex，一种新类型的索引对象，用于支持索引与重复。这是围绕分类（在v0.15.0中引入）的容器，并且允许对具有大量重复元素的索引进行有效的索引和存储。在0.16.1之前，使用类别dtype设置DataFrame / Series的索引会将其转换为常规的基于对象的Index。 df = pd.DataFrame({'A': np.arange(6), 'B': list('aabbca')}) df['B'] = df['B'].astype('category', categories=list('cab')) df A B 0 0 a 1 1 a 2 2 b 3 3 b 4 4 c 5 5 a df.dtypes A int32 B category dtype: object df.B.cat.categories Index(['c', 'a', 'b'], dtype='object') 设置索引，将创建一个CategoricalIndex df2 = df.set_index('B') df2.index CategoricalIndex(['a', 'a', 'b', 'b', 'c', 'a'], categories=['c', 'a', 'b'], ordered=False, name='B', dtype='category') df2.loc['a'] A B a 0 a 1 a 5 这些保留了分类索引 df2.loc['a'].index CategoricalIndex(['a', 'a', 'a'], categories=['c', 'a', 'b'], ordered=False, name='B', dtype='category') df2.sort_index() A B c 4 a 0 a 1 a 5 b 2 b 3 索引上的Groupby操作也将保留索引本质 df2.groupby(level=0).sum() A B c 4 a 6 b 5 df2.groupby(level=0).sum().index CategoricalIndex(['c', 'a', 'b'], categories=['c', 'a', 'b'], ordered=False, name='B', dtype='category') 重索引操作将根据传递的索引器的类型返回一个结果索引，这意味着传递一个列表将返回一个普通的索引;使用分类索引将返回CategoricalIndex，根据PASSED分类类型的类别索引。这允许任意索引这些甚至与不在类别中的值，类似于您可以重新索引任何pandas索引。 df2.reindex(['a','e']) A B a 0.0 a 1.0 a 5.0 e NaN df2.reindex(['a','e']).index Index(['a', 'a', 'a', 'e'], dtype='object', name='B') df2.reindex(pd.Categorical(['a','e'],categories=list('abcde'))) A B a 0.0 a 1.0 a 5.0 e NaN Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 22:01:57 "},"pandas/statistical_analysis/statistical_analysis.html":{"url":"pandas/statistical_analysis/statistical_analysis.html","title":"统计分析","keywords":"","body":"统计分析 pandas本身定位是表格工具,算法不是他的主要目标,所以他内置的算法只是坎坎够用,pandas本身依赖numpy,因此numpy有的统计方法他都有,比如观察他的均值方差标准差什么的,本文依然使用iris来作为源数据 import pandas as pd import matplotlib.pyplot as plt %matplotlib inline iris_data = pd.read_csv(\"./source/iris.data\",header = None,encoding = \"utf-8\", names=[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\",\"class\"]) iris_data.describe() sepal_length sepal_width petal_length petal_width count 150.000000 150.000000 150.000000 150.000000 mean 5.843333 3.054000 3.758667 1.198667 std 0.828066 0.433594 1.764420 0.763161 min 4.300000 2.000000 1.000000 0.100000 25% 5.100000 2.800000 1.600000 0.300000 50% 5.800000 3.000000 4.350000 1.300000 75% 6.400000 3.300000 5.100000 1.800000 max 7.900000 4.400000 6.900000 2.500000 可以看到各个列的最常见统计学指标 相关性 numpy只默认支持协方差矩阵的计算 他们都可以带参数min_periods关键字，该关键字为每个列对指定所需的最小观测值数，以获得有效的结果 协方差矩阵 iris_copy = iris_data.copy() iris_cov = iris_copy[iris_copy.columns[:-1]].T.cov() iris_cov[:5] 0 1 2 3 4 5 6 7 8 9 ... 140 141 142 143 144 145 146 147 148 149 0 4.750000 4.421667 4.353333 4.160000 4.696667 4.860000 4.215000 4.595000 3.9650 4.493333 ... 2.650000 3.090000 2.341667 2.730 2.596667 2.850000 2.741667 2.915000 2.475000 2.600000 1 4.421667 4.149167 4.055000 3.885000 4.358333 4.515000 3.907500 4.284167 3.7075 4.210000 ... 2.725000 3.128333 2.409167 2.805 2.661667 2.906667 2.820833 2.955833 2.504167 2.628333 2 4.353333 4.055000 3.990000 3.813333 4.303333 4.453333 3.861667 4.211667 3.6350 4.120000 ... 2.446667 2.850000 2.161667 2.520 2.396667 2.630000 2.531667 2.688333 2.281667 2.396667 3 4.160000 3.885000 3.813333 3.656667 4.110000 4.256667 3.688333 4.031667 3.4850 3.953333 ... 2.493333 2.856667 2.218333 2.580 2.443333 2.653333 2.571667 2.718333 2.321667 2.440000 4 4.696667 4.358333 4.303333 4.110000 4.650000 4.810000 4.175000 4.541667 3.9150 4.433333 ... 2.530000 2.963333 2.238333 2.610 2.483333 2.726667 2.615000 2.798333 2.381667 2.503333 5 rows × 150 columns 皮尔逊相关度 这个可以使用numpy来求了 import numpy as np iris_copy = iris_data.copy() iris_ = iris_copy[iris_copy.columns[:-1]] pd.DataFrame(np.corrcoef(iris_.as_matrix()))[:5] 0 1 2 3 4 5 6 7 8 9 ... 140 141 142 143 144 145 146 147 148 149 0 1.000000 0.995999 0.999974 0.998168 0.999347 0.999586 0.998811 0.999538 0.998077 0.996552 ... 0.597825 0.685581 0.574649 0.584668 0.603048 0.646865 0.605998 0.653473 0.633917 0.633158 1 0.995999 1.000000 0.996607 0.997397 0.992233 0.993592 0.990721 0.997118 0.998546 0.999033 ... 0.657750 0.742643 0.632574 0.642756 0.661387 0.705879 0.667114 0.708983 0.686257 0.684835 2 0.999974 0.996607 1.000000 0.998333 0.999061 0.999377 0.998438 0.999605 0.998356 0.996986 ... 0.602231 0.689931 0.578798 0.588854 0.607300 0.651305 0.610553 0.657556 0.637631 0.636806 3 0.998168 0.997397 0.998333 1.000000 0.996719 0.997833 0.996139 0.999546 0.999833 0.999307 ... 0.641080 0.722377 0.620453 0.629754 0.646729 0.686380 0.647851 0.694538 0.677737 0.677225 4 0.999347 0.992233 0.999061 0.996719 1.000000 0.999883 0.999914 0.998503 0.996031 0.993761 ... 0.576858 0.664510 0.555166 0.564947 0.582896 0.625491 0.584183 0.634029 0.616536 0.616138 5 rows × 150 columns 也可以使用pandas中的corr方法 corr可以使用的算法有: pearson (default)皮尔逊相关系数 kendall Kendall Tau相关系数 spearman 斯皮尔曼等级相关系数 可以使用'method'关键字指定.请注意，非数字列将从相关性计算中自动排除。为了自己看起来明确,要么写好注释,要么就自己手动排除或者处理 iris_T.corr(method='spearman')[:5] --------------------------------------------------------------------------- NameError Traceback (most recent call last) in () ----> 1 iris_T.corr(method='spearman')[:5] NameError: name 'iris_T' is not defined 其他统计方法 Method Description count() Number of non-null observations sum() Sum of values mean() Mean of values median() Arithmetic median of values min() Minimum max() Maximum std() Bessel-corrected sample standard deviation var() Unbiased variance skew() 偏度 kurt() 峰度 quantile() 分位数(百分比作为值参数) apply() Generic apply 窗口函数 对于处理数据，pandas提供了许多窗口函数用于计算公共窗口或滚动统计。 其中包括计数，总和，平均值，中值，相关性，方差，协方差，标准偏差，偏度和峰度。 我们使用rolling,.expanding,ewm 对数据进行相应的处理 这三个函数的用法和groupby很像, 他们的构造函数通常这些方法都有相同的接口。 他们都接受以下参数： window：移动窗口的大小 min_periods：要求非空数据点的阈值（否则结果为NA） center：boolean，是否在中间设置标签（默认为False） axis rolling函数 rolling(window,min_periods,center,axis) s = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000)) s = s.cumsum() s[:5] 2000-01-01 -1.469066 2000-01-02 -1.493505 2000-01-03 -3.071202 2000-01-04 -2.740711 2000-01-05 -3.336262 Freq: D, dtype: float64 r = s.rolling(window=60) r Rolling [window=60,center=False,axis=0] r.mean() 2000-01-01 NaN 2000-01-02 NaN 2000-01-03 NaN 2000-01-04 NaN 2000-01-05 NaN 2000-01-06 NaN 2000-01-07 NaN 2000-01-08 NaN 2000-01-09 NaN 2000-01-10 NaN 2000-01-11 NaN 2000-01-12 NaN 2000-01-13 NaN 2000-01-14 NaN 2000-01-15 NaN 2000-01-16 NaN 2000-01-17 NaN 2000-01-18 NaN 2000-01-19 NaN 2000-01-20 NaN 2000-01-21 NaN 2000-01-22 NaN 2000-01-23 NaN 2000-01-24 NaN 2000-01-25 NaN 2000-01-26 NaN 2000-01-27 NaN 2000-01-28 NaN 2000-01-29 NaN 2000-01-30 NaN ... 2002-08-28 46.641130 2002-08-29 46.733553 2002-08-30 46.801611 2002-08-31 46.899215 2002-09-01 47.016365 2002-09-02 47.088110 2002-09-03 47.147598 2002-09-04 47.200116 2002-09-05 47.257776 2002-09-06 47.335399 2002-09-07 47.402138 2002-09-08 47.416653 2002-09-09 47.402354 2002-09-10 47.377841 2002-09-11 47.358784 2002-09-12 47.339613 2002-09-13 47.287782 2002-09-14 47.239256 2002-09-15 47.219807 2002-09-16 47.201183 2002-09-17 47.142999 2002-09-18 47.060706 2002-09-19 47.029424 2002-09-20 46.995019 2002-09-21 46.961195 2002-09-22 46.952758 2002-09-23 46.961190 2002-09-24 46.940297 2002-09-25 46.935238 2002-09-26 46.923563 Freq: D, dtype: float64 s.plot() r.mean().plot(style='k') df = pd.DataFrame(np.random.randn(1000, 4), index=pd.date_range('1/1/2000', periods=1000), columns=['A', 'B', 'C', 'D']) df = df.cumsum() df.rolling(window=60).sum().plot(subplots=True) df.plot(subplots=True) array([, , , ], dtype=object) 使用自定义的方法 s.rolling(window=60)\\ .apply(lambda x: np.fabs(x - x.mean()).mean())\\ .plot(style='k') rolling有一个特有关键字win_type 它表示窗口的类型, 公认类型有: boxcar triang blackman hamming bartlett parzen bohman blackmanharris nuttall barthann kaiser (需要beta参数) gaussian (需要std参数) general_gaussian (需要 power, width参数) slepian (需要width参数). ser = pd.Series(np.random.randn(10), index=pd.date_range('1/1/2000', periods=10)) ser.rolling(window=5, win_type='triang').mean() 2000-01-01 NaN 2000-01-02 NaN 2000-01-03 NaN 2000-01-04 NaN 2000-01-05 0.241423 2000-01-06 0.554305 2000-01-07 0.879226 2000-01-08 0.802116 2000-01-09 0.600150 2000-01-10 0.049508 Freq: D, dtype: float64 ser.rolling(window=5, win_type='boxcar').mean() 2000-01-01 NaN 2000-01-02 NaN 2000-01-03 NaN 2000-01-04 NaN 2000-01-05 0.430083 2000-01-06 0.543986 2000-01-07 0.612879 2000-01-08 0.790742 2000-01-09 0.600822 2000-01-10 -0.150064 Freq: D, dtype: float64 ser.rolling(window=5, win_type='gaussian').mean(std=0.1) 2000-01-01 NaN 2000-01-02 NaN 2000-01-03 NaN 2000-01-04 NaN 2000-01-05 -0.345494 2000-01-06 0.117715 2000-01-07 2.378884 2000-01-08 -0.026842 2000-01-09 0.940132 2000-01-10 0.543824 Freq: D, dtype: float64 时间感知滚动 这对于非规则的时间频率指数特别有用。第一个参数使用字符串表示时间间隔即可 dft = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]}, index=pd.date_range('20130101 09:00:00', periods=5, freq='s')) dft B 2013-01-01 09:00:00 0.0 2013-01-01 09:00:01 1.0 2013-01-01 09:00:02 2.0 2013-01-01 09:00:03 NaN 2013-01-01 09:00:04 4.0 dft.rolling('2s').sum() B 2013-01-01 09:00:00 0.0 2013-01-01 09:00:01 1.0 2013-01-01 09:00:02 3.0 2013-01-01 09:00:03 2.0 2013-01-01 09:00:04 4.0 计算窗口的cov() 和 corr() 在金融数据分析和其他领域中，通常对于时间序列的集合计算协方差和相关矩阵。通常，人们也对移动窗协方差和相关矩阵感兴趣。这可以通过传递 pairwise 关键字参数来实现，在DataFrame输入的情况下，将产生一个Panel，其中的 items 是有问题的日期。在单个DataFrame参数的情况下，成对参数甚至可以省略： df2 = df[:20] df2.rolling(window=5).corr(df2['B']) A B C D 2000-01-01 NaN NaN NaN NaN 2000-01-02 NaN NaN NaN NaN 2000-01-03 NaN NaN NaN NaN 2000-01-04 NaN NaN NaN NaN 2000-01-05 -0.988134 1.0 -0.509080 -0.044348 2000-01-06 -0.971898 1.0 -0.267032 -0.140462 2000-01-07 -0.614334 1.0 -0.248780 -0.932933 2000-01-08 -0.164408 1.0 0.333629 -0.705022 2000-01-09 0.588439 1.0 0.461840 -0.424914 2000-01-10 -0.089130 1.0 0.613644 -0.502755 2000-01-11 -0.404701 1.0 0.817422 -0.617821 2000-01-12 -0.306358 1.0 0.947502 -0.482659 2000-01-13 0.162125 1.0 0.722880 0.765848 2000-01-14 0.921286 1.0 -0.163586 0.728886 2000-01-15 0.936731 1.0 -0.898769 0.799872 2000-01-16 0.921981 1.0 -0.622629 0.715288 2000-01-17 0.852761 1.0 -0.510544 0.748616 2000-01-18 0.706772 1.0 -0.125578 0.506575 2000-01-19 -0.383707 1.0 -0.041564 0.370664 2000-01-20 -0.740382 1.0 0.229220 0.140201 covs = df[['B','C','D']].rolling(window=50).cov(df[['A','B','C']], pairwise=True) covs[df.index[-50]] A B C B -5.131780 5.522610 -0.344374 C 1.051719 -0.344374 2.804096 D 1.841796 0.252558 1.139038 correls = df.rolling(window=50).corr() correls[df.index[-50]] A B C D A 1.000000 -0.617498 0.177600 0.330833 B -0.617498 1.000000 -0.087511 0.068268 C 0.177600 -0.087511 1.000000 0.432085 D 0.330833 0.068268 0.432085 1.000000 correls.loc[:, 'A', 'C'].plot() 使用aggregate聚合 这个操作和groupby那个聚合非常类似,构建窗口后通过一系列算法获得了各窗口的值,我们可以通过传递一个函数到整个DataFrame 也可以用agg()一次应用多个function dfa = pd.DataFrame(np.random.randn(1000, 3), index=pd.date_range('1/1/2000', periods=1000), columns=['A', 'B', 'C']) r = dfa.rolling(window=60,min_periods=1) r.aggregate(np.sum)[:10] A B C 2000-01-01 -0.381921 0.197892 -0.387883 2000-01-02 -1.283849 0.631795 -0.984351 2000-01-03 -0.561875 0.727460 -0.631296 2000-01-04 -0.677190 2.377584 -0.764575 2000-01-05 -0.892768 1.747055 -0.672681 2000-01-06 -2.100031 2.234710 -1.314329 2000-01-07 -1.458504 3.485393 -0.673807 2000-01-08 -1.001579 3.055856 -1.339435 2000-01-09 -0.189259 4.399352 -0.788718 2000-01-10 0.603671 4.577256 -0.705698 r['A'].agg([np.sum, np.mean, np.std])[:10] sum mean std 2000-01-01 -0.381921 -0.381921 NaN 2000-01-02 -1.283849 -0.641925 0.367700 2000-01-03 -0.561875 -0.187292 0.829262 2000-01-04 -0.677190 -0.169298 0.678045 2000-01-05 -0.892768 -0.178554 0.587569 2000-01-06 -2.100031 -0.350005 0.672729 2000-01-07 -1.458504 -0.208358 0.719433 2000-01-08 -1.001579 -0.125197 0.706377 2000-01-09 -0.189259 -0.021029 0.730929 2000-01-10 0.603671 0.060367 0.735628 r['A'].agg({'result1' : np.sum,'result2' : np.mean})[:10] result1 result2 2000-01-01 -0.381921 -0.381921 2000-01-02 -1.283849 -0.641925 2000-01-03 -0.561875 -0.187292 2000-01-04 -0.677190 -0.169298 2000-01-05 -0.892768 -0.178554 2000-01-06 -2.100031 -0.350005 2000-01-07 -1.458504 -0.208358 2000-01-08 -1.001579 -0.125197 2000-01-09 -0.189259 -0.021029 2000-01-10 0.603671 0.060367 r.agg([np.sum, np.mean])[:10] A B C sum mean sum mean sum mean 2000-01-01 -0.381921 -0.381921 0.197892 0.197892 -0.387883 -0.387883 2000-01-02 -1.283849 -0.641925 0.631795 0.315897 -0.984351 -0.492176 2000-01-03 -0.561875 -0.187292 0.727460 0.242487 -0.631296 -0.210432 2000-01-04 -0.677190 -0.169298 2.377584 0.594396 -0.764575 -0.191144 2000-01-05 -0.892768 -0.178554 1.747055 0.349411 -0.672681 -0.134536 2000-01-06 -2.100031 -0.350005 2.234710 0.372452 -1.314329 -0.219055 2000-01-07 -1.458504 -0.208358 3.485393 0.497913 -0.673807 -0.096258 2000-01-08 -1.001579 -0.125197 3.055856 0.381982 -1.339435 -0.167429 2000-01-09 -0.189259 -0.021029 4.399352 0.488817 -0.788718 -0.087635 2000-01-10 0.603671 0.060367 4.577256 0.457726 -0.705698 -0.070570 expanding函数 expanding(window,min_periods,center,axis) 滚动统计的一个常见替代方法是使用扩展窗口，该窗口产生具有到达该时间点之前可用的所有数据的统计的值。 他的接口接近.rolling的接口，.expanding方法返回一个Expanding对象。我们可以对比下一下两个函数,他们是等效的 df.rolling(window=len(df), min_periods=1).mean()[:5] A B C D 2000-01-01 0.229987 -1.887123 0.039168 0.058430 2000-01-02 -0.235200 -1.471578 -0.230086 -0.237068 2000-01-03 -0.784645 -0.965294 -0.766004 -0.240188 2000-01-04 -1.142385 -0.637957 -0.714035 -0.266348 2000-01-05 -1.151739 -0.567396 -0.556405 -0.068604 df.expanding(min_periods=1).mean()[:5] A B C D 2000-01-01 0.229987 -1.887123 0.039168 0.058430 2000-01-02 -0.235200 -1.471578 -0.230086 -0.237068 2000-01-03 -0.784645 -0.965294 -0.766004 -0.240188 2000-01-04 -1.142385 -0.637957 -0.714035 -0.266348 2000-01-05 -1.151739 -0.567396 -0.556405 -0.068604 s.plot(style='k--') s.expanding().mean().plot(style='k') 指数加权窗口ewm ewm是几个上述统计量的指数加权版本。 他支持的默认方法比较少 Function Description mean() EW moving average var() EW moving variance std() EW moving standard deviation corr() EW moving correlation cov() EW moving covariance s.plot(style='k--') s.ewm(span=20).mean().plot(style='k') Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 22:03:30 "},"pandas/Visualization/Visualization.html":{"url":"pandas/Visualization/Visualization.html","title":"数据可视化","keywords":"","body":"数据可视化 pandas针对表格数据有对matplotlib的封装,通过polt()方法可以方便的绘制图形 import pandas as pd import numpy as np import matplotlib import matplotlib.pyplot as plt matplotlib.style.use('ggplot') %matplotlib inline 基本绘图 最基础的绘图就是为序列绘图polt()了 我们以随机游走模拟股市行情 如果索引由日期组成，它将调用gcf().autofmt_xdate()来尝试按索引(index)的格式格式化x轴。 ps:累积和(cumsum) S_0=0 \\\\ S_{n+1}=\\max(0, S_n+x_n-\\omega_n) 用以在某个相对稳定的数据序列中，检测出开始发生异常的数据点。所谓异常的数据点，比如说，从这点开始，整个数列的平均值或者均方差开始发生改变，进而影响到整组数据的稳定。所以累积和最典型的应用是在“改变检测”（Change Detection）中对参量变化的检测。由于累积和管制法能充分利用数据变化之顺序与大小,故相当适合用于侦测制程的微量变化(small shifts) 这边使用累积和用来获得当天的值 ts_o = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2016', periods=1000)) ts = ts_o.cumsum()# 累积和 ts[:5] 2016-01-01 -0.943073 2016-01-02 0.645978 2016-01-03 -0.162719 2016-01-04 -0.593420 2016-01-05 -1.552354 Freq: D, dtype: float64 ts.plot() 如果是针对的df,那么它会按列分别绘制图形.它会自动用不同颜色来区分 df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=list('ABCD')) df = df.cumsum() df[:5] A B C D 2016-01-01 1.768804 -1.509527 -1.630513 -0.407891 2016-01-02 1.631288 0.145392 -1.067315 -1.405604 2016-01-03 1.153486 -0.335480 -1.320116 -2.216602 2016-01-04 0.916897 -1.356709 -1.410290 -1.637204 2016-01-05 1.472524 -1.381097 -2.646981 -1.246137 df.plot() 指定x轴y轴 df3 = pd.DataFrame(np.random.randn(1000, 2), columns=['B', 'C']).cumsum() df3['A'] = pd.Series(list(range(len(df)))) df3[:5] B C A 0 -0.487310 1.489582 0 1 0.018866 2.249854 1 2 1.536721 0.929395 2 3 2.390767 -0.671159 3 4 4.575829 -2.713449 4 df3.plot(x='A', y='B') 图形设置 和在matplotlib中一样,我们可以设置style,label,color等,如 style='k--', label='Series','legend=False' plot的完整接口如下: .plot(x=None, y=None, kind='line', ax=None, subplots=False, sharex=None, sharey=False, layout=None, figsize=None, use_index=True, title=None, grid=None, legend=True, style=None, logx=False, logy=False, loglog=False, xticks=None, yticks=None, xlim=None, ylim=None, rot=None, fontsize=None, colormap=None, table=False, yerr=None, xerr=None, secondary_y=False, sort_columns=False, 其中 legend表示用户不用图例 logy 表示是否使用对数标度Y轴 secondary_y表示是否使用第二根y轴,这常在有两个图形在同一张图中时用 subplots=True和figsize=(x,x)配合用于绘制子图 子图的布局可以通过layout关键字指定。它可以接受（行，列）。 layout关键字也可以在hist和boxplot中使用。如果输入无效，将引发ValueError。由布局指定的行x列可包含的轴数必须大于所需子图的数量。如果布局可以包含比所需更多的轴，则不绘制空白轴。与numpy数组的重塑方法类似，对于一个维度，您可以使用-1自动计算所需的行数或列数，而另一个维度。比如plot(subplots=True, layout=(2, 3), figsize=(6, 6), sharex=False) 使用table=True绘制表格 df3.plot(x='A', y='B',style='k--', label='Series') Colormaps 绘制大量列时的潜在问题是，由于默认颜色的重复，可能难以区分某些系列。为了解决这个问题，DataFrame绘图支持使用colormap =参数，它接受一个Matplotlib色彩映射或一个字符串，它是用Matplotlib注册的色彩映射的名称。默认的matplotlib色彩图可以在matplotlib的cm模块中找到,同时cm模块中的对象也可以作为输入参数 from matplotlib import cm df_color = pd.DataFrame(np.random.randn(1000, 10), index=ts.index) df_color = df_color.cumsum() df_color.plot(colormap='cubehelix') accent df_color.plot(colormap=cm.cubehelix) 绘制带errorbar的图形 ix_err = pd.MultiIndex.from_arrays([['a', 'a', 'a', 'a', 'b', 'b', 'b', 'b'], ['foo', 'foo', 'bar', 'bar', 'foo', 'foo', 'bar', 'bar']], names=['letter', 'word']) df_err = pd.DataFrame({'data1': [3, 2, 4, 3, 2, 4, 3, 2], 'data2': [6, 5, 7, 5, 4, 5, 6, 5]}, index=ix_err) gp_err = df_err.groupby(level=('letter', 'word')) means = gp_err.mean() errors = gp_err.std() means data1 data2 letter word a bar 3.5 6.0 foo 2.5 5.5 b bar 2.5 5.5 foo 3.0 4.5 errors data1 data2 letter word a bar 0.707107 1.414214 foo 0.707107 0.707107 b bar 0.707107 0.707107 foo 1.414214 0.707107 fig, ax = plt.subplots() means.plot.bar(yerr=errors, ax=ax) 额外的绘图工具 pandas.tools.plotting模块中还提供了另外几个绘图工具 散点矩阵图scatter_matrix from pandas.tools.plotting import scatter_matrix df1 = pd.DataFrame(np.random.randn(1000, 4), columns=['a', 'b', 'c', 'd']) scatter_matrix(df1, alpha=0.2, figsize=(6, 6), diagonal='kde') array([[, , , ], [, , , ], [, , , ], [, , , ]], dtype=object) 安德鲁斯曲线 安德鲁斯曲线允许将多变量数据绘制为使用样本的属性创建的大量曲线作为傅里叶级数的系数。通过为每个类不同地着色这些曲线，可以可视化数据聚类。属于相同类别的样品的曲线通常更靠近在一起并形成更大的结构。 以iris为例 from pandas.tools.plotting import andrews_curves iris = pd.read_csv('source/iris.csv') iris[:5] sepal_length sepal_width petal_length petal_width class 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa andrews_curves(iris, 'class') 平行坐标parallel_coordinates 平行坐标是绘制多变量数据的绘图技术。它允许人们看到数据中的簇，并可视地估计其他统计量。使用平行坐标点表示为连接的线段。每个垂直线表示一个属性。一组连接的线段表示一个数据点。倾向于聚类的点将更靠近在一起。 from pandas.tools.plotting import parallel_coordinates parallel_coordinates(iris, 'class') RadViz图 RadViz是一种可视化多变量数据的方法。它基于简单的弹簧张力最小化算法(spring tension minimization algorithm)。基本上你在画板上设置了一堆点。在我们的例子中，它们在单位圆上等间隔。每个点表示单个属性。然后假设数据集中的每个样本都通过弹簧附加到这些点中的每一个上，其刚度与该属性的数值成比例（它们被归一化为单位间隔）。在平面中我们的样本沉降的点（其中作用在我们的样本上的力处于平衡）是表示我们的样本的点将被绘制的点。根据样本属于哪个类别，它将有不同的颜色。 from pandas.tools.plotting import radviz radviz(iris, 'class') 滞后图 滞后图用于检查数据集或时间序列是否是随机的。随机数据在滞后图中不应显示任何结构。非随机结构意味着底层数据不是随机的。 from pandas.tools.plotting import lag_plot unr = pd.Series(0.1 * np.random.rand(1000) + 0.9 * np.sin(np.linspace(-99 * np.pi, 99 * np.pi, num=1000))) lag_plot(unr) lag_plot(ts) lag_plot(ts_o)#随机 自相关图autocorrelation_plot 自相关图通常用于检查时间序列中的随机性。这是通过计算在不同时间滞后的数据值的自相关来完成的。如果时间序列是随机的，对于任何和时间滞后分离，这种自相关应该接近零。如果时间序列是非随机的，则一个或多个自相关将显着地非零。图中显示的水平线对应于95％和99％置信带。虚线是99％置信带。 from pandas.tools.plotting import autocorrelation_plot data_autocorrelation = pd.Series(0.7 * np.random.rand(1000) + 0.3 * np.sin(np.linspace(-9 * np.pi, 9 * np.pi, num=1000))) autocorrelation_plot(data_autocorrelation) 引导图bootstrap_plot 引导图用于视觉评估统计量的不确定性，例如平均值，中值，中等范围等。从数据集中选择指定大小的随机子集，针对该子集计算所讨论的统计量，并且该过程是根据指定次数重复的。图形和直方图的结果构成了引导图。 from pandas.tools.plotting import bootstrap_plot data_bootstrap = pd.Series(np.random.rand(1000)) bootstrap_plot(data_bootstrap, size=50, samples=500, color='grey') 常见统计图 除了折线图,当然还有常见统计图形比如栅栏图,直方图,饼图,箱图了 绘制这些图形最简单的方式就是使用plot.()方法了,他可以在一副图中绘制出想要的内容 使用缺失数据绘制 Pandas试图做实用的可以绘制包含缺失数据的DataFrames或Series的图形。它会默认的根据绘图类型，丢弃，舍弃或填充缺失值。当然更好的方式是先处理缺失值再绘图 Plot Type NaN Handling Line 在NaNs处留下空隙 Line (stacked) 用0填充 Bar 用0填充 Scatter 删除Nan Histogram 删除Nan Box 删除Nan Area 用0填充 KDE 删除Nan Hexbin 删除Nan Pie 用0填充 绘制图表table from pandas.tools.plotting import table df_table = pd.DataFrame(np.random.rand(5, 3), columns=['a', 'b', 'c']) df_table a b c 0 0.907814 0.577342 0.972353 1 0.040087 0.499157 0.191772 2 0.474351 0.452796 0.955516 3 0.872288 0.324289 0.467717 4 0.045308 0.264322 0.081304 fig, ax = plt.subplots(1, 1) table(ax, np.round(df_table.describe(), 2), loc='upper right', colWidths=[0.2, 0.2, 0.2]) df_table.plot(ax=ax, ylim=(0, 2), legend=None) 散点图scatter 观察两组数据的特点最好的方法就是使用散点图 df_scatter = pd.DataFrame(np.random.rand(50, 4), columns=['a', 'b', 'c', 'd']) df_scatter.plot.scatter(x='a', y='b'); 散点分组 ax = df_scatter.plot.scatter(x='a', y='b', color='DarkBlue', label='Group 1') df_scatter.plot.scatter(x='c', y='d', color='DarkGreen', label='Group 2', ax=ax) 使用灰度区分组 df_scatter.plot.scatter(x='a', y='b', c='c', s=50) 使用点的大小来区分组别 df_scatter.plot.scatter(x='a', y='b', s=df_scatter['c']*200) 散点密度图kde ser = pd.Series(np.random.randn(1000)) ser.plot.kde() 六边形图hexbin 如果您的数据太密集，则Hexbin图可能是散点图的有用替代方法，无法单独绘制每个点。 df_hexbin = pd.DataFrame(np.random.randn(1000, 2), columns=['a', 'b']) df_hexbin['b'] = df_hexbin['b'] + np.arange(1000) df_hexbin[:5] a b 0 0.408026 -0.811502 1 -0.587273 0.383572 2 2.415451 3.996042 3 1.264680 2.171141 4 2.843472 3.536401 df_hexbin.plot.hexbin(x='a', y='b', gridsize=25) 一个有用的关键字参数是gridsize;它控制x方向上的六边形数量，默认为100.较大的网格尺寸意味着更多，更小的箱柜(bin). 默认情况下，计算每个（x，y）点周围的计数的直方图。您可以通过将值传递给C和reduce_C_function参数来指定备用聚合。 C指定每个（x，y）点的值，reduce_C_function是一个参数的函数，将bin中的所有值减少为单个数字(例如mean，max，sum，std).在该示例中，位置由列a和b给出，而值由列z给出.bin是用numpy的max函数聚合的. df_hexbin = pd.DataFrame(np.random.randn(1000, 2), columns=['a', 'b']) df_hexbin['b'] = df_hexbin['b'] = df_hexbin['b'] + np.arange(1000) df_hexbin['z'] = np.random.uniform(0, 3, 1000) df_hexbin.plot.hexbin(x='a', y='b', C='z', reduce_C_function=np.max,gridsize=25) 栅栏图bar df.ix[5].plot.bar() plt.figure() df.ix[5].plot(kind='bar') plt.axhline(0, color='k') plt.show() df2 = pd.DataFrame(np.random.rand(10, 4), columns=['a', 'b', 'c', 'd']) df2.plot.bar(); df2.plot.bar(stacked=True) 橫置的栅栏图barh df2.plot.barh(stacked=True) 直方图hist 直方图常用来体现不同区间的分布情况 df4 = pd.DataFrame({'a': np.random.randn(1000) + 1, 'b': np.random.randn(1000), 'c': np.random.randn(1000) - 1}, columns=['a', 'b', 'c']) df4[:5] a b c 0 2.098046 0.700889 -1.788784 1 2.478216 -1.295595 -2.413717 2 0.309454 0.795296 -1.801240 3 0.186927 -1.212297 -0.716213 4 -0.196420 -0.072681 -1.323029 df4.plot.hist(alpha=0.5) df4.plot.hist(stacked=True, bins=20) 您可以传递由matplotlib hist支持的其他关键字。例如，水平和累积的histgram可以通过orientation ='horizontal'和cumulative ='True'绘制。 df4['a'].plot.hist(orientation='horizontal', cumulative=True) df.diff().hist(color='k', alpha=0.5, bins=50) array([[, ], [, ]], dtype=object) data = pd.Series(np.random.randn(1000)) data.hist(by=np.random.randint(0, 4, 1000), figsize=(6, 4)) array([[, ], [, ]], dtype=object) 箱图 箱图是直方图的进化,可以更好的观察不同组别的统计学分布情况 df = pd.DataFrame(np.random.rand(10, 5), columns=['A', 'B', 'C', 'D', 'E']) df A B C D E 0 0.530801 0.879414 0.746797 0.769493 0.268179 1 0.879360 0.067813 0.834677 0.123594 0.004283 2 0.746788 0.239194 0.459012 0.197933 0.022791 3 0.673286 0.937733 0.746696 0.128579 0.905100 4 0.424843 0.606296 0.218359 0.800959 0.175384 5 0.121017 0.558144 0.954226 0.585608 0.772449 6 0.281973 0.599172 0.485583 0.793592 0.833444 7 0.696017 0.876120 0.009563 0.142212 0.747473 8 0.777619 0.834691 0.816196 0.038078 0.518234 9 0.252343 0.666446 0.248015 0.023385 0.592396 df.plot.box() Boxplot可以通过传递color关键字来着色。你可以传递一个dict，它的键是box，whiskers，medians和caps。如果dict中缺少某些键，则默认颜色用于相应的艺术家。此外，boxplot有sym关键字来指定传单风格。当你通过color关键字传递其他类型的参数时，它将直接传递给matplotlib用于所有框，whiskers，medians和caps的着色。颜色应用于每个要绘制的框。如果你想要更复杂的着色，你可以通过传递return_type来获得每个绘制的艺术家。 color = dict(boxes='DarkGreen', whiskers='DarkOrange', medians='DarkBlue', caps='Gray') df.plot.box(color=color, sym='r+') df.plot.box(vert=False, positions=[1, 4, 5, 6, 8]) df = pd.DataFrame(np.random.rand(10,5)) bp = df.boxplot() 您可以使用by关键字参数创建分层箱形图以创建分组。 df = pd.DataFrame(np.random.rand(10,2), columns=['Col1', 'Col2'] ) df['X'] = pd.Series(['A','A','A','A','A','B','B','B','B','B']) bp = df.boxplot(by='X') 您还可以传递要绘制的列的子集，以及按多个列分组 df = pd.DataFrame(np.random.rand(10,3), columns=['Col1', 'Col2', 'Col3']) df['X'] = pd.Series(['A','A','A','A','A','B','B','B','B','B']) df['Y'] = pd.Series(['A','B','A','B','A','B','A','B','A','B']) bp = df.boxplot(column=['Col1','Col2'], by=['X','Y']) Groupby.boxplot总是返回一系列return_type。 np.random.seed(1234) df_box = pd.DataFrame(np.random.randn(50, 2)) df_box['g'] = np.random.choice(['A', 'B'], size=50) df_box.loc[df_box['g'] == 'B', 1] += 3 bp = df_box.boxplot(by='g') bp = df_box.groupby('g').boxplot() 面积图area 面积图强调数量随时间而变化的程度，也可用于引起人们对总值趋势的注意。例如，表示随时间而变化的利润的数据可以绘制在面积图中以强调总利润 df = pd.DataFrame(np.random.rand(10, 4), columns=['a', 'b', 'c', 'd']) df.plot.area() df.plot.area(stacked=False); 饼图Pie 饼图常用在直观的观察比例 series = pd.Series(3 * np.random.rand(4), index=['a', 'b', 'c', 'd'], name='series') series.plot.pie(figsize=(6, 6)) 对于饼图，最好使用正方形的数字，一个具有相等的宽高比。您可以创建具有相等宽度和高度的图形，或者在绘制后通过在返回的轴对象上调用ax.set_aspect（'equal'）来强制长宽比相等。请注意，使用DataFrame的饼图需要您通过y参数指定目标列，或者subplots = True。指定y时，将绘制所选列的饼图。如果指定了subplots = True，则每个列的饼图将绘制为子图。默认情况下，每个饼图中将绘制一个图例;指定legend = False以隐藏它。 df = pd.DataFrame(3 * np.random.rand(4, 2), index=['a', 'b', 'c', 'd'], columns=['x', 'y']) df.plot.pie(subplots=True, figsize=(8, 4)) array([, ], dtype=object) 如果要隐藏楔形标签，请指定labels = None。 如果指定fontsize，该值将应用于楔形标签。 此外，可以使用由matplotlib.pyplot.pie（）支持的其他关键字。 series.plot.pie(labels=['AA', 'BB', 'CC', 'DD'], colors=['r', 'g', 'b', 'c'],autopct='%.2f', fontsize=20, figsize=(6, 6)) 如果传递总和小于1.0的值，则matplotlib绘制一个半圆 series = pd.Series([0.1] * 4, index=['a', 'b', 'c', 'd'], name='series2') series.plot.pie(figsize=(6, 6)) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 22:05:02 "},"pandas/data_procurement.html":{"url":"pandas/data_procurement.html","title":"数据获取与保存","keywords":"","body":"数据获取与保存 数据的来源途径无非几种 从网上直接爬取,这个属于写爬虫,不是本文范围 从原生的Python数据结构中获取 从json中获取 数据库中调取, 从excel中读取, 从csv文本文件中获得. 通过pickle序列化数据 而存储数据也无非以下几种方式: 通过pickle序列化数据 保存为json 保存到数据库 保存为excel 保存为csv pandas针对上面的每种获取途径,都提供了方便的获取方式 import pandas as pd 从原生Python数据结构中获取 从二维列表转换 pandas可以将二维列表以表格的形式组合 names = ['Bob','Jessica','Mary','John','Mel'] births = [1968, 1955, 1977,1978, 1973] weight = [69,89,76,90,78] table_o = list(zip(names,births,weight)) table_o [('Bob', 1968, 69), ('Jessica', 1955, 89), ('Mary', 1977, 76), ('John', 1978, 90), ('Mel', 1973, 78)] pd.DataFrame(table_o,columns =[\"name\",\"births\",\"weight\"])# columns指定列标签 name births weight 0 Bob 1968 69 1 Jessica 1955 89 2 Mary 1977 76 3 John 1978 90 4 Mel 1973 78 从字典中直接生成 pandas也允许将数据放在字典内,这样key是每列的标题,value就会按顺序填入 table_dict = {\"names\":['Bob','Jessica','Mary','John','Mel'], \"births\":[1968, 1955, 1977,1978, 1973], \"weight\":[69,89,76,90,78] } table_dict {'births': [1968, 1955, 1977, 1978, 1973], 'names': ['Bob', 'Jessica', 'Mary', 'John', 'Mel'], 'weight': [69, 89, 76, 90, 78]} pd.DataFrame(table_dict) births names weight 0 1968 Bob 69 1 1955 Jessica 89 2 1977 Mary 76 3 1978 John 90 4 1973 Mel 78 从包裹字典的列表中获取 另一种则是按行获取,每个字典是表格中的一行 table_row = [{\"names\":'Bob', \"births\":1968, \"weight\":69 }, {\"names\":'Jessica', \"births\":1955, \"weight\":89 }, {\"names\":'Mary', \"births\":1977, \"weight\":76 }, {\"names\":'John', \"births\":1978, \"weight\":90 }, {\"names\":'Mel', \"births\": 1973, \"weight\":78 }] table_row [{'births': 1968, 'names': 'Bob', 'weight': 69}, {'births': 1955, 'names': 'Jessica', 'weight': 89}, {'births': 1977, 'names': 'Mary', 'weight': 76}, {'births': 1978, 'names': 'John', 'weight': 90}, {'births': 1973, 'names': 'Mel', 'weight': 78}] pd.DataFrame(table_row) births names weight 0 1968 Bob 69 1 1955 Jessica 89 2 1977 Mary 76 3 1978 John 90 4 1973 Mel 78 从csv文件中读取和保存 所谓csv文件是指使用特定符号分隔数据属性,换行分隔不同数据的文本文件. 这次的例子我们主要用的数据便来自于此. 我们惯例的用iris来作为是数据集.下载后放入./source/ 让我先看看该数据是什么样子 with open(\"./source/iris.data\") as f: print(f.readline()) 5.1,3.5,1.4,0.2,Iris-setosa 在看看各个列代表的意思吧 with open(\"./source/iris.names\",\"r\") as names: lines = names.readlines() print(\"\".join(lines[49:58])) 7. Attribute Information: 1. sepal length in cm 2. sepal width in cm 3. petal length in cm 4. petal width in cm 5. class: -- Iris Setosa -- Iris Versicolour -- Iris Virginica 可见它没有头部说明,所以我们这样读取该文件: iris_data = pd.read_csv(\"./source/iris.data\",header = None,encoding = \"utf-8\", names=[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\",\"class\"]) iris_data[:5]#取前5行 sepal_length sepal_width petal_length petal_width class 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa 保存到csv pd.DataFrame(table_row).to_csv(\"source/people.csv\",index=False) iris_data.to_csv(\"source/iris.csv\",index=False)# 记得不要把序号写进去 new_iris_data = pd.read_csv(\"source/iris.csv\") new_iris_data[:5] sepal_length sepal_width petal_length petal_width class 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa 从json中获取和保存 先随便来个json格式的文件,我们就自己写个例子people.json为例好了,该文件放在./data/文件夹下,看下内容: with open(\"./source/people.json\") as f: print(f.readline()) [{\"name\":\"Michael\"},{\"name\":\"Andy\", \"age\":30},{\"name\":\"Justin\", \"age\":19}] people_from_jsonfile = pd.read_json(\"./source/people.json\") people_from_jsonfile age name 0 NaN Michael 1 30.0 Andy 2 19.0 Justin 保存为json 要保存为json格式,也只需要是用to_json方法即可 people_from_jsonfile.to_json() '{\"age\":{\"0\":null,\"1\":30.0,\"2\":19.0},\"name\":{\"0\":\"Michael\",\"1\":\"Andy\",\"2\":\"Justin\"}}' people_from_jsonfile.to_json(\"./source/people_cp.json\") new_peoplefrom_jsonfile = pd.read_json(\"./source/people_cp.json\") new_peoplefrom_jsonfile age name 0 NaN Michael 1 30.0 Andy 2 19.0 Justin 数据库中读取 (需要SQLAlchemy库)和保存 我们以python自带的sqlite3来作测试 先创建一个数据库,还是用我们的people.json中的数据,如何制作具体看 制作好的people.db依然放在./source文件夹下 from sqlalchemy import create_engine conn = create_engine(\"sqlite:///source/people.db\") conn Engine(sqlite:///source/people.db) 读取数据库中的表 people_from_db = pd.read_sql('people', conn) people_from_db name age 0 Michael NaN 1 Andy 30.0 2 Justin 19.0 使用查询语句获得数据 peole_from_db_query = pd.read_sql_query('SELECT * FROM people', conn) peole_from_db_query name age 0 Michael NaN 1 Andy 30.0 2 Justin 19.0 保存到数据库 peole_from_db_query.to_sql('new_people3', conn) new_people_from_db = pd.read_sql('new_people3', conn) new_people_from_db index name age 0 0 Michael NaN 1 1 Andy 30.0 2 2 Justin 19.0 从excel中读取数据(需要xlrd)和保存 一样的我们还是拿people作为数据,创建一个excel文件放入./source # using the ExcelFile class xls = pd.ExcelFile('./source/people.xlsx') data_fromExcel = xls.parse(u'工作表1', index_col=None, na_values=['NA']) data_fromExcel name age 0 Michael NaN 1 Andy 30.0 2 Justin 19.0 people_fromExcel = pd.read_excel('./source/people.xlsx', u'工作表1', index_col=None, na_values=['NA']) people_fromExcel name age 0 Michael NaN 1 Andy 30.0 2 Justin 19.0 保存到excel iris_data.to_excel('source/iris.xlsx', sheet_name='Sheet1',index=False) 通过pickle序列化数据 要将表格序列化只需要使用to_pickle方法就好 iris_data.to_pickle(\"source/iris.pickle\") 读取也是只要pd.read_pickle(path)即可 iris_data_copy = pd.read_pickle(\"source/iris.pickle\") iris_data_copy[:5] sepal_length sepal_width petal_length petal_width class 0 5.1 3.5 1.4 0.2 Iris-setosa 1 4.9 3.0 1.4 0.2 Iris-setosa 2 4.7 3.2 1.3 0.2 Iris-setosa 3 4.6 3.1 1.5 0.2 Iris-setosa 4 5.0 3.6 1.4 0.2 Iris-setosa Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 21:47:41 "},"matplotlib/":{"url":"matplotlib/","title":"可视化工具matplotlib","keywords":"","body":"python数据分析攻略 matplotlib和numpy一样,是事实上的python标准库 是被使用最多的二维绘图Python包。它不仅提供一个非常快捷的用python可视化数据的方法，而且提供了出版质量的多种格式图像。 不过遗憾的是pypy目前并不支持. matplotlib主要是一个绘图工具,大多数的数据科学工具都对他支持良好. 它体系庞大复杂,可以绘制各种常规图形,也可以绘制点线构成自定义的图形,可以是2d图形也可以画3d图形,可以绘制图片也可以构建简单动画,甚至于还有个模块爬取美股信息 本文将从多个角度介绍matplotlib Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 18:52:40 "},"matplotlib/matplotlib_config/matplotlib_config.html":{"url":"matplotlib/matplotlib_config/matplotlib_config.html","title":"matplotlib设置","keywords":"","body":"matplotlib的基本设置 绘图从来就是个很复杂的东西,各种样式各种设置非常复杂,不信的同学可以拿latex类比下. matplotlib设置方式可以分为三种: 使用内置的配置主题 临时设置 使用配置文件matplotlibrc import matplotlib.pyplot as plt import matplotlib import numpy as np %matplotlib inline 通常matplotlib在linux下的设置文件放在~/.config/matplotlib/下但也会有特殊,我们可以用下面的代码查看配置文件的位置 matplotlib.get_configdir() '/Users/huangsizhe/.matplotlib' 使用内置的配置主题 matplotlib内置了许多基本的设置主题可以通过matplotlib.pyplot.style.available查看 plt.style.available ['bmh', 'classic', 'dark_background', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn-bright', 'seaborn-colorblind', 'seaborn-dark-palette', 'seaborn-dark', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', 'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', 'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'seaborn', 'animation_support', 'chinese_support'] 样式的用法有两种, 一种是全局使用,plt.style.use('seaborn-darkgrid') 设定好之后所有下面的图将都是这一样式 另一种是临时使用样式,可以使用plt.style.context结合with语句,构建上下文环境 我们来看看他们的效果大约是啥样 x=[1,2,3,4,5,6,7,8] y=[2,1,3,5,2,6,12,7] with plt.style.context(('seaborn-darkgrid')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-notebook')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('classic')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-ticks')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('grayscale')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('bmh')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-talk')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('dark_background')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('ggplot')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('fivethirtyeight')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-colorblind')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-deep')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-whitegrid')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-bright')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-poster')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-muted')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-paper')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-white')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-pastel')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-dark')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-dark-palette')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() 这些主题都是可以组合使用的 with plt.style.context(('fivethirtyeight','seaborn-whitegrid','seaborn-pastel')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() with plt.style.context(('seaborn-whitegrid','seaborn-pastel','fivethirtyeight')): plt.figure(figsize=(5,4)) plt.plot(x,y) plt.show() 可以看出,如果有冲突,后定义的会覆盖先定义的. 临时修改配置 matplotlib允许临时修改配置,使用的是matplotlib.rcParams matplotlib.rcParams['lines.linewidth'] = 2 matplotlib.rcParams['lines.color'] = 'r' 或者使用matplotlib.rc(group, **kwargs)来快速的为分组做设定 matplotlib.rc('lines', linewidth=2, color='r') 使用matplotlibrc文件全局的设置 matplotlib会以 本地->环境变量MATPLOTLIBRC/matplotlibrc指定位置->用户配置位置(linux:.config/matplotlib/matplotlibrc,other:.matplotlib/matplotlibrc),->matplotlib安装根目录/matplotlib/mpl-data/matplotlibrc 的顺序查找matplotlibrc,用它就可以配置需要的设置了,这个方法是全局默认加载的. 一份设置文档大约是这个样子,和python规则一样,#代表注释 ### MATPLOTLIBRC FORMAT # This is a sample matplotlib configuration file - you can find a copy # of it on your system in # site-packages/matplotlib/mpl-data/matplotlibrc. If you edit it # there, please note that it will be overwritten in your next install. # If you want to keep a permanent local copy that will not be # overwritten, place it in the following location: # unix/linux: # $HOME/.config/matplotlib/matplotlibrc or # $XDG_CONFIG_HOME/matplotlib/matplotlibrc (if $XDG_CONFIG_HOME is set) # other platforms: # $HOME/.matplotlib/matplotlibrc # # See http://matplotlib.org/users/customizing.html#the-matplotlibrc-file for # more details on the paths which are checked for the configuration file. # # This file is best viewed in a editor which supports python mode # syntax highlighting. Blank lines, or lines starting with a comment # symbol, are ignored, as are trailing comments. Other lines must # have the format # key : val # optional comment # # Colors: for the color values below, you can either use - a # matplotlib color string, such as r, k, or b - an rgb tuple, such as # (1.0, 0.5, 0.0) - a hex string, such as ff00ff - a scalar # grayscale intensity such as 0.75 - a legal html color name, e.g., red, # blue, darkslategray #### CONFIGURATION BEGINS HERE # The default backend; one of GTK GTKAgg GTKCairo GTK3Agg GTK3Cairo # MacOSX Qt4Agg Qt5Agg TkAgg WX WXAgg Agg Cairo GDK PS PDF SVG # Template. # You can also deploy your own backend outside of matplotlib by # referring to the module name (which must be in the PYTHONPATH) as # 'module://my_backend'. backend : tkagg # If you are using the Qt4Agg backend, you can choose here # to use the PyQt4 bindings or the newer PySide bindings to # the underlying Qt4 toolkit. #backend.qt4 : PyQt4 # PyQt4 | PySide # Note that this can be overridden by the environment variable # QT_API used by Enthought Tool Suite (ETS); valid values are # \"pyqt\" and \"pyside\". The \"pyqt\" setting has the side effect of # forcing the use of Version 2 API for QString and QVariant. # The port to use for the web server in the WebAgg backend. # webagg.port : 8888 # If webagg.port is unavailable, a number of other random ports will # be tried until one that is available is found. # webagg.port_retries : 50 # When True, open the webbrowser to the plot that is shown # webagg.open_in_browser : True # When True, the figures rendered in the nbagg backend are created with # a transparent background. # nbagg.transparent : False # if you are running pyplot inside a GUI and your backend choice # conflicts, we will automatically try to find a compatible one for # you if backend_fallback is True #backend_fallback: True #interactive : False #toolbar : toolbar2 # None | toolbar2 (\"classic\" is deprecated) #timezone : UTC # a pytz timezone string, e.g., US/Central or Europe/Paris # Where your matplotlib data lives if you installed to a non-default # location. This is where the matplotlib fonts, bitmaps, etc reside #datapath : /home/jdhunter/mpldata ### LINES # See http://matplotlib.org/api/artist_api.html#module-matplotlib.lines for more # information on line properties. #lines.linewidth : 1.5 # line width in points #lines.linestyle : - # solid line #lines.color : C0 # has no affect on plot(); see axes.prop_cycle #lines.marker : None # the default marker #lines.markeredgewidth : 1.0 # the line width around the marker symbol #lines.markersize : 6 # markersize, in points #lines.dash_joinstyle : miter # miter|round|bevel #lines.dash_capstyle : butt # butt|round|projecting #lines.solid_joinstyle : miter # miter|round|bevel #lines.solid_capstyle : projecting # butt|round|projecting #lines.antialiased : True # render lines in antialiased (no jaggies) # The three standard dash patterns. These are scaled by the linewidth. #lines.dashed_pattern : 2.8, 1.2 #lines.dashdot_pattern : 4.8, 1.2, 0.8, 1.2 #lines.dotted_pattern : 1.1, 1.1 #lines.scale_dashes : True #markers.fillstyle: full # full|left|right|bottom|top|none ### PATCHES # Patches are graphical objects that fill 2D space, like polygons or # circles. See # http://matplotlib.org/api/artist_api.html#module-matplotlib.patches # information on patch properties #patch.linewidth : 1 # edge width in points. #patch.facecolor : C0 #patch.edgecolor : black # if forced, or patch is not filled #patch.force_edgecolor : False # True to always use edgecolor #patch.antialiased : True # render patches in antialiased (no jaggies) ### HATCHES #hatch.color : k #hatch.linewidth : 1.0 ### Boxplot #boxplot.notch : False #boxplot.vertical : True #boxplot.whiskers : 1.5 #boxplot.bootstrap : None #boxplot.patchartist : False #boxplot.showmeans : False #boxplot.showcaps : True #boxplot.showbox : True #boxplot.showfliers : True #boxplot.meanline : False #boxplot.flierprops.color : 'k' #boxplot.flierprops.marker : 'o' #boxplot.flierprops.markerfacecolor : 'none' #boxplot.flierprops.markeredgecolor : 'k' #boxplot.flierprops.markersize : 6 #boxplot.flierprops.linestyle : 'none' #boxplot.flierprops.linewidth : 1.0 #boxplot.boxprops.color : 'k' #boxplot.boxprops.linewidth : 1.0 #boxplot.boxprops.linestyle : '-' #boxplot.whiskerprops.color : 'k' #boxplot.whiskerprops.linewidth : 1.0 #boxplot.whiskerprops.linestyle : '-' #boxplot.capprops.color : 'k' #boxplot.capprops.linewidth : 1.0 #boxplot.capprops.linestyle : '-' #boxplot.medianprops.color : 'C1' #boxplot.medianprops.linewidth : 1.0 #boxplot.medianprops.linestyle : '-' #boxplot.meanprops.color : 'C2' #boxplot.meanprops.marker : '^' #boxplot.meanprops.markerfacecolor : 'C2' #boxplot.meanprops.markeredgecolor : 'C2' #boxplot.meanprops.markersize : 6 #boxplot.meanprops.linestyle : 'none' #boxplot.meanprops.linewidth : 1.0 ### FONT # # font properties used by text.Text. See # http://matplotlib.org/api/font_manager_api.html for more # information on font properties. The 6 font properties used for font # matching are given below with their default values. # # The font.family property has five values: 'serif' (e.g., Times), # 'sans-serif' (e.g., Helvetica), 'cursive' (e.g., Zapf-Chancery), # 'fantasy' (e.g., Western), and 'monospace' (e.g., Courier). Each of # these font families has a default list of font names in decreasing # order of priority associated with them. When text.usetex is False, # font.family may also be one or more concrete font names. # # The font.style property has three values: normal (or roman), italic # or oblique. The oblique style will be used for italic, if it is not # present. # # The font.variant property has two values: normal or small-caps. For # TrueType fonts, which are scalable fonts, small-caps is equivalent # to using a font size of 'smaller', or about 83%% of the current font # size. # # The font.weight property has effectively 13 values: normal, bold, # bolder, lighter, 100, 200, 300, ..., 900. Normal is the same as # 400, and bold is 700. bolder and lighter are relative values with # respect to the current weight. # # The font.stretch property has 11 values: ultra-condensed, # extra-condensed, condensed, semi-condensed, normal, semi-expanded, # expanded, extra-expanded, ultra-expanded, wider, and narrower. This # property is not currently implemented. # # The font.size property is the default font size for text, given in pts. # 10 pt is the standard value. # #font.family : sans-serif #font.style : normal #font.variant : normal #font.weight : medium #font.stretch : normal # note that font.size controls default text sizes. To configure # special text sizes tick labels, axes, labels, title, etc, see the rc # settings for axes and ticks. Special text sizes can be defined # relative to font.size, using the following values: xx-small, x-small, # small, medium, large, x-large, xx-large, larger, or smaller #font.size : 10.0 #font.serif : DejaVu Serif, Bitstream Vera Serif, New Century Schoolbook, Century Schoolbook L, Utopia, ITC Bookman, Bookman, Nimbus Roman No9 L, Times New Roman, Times, Palatino, Charter, serif #font.sans-serif : DejaVu Sans, Bitstream Vera Sans, Lucida Grande, Verdana, Geneva, Lucid, Arial, Helvetica, Avant Garde, sans-serif #font.cursive : Apple Chancery, Textile, Zapf Chancery, Sand, Script MT, Felipa, cursive #font.fantasy : Comic Sans MS, Chicago, Charcoal, Impact, Western, Humor Sans, xkcd, fantasy #font.monospace : DejaVu Sans Mono, Bitstream Vera Sans Mono, Andale Mono, Nimbus Mono L, Courier New, Courier, Fixed, Terminal, monospace ### TEXT # text properties used by text.Text. See # http://matplotlib.org/api/artist_api.html#module-matplotlib.text for more # information on text properties #text.color : black ### LaTeX customizations. See http://wiki.scipy.org/Cookbook/Matplotlib/UsingTex #text.usetex : False # use latex for all text handling. The following fonts # are supported through the usual rc parameter settings: # new century schoolbook, bookman, times, palatino, # zapf chancery, charter, serif, sans-serif, helvetica, # avant garde, courier, monospace, computer modern roman, # computer modern sans serif, computer modern typewriter # If another font is desired which can loaded using the # LaTeX \\usepackage command, please inquire at the # matplotlib mailing list #text.latex.unicode : False # use \"ucs\" and \"inputenc\" LaTeX packages for handling # unicode strings. #text.latex.preamble : # IMPROPER USE OF THIS FEATURE WILL LEAD TO LATEX FAILURES # AND IS THEREFORE UNSUPPORTED. PLEASE DO NOT ASK FOR HELP # IF THIS FEATURE DOES NOT DO WHAT YOU EXPECT IT TO. # preamble is a comma separated list of LaTeX statements # that are included in the LaTeX document preamble. # An example: # text.latex.preamble : \\usepackage{bm},\\usepackage{euler} # The following packages are always loaded with usetex, so # beware of package collisions: color, geometry, graphicx, # type1cm, textcomp. Adobe Postscript (PSSNFS) font packages # may also be loaded, depending on your font settings #text.dvipnghack : None # some versions of dvipng don't handle alpha # channel properly. Use True to correct # and flush ~/.matplotlib/tex.cache # before testing and False to force # correction off. None will try and # guess based on your dvipng version #text.hinting : auto # May be one of the following: # 'none': Perform no hinting # 'auto': Use FreeType's autohinter # 'native': Use the hinting information in the # font file, if available, and if your # FreeType library supports it # 'either': Use the native hinting information, # or the autohinter if none is available. # For backward compatibility, this value may also be # True === 'auto' or False === 'none'. #text.hinting_factor : 8 # Specifies the amount of softness for hinting in the # horizontal direction. A value of 1 will hint to full # pixels. A value of 2 will hint to half pixels etc. #text.antialiased : True # If True (default), the text will be antialiased. # This only affects the Agg backend. # The following settings allow you to select the fonts in math mode. # They map from a TeX font name to a fontconfig font pattern. # These settings are only used if mathtext.fontset is 'custom'. # Note that this \"custom\" mode is unsupported and may go away in the # future. #mathtext.cal : cursive #mathtext.rm : serif #mathtext.tt : monospace #mathtext.it : serif:italic #mathtext.bf : serif:bold #mathtext.sf : sans #mathtext.fontset : dejavusans # Should be 'dejavusans' (default), # 'dejavuserif', 'cm' (Computer Modern), 'stix', # 'stixsans' or 'custom' #mathtext.fallback_to_cm : True # When True, use symbols from the Computer Modern # fonts when a symbol can not be found in one of # the custom math fonts. #mathtext.default : it # The default font to use for math. # Can be any of the LaTeX font names, including # the special name \"regular\" for the same font # used in regular text. ### AXES # default face and edge color, default tick sizes, # default fontsizes for ticklabels, and so on. See # http://matplotlib.org/api/axes_api.html#module-matplotlib.axes #axes.facecolor : white # axes background color #axes.edgecolor : black # axes edge color #axes.linewidth : 0.8 # edge linewidth #axes.grid : False # display grid or not #axes.titlesize : large # fontsize of the axes title #axes.titlepad : 4.0 # pad between axes and title in points #axes.labelsize : medium # fontsize of the x any y labels #axes.labelpad : 4.0 # space between label and axis #axes.labelweight : normal # weight of the x and y labels #axes.labelcolor : black #axes.axisbelow : 'line' # draw axis gridlines and ticks below # patches (True); above patches but below # lines ('line'); or above all (False) #axes.formatter.limits : -7, 7 # use scientific notation if log10 # of the axis range is smaller than the # first or larger than the second #axes.formatter.use_locale : False # When True, format tick labels # according to the user's locale. # For example, use ',' as a decimal # separator in the fr_FR locale. #axes.formatter.use_mathtext : False # When True, use mathtext for scientific # notation. #axes.formatter.useoffset : True # If True, the tick label formatter # will default to labeling ticks relative # to an offset when the data range is # small compared to the minimum absolute # value of the data. #axes.formatter.offset_threshold : 4 # When useoffset is True, the offset # will be used when it can remove # at least this number of significant # digits from tick labels. # axes.spines.left : True # display axis spines # axes.spines.bottom : True # axes.spines.top : True # axes.spines.right : True #axes.unicode_minus : True # use unicode for the minus symbol # rather than hyphen. See # http://en.wikipedia.org/wiki/Plus_and_minus_signs#Character_codes #axes.prop_cycle : cycler('color', # ['1f77b4', 'ff7f0e', '2ca02c', 'd62728', # '9467bd', '8c564b', 'e377c2', '7f7f7f', # 'bcbd22', '17becf']) # color cycle for plot lines # as list of string colorspecs: # single letter, long name, or # web-style hex #axes.autolimit_mode : data # How to scale axes limits to the data. # Use \"data\" to use data limits, plus some margin # Use \"round_number\" move to the nearest \"round\" number #axes.xmargin : .05 # x margin. See `axes.Axes.margins` #axes.ymargin : .05 # y margin See `axes.Axes.margins` #polaraxes.grid : True # display grid on polar axes #axes3d.grid : True # display grid on 3d axes ### DATES # These control the default format strings used in AutoDateFormatter. # Any valid format datetime format string can be used (see the python # `datetime` for details). For example using '%%x' will use the locale date representation # '%%X' will use the locale time representation and '%%c' will use the full locale datetime # representation. # These values map to the scales: # {'year': 365, 'month': 30, 'day': 1, 'hour': 1/24, 'minute': 1 / (24 * 60)} # date.autoformatter.year : %Y # date.autoformatter.month : %Y-%m # date.autoformatter.day : %Y-%m-%d # date.autoformatter.hour : %H:%M # date.autoformatter.minute : %H:%M:%S # date.autoformatter.second : %H:%M:%S # date.autoformatter.microsecond : %H:%M:%S.%f ### TICKS # see http://matplotlib.org/api/axis_api.html#matplotlib.axis.Tick #xtick.top : False # draw ticks on the top side #xtick.bottom : True # draw ticks on the bottom side #xtick.major.size : 3.5 # major tick size in points #xtick.minor.size : 2 # minor tick size in points #xtick.major.width : 0.8 # major tick width in points #xtick.minor.width : 0.6 # minor tick width in points #xtick.major.pad : 3.5 # distance to major tick label in points #xtick.minor.pad : 3.4 # distance to the minor tick label in points #xtick.color : k # color of the tick labels #xtick.labelsize : medium # fontsize of the tick labels #xtick.direction : out # direction: in, out, or inout #xtick.minor.visible : False # visibility of minor ticks on x-axis #xtick.major.top : True # draw x axis top major ticks #xtick.major.bottom : True # draw x axis bottom major ticks #xtick.minor.top : True # draw x axis top minor ticks #xtick.minor.bottom : True # draw x axis bottom minor ticks #ytick.left : True # draw ticks on the left side #ytick.right : False # draw ticks on the right side #ytick.major.size : 3.5 # major tick size in points #ytick.minor.size : 2 # minor tick size in points #ytick.major.width : 0.8 # major tick width in points #ytick.minor.width : 0.6 # minor tick width in points #ytick.major.pad : 3.5 # distance to major tick label in points #ytick.minor.pad : 3.4 # distance to the minor tick label in points #ytick.color : k # color of the tick labels #ytick.labelsize : medium # fontsize of the tick labels #ytick.direction : out # direction: in, out, or inout #ytick.minor.visible : False # visibility of minor ticks on y-axis #xtick.major.left : True # draw y axis left major ticks #xtick.major.right : True # draw y axis right major ticks #xtick.minor.left : True # draw y axis left minor ticks #xtick.minor.right : True # draw y axis right minor ticks ### GRIDS #grid.color : b0b0b0 # grid color #grid.linestyle : - # solid #grid.linewidth : 0.8 # in points #grid.alpha : 1.0 # transparency, between 0.0 and 1.0 ### Legend #legend.loc : best #legend.frameon : True # if True, draw the legend on a background patch #legend.framealpha : 0.8 # legend patch transparency #legend.facecolor : inherit # inherit from axes.facecolor; or color spec #legend.edgecolor : 0.8 # background patch boundary color #legend.fancybox : True # if True, use a rounded box for the # legend background, else a rectangle #legend.shadow : False # if True, give background a shadow effect #legend.numpoints : 1 # the number of marker points in the legend line #legend.scatterpoints : 1 # number of scatter points #legend.markerscale : 1.0 # the relative size of legend markers vs. original #legend.fontsize : medium # Dimensions as fraction of fontsize: #legend.borderpad : 0.4 # border whitespace #legend.labelspacing : 0.5 # the vertical space between the legend entries #legend.handlelength : 2.0 # the length of the legend lines #legend.handleheight : 0.7 # the height of the legend handle #legend.handletextpad : 0.8 # the space between the legend line and legend text #legend.borderaxespad : 0.5 # the border between the axes and legend edge #legend.columnspacing : 2.0 # column separation ### FIGURE # See http://matplotlib.org/api/figure_api.html#matplotlib.figure.Figure #figure.titlesize : large # size of the figure title (Figure.suptitle()) #figure.titleweight : normal # weight of the figure title #figure.figsize : 6.4, 4.8 # figure size in inches #figure.dpi : 100 # figure dots per inch #figure.facecolor : white # figure facecolor; 0.75 is scalar gray #figure.edgecolor : white # figure edgecolor #figure.autolayout : False # When True, automatically adjust subplot # parameters to make the plot fit the figure #figure.max_open_warning : 20 # The maximum number of figures to open through # the pyplot interface before emitting a warning. # If less than one this feature is disabled. # The figure subplot parameters. All dimensions are a fraction of the #figure.subplot.left : 0.125 # the left side of the subplots of the figure #figure.subplot.right : 0.9 # the right side of the subplots of the figure #figure.subplot.bottom : 0.11 # the bottom of the subplots of the figure #figure.subplot.top : 0.88 # the top of the subplots of the figure #figure.subplot.wspace : 0.2 # the amount of width reserved for blank space between subplots, # expressed as a fraction of the average axis width #figure.subplot.hspace : 0.2 # the amount of height reserved for white space between subplots, # expressed as a fraction of the average axis height ### IMAGES #image.aspect : equal # equal | auto | a number #image.interpolation : nearest # see help(imshow) for options #image.cmap : viridis # A colormap name, gray etc... #image.lut : 256 # the size of the colormap lookup table #image.origin : upper # lower | upper #image.resample : True #image.composite_image : True # When True, all the images on a set of axes are # combined into a single composite image before # saving a figure as a vector graphics file, # such as a PDF. ### CONTOUR PLOTS #contour.negative_linestyle : dashed # dashed | solid #contour.corner_mask : True # True | False | legacy ### ERRORBAR PLOTS #errorbar.capsize : 0 # length of end cap on error bars in pixels ### HISTOGRAM PLOTS #hist.bins : 10 # The default number of histogram bins. # If Numpy 1.11 or later is # installed, may also be `auto` ### SCATTER PLOTS #scatter.marker : o # The default marker type for scatter plots. ### Agg rendering ### Warning: experimental, 2008/10/10 #agg.path.chunksize : 0 # 0 to disable; values in the range # 10000 to 100000 can improve speed slightly # and prevent an Agg rendering failure # when plotting very large data sets, # especially if they are very gappy. # It may cause minor artifacts, though. # A value of 20000 is probably a good # starting point. ### SAVING FIGURES #path.simplify : True # When True, simplify paths by removing \"invisible\" # points to reduce file size and increase rendering # speed #path.simplify_threshold : 0.1 # The threshold of similarity below which # vertices will be removed in the simplification # process #path.snap : True # When True, rectilinear axis-aligned paths will be snapped to # the nearest pixel when certain criteria are met. When False, # paths will never be snapped. #path.sketch : None # May be none, or a 3-tuple of the form (scale, length, # randomness). # *scale* is the amplitude of the wiggle # perpendicular to the line (in pixels). *length* # is the length of the wiggle along the line (in # pixels). *randomness* is the factor by which # the length is randomly scaled. # the default savefig params can be different from the display params # e.g., you may want a higher resolution, or to make the figure # background white #savefig.dpi : figure # figure dots per inch or 'figure' #savefig.facecolor : white # figure facecolor when saving #savefig.edgecolor : white # figure edgecolor when saving #savefig.format : png # png, ps, pdf, svg #savefig.bbox : standard # 'tight' or 'standard'. # 'tight' is incompatible with pipe-based animation # backends but will workd with temporary file based ones: # e.g. setting animation.writer to ffmpeg will not work, # use ffmpeg_file instead #savefig.pad_inches : 0.1 # Padding to be used when bbox is set to 'tight' #savefig.jpeg_quality: 95 # when a jpeg is saved, the default quality parameter. #savefig.directory : ~ # default directory in savefig dialog box, # leave empty to always use current working directory #savefig.transparent : False # setting that controls whether figures are saved with a # transparent background by default # tk backend params #tk.window_focus : False # Maintain shell focus for TkAgg # ps backend params #ps.papersize : letter # auto, letter, legal, ledger, A0-A10, B0-B10 #ps.useafm : False # use of afm fonts, results in small files #ps.usedistiller : False # can be: None, ghostscript or xpdf # Experimental: may produce smaller files. # xpdf intended for production of publication quality files, # but requires ghostscript, xpdf and ps2eps #ps.distiller.res : 6000 # dpi #ps.fonttype : 3 # Output Type 3 (Type3) or Type 42 (TrueType) # pdf backend params #pdf.compression : 6 # integer from 0 to 9 # 0 disables compression (good for debugging) #pdf.fonttype : 3 # Output Type 3 (Type3) or Type 42 (TrueType) # svg backend params #svg.image_inline : True # write raster image data directly into the svg file #svg.fonttype : 'path' # How to handle SVG fonts: # 'none': Assume fonts are installed on the machine where the SVG will be viewed. # 'path': Embed characters as paths -- supported by most SVG renderers # 'svgfont': Embed characters as SVG fonts -- supported only by Chrome, # Opera and Safari #svg.hashsalt : None # if not None, use this string as hash salt # instead of uuid4 # docstring params #docstring.hardcopy = False # set this when you want to generate hardcopy docstring # Set the verbose flags. This controls how much information # matplotlib gives you at runtime and where it goes. The verbosity # levels are: silent, helpful, debug, debug-annoying. Any level is # inclusive of all the levels below it. If your setting is \"debug\", # you'll get all the debug and helpful messages. When submitting # problems to the mailing-list, please set verbose to \"helpful\" or \"debug\" # and paste the output into your report. # # The \"fileo\" gives the destination for any calls to verbose.report. # These objects can a filename, or a filehandle like sys.stdout. # # You can override the rc default verbosity from the command line by # giving the flags --verbose-LEVEL where LEVEL is one of the legal # levels, e.g., --verbose-helpful. # # You can access the verbose instance in your code # from matplotlib import verbose. #verbose.level : silent # one of silent, helpful, debug, debug-annoying #verbose.fileo : sys.stdout # a log filename, sys.stdout or sys.stderr # Event keys to interact with figures/plots via keyboard. # Customize these settings according to your needs. # Leave the field(s) empty if you don't need a key-map. (i.e., fullscreen : '') #keymap.fullscreen : f # toggling #keymap.home : h, r, home # home or reset mnemonic #keymap.back : left, c, backspace # forward / backward keys to enable #keymap.forward : right, v # left handed quick navigation #keymap.pan : p # pan mnemonic #keymap.zoom : o # zoom mnemonic #keymap.save : s # saving current figure #keymap.quit : ctrl+w, cmd+w # close the current figure #keymap.grid : g # switching on/off a grid in current axes #keymap.yscale : l # toggle scaling of y-axes ('log'/'linear') #keymap.xscale : L, k # toggle scaling of x-axes ('log'/'linear') #keymap.all_axes : a # enable all axes # Control location of examples data files #examples.directory : '' # directory to look in for custom installation ###ANIMATION settings #animation.html : 'none' # How to display the animation as HTML in # the IPython notebook. 'html5' uses # HTML5 video tag. #animation.writer : ffmpeg # MovieWriter 'backend' to use #animation.codec : h264 # Codec to use for writing movie #animation.bitrate: -1 # Controls size/quality tradeoff for movie. # -1 implies let utility auto-determine #animation.frame_format: 'png' # Controls frame format used by temp files #animation.ffmpeg_path: 'ffmpeg' # Path to ffmpeg binary. Without full path # $PATH is searched #animation.ffmpeg_args: '' # Additional arguments to pass to ffmpeg #animation.avconv_path: 'avconv' # Path to avconv binary. Without full path # $PATH is searched #animation.avconv_args: '' # Additional arguments to pass to avconv #animation.mencoder_path: 'mencoder' # Path to mencoder binary. Without full path # $PATH is searched #animation.mencoder_args: '' # Additional arguments to pass to mencoder #animation.convert_path: 'convert' # Path to ImageMagick's convert binary. # On Windows use the full path since convert # is also the name of a system tool. 自定义主题(支持中文字体) 我们当然可以自己定义自己的主题,他的内容和matplotlibrc一样,但以.mplstyle作为后缀,自定义的主题放在mpl_configdir/stylelib下就可以被识别,比如我们定义一个专用于可以显示中文的主题chinese_support.mplstyle 第一步,下载字体,我们使用[微软雅黑],下载好后放在自己的设置文件夹matplotlib安装根目录/matplotlib/mpl-data/下的fonts/ttf文件夹中(这步如果已经有字体文件可以省略) 第二步,在你的设置文件夹下的stylelib文件夹下(没有就自己创建)写下 font.family : LiHei ProLi,Song Pro,Microsoft YaHei, sans-serif 为了跨平台,可以把Microsoft YaHei放到前面,但个人觉得没苹果的字体好看,就算了 第三步,删除fontList.cache文件然后重启即可 字体文件可以在这里下载,本文用到的两个配置文件在这里可以下载: chinese_support.mplstyle animation_support.mplstyle 查看自己有哪些字体可以使用如下命令 from matplotlib.font_manager import FontManager import subprocess fm = FontManager() mat_fonts = set(f.name for f in fm.ttflist) mat_fonts {'.Keyboard', '.LastResort', 'Andale Mono', 'Apple Braille', 'Apple Chancery', 'AppleGothic', 'AppleMyungjo', 'Arial', 'Arial Black', 'Arial Narrow', 'Arial Rounded MT Bold', 'Arial Unicode MS', 'Ayuthaya', 'Big Caslon', 'Bodoni 72 Smallcaps', 'Bodoni Ornaments', 'Bradley Hand', 'Brush Script MT', 'Chalkduster', 'Comic Sans MS', 'Courier New', 'DIN Alternate', 'DIN Condensed', 'DejaVu Sans', 'DejaVu Sans Display', 'DejaVu Sans Mono', 'DejaVu Serif', 'DejaVu Serif Display', 'Diwan Thuluth', 'Farisi', 'Georgia', 'GungSeo', 'Gurmukhi MT', 'HeadLineA', 'Herculanum', 'Hoefler Text', 'Impact', 'InaiMathi', 'Khmer Sangam MN', 'Kokonor', 'Krungthep', 'Lao Sangam MN', 'LiHei Pro', 'LiSong Pro', 'Luminari', 'Microsoft Sans Serif', 'Mishafi', 'Mishafi Gold', 'Osaka', 'PCMyungjo', 'PilGi', 'Plantagenet Cherokee', 'STFangsong', 'STHeiti', 'STIXGeneral', 'STIXIntegralsD', 'STIXIntegralsSm', 'STIXIntegralsUp', 'STIXIntegralsUpD', 'STIXIntegralsUpSm', 'STIXNonUnicode', 'STIXSizeFiveSym', 'STIXSizeFourSym', 'STIXSizeOneSym', 'STIXSizeThreeSym', 'STIXSizeTwoSym', 'STIXVariants', 'Sathu', 'SignPainter', 'Silom', 'Skia', 'Symbol', 'System Font', 'Tahoma', 'Times New Roman', 'Trattatello', 'Trebuchet MS', 'Verdana', 'Wawati SC', 'Wawati TC', 'Webdings', 'Weibei SC', 'Weibei TC', 'Wingdings', 'Wingdings 2', 'Wingdings 3', 'YuGothic', 'Yuppy SC', 'Yuppy TC', 'Zapf Dingbats', 'Zapfino', 'cmb10', 'cmex10', 'cmmi10', 'cmr10', 'cmss10', 'cmsy10', 'cmtt10'} X = np.linspace(-np.pi, np.pi, 256,endpoint=True) C,S = np.cos(X), np.sin(X) plt.figure(figsize=(8,5), dpi=80)#设置图片大小和dpi plt.subplot(111) plt.plot(X, C, color=\"blue\", linewidth=2.5, linestyle=\"-\",label=u\"余弦\") plt.plot(X, S, color=\"red\", linewidth=2.5, linestyle=\"-\",label=u\"正弦\") plt.legend(loc='upper left')#图例位置 plt.xlim(X.min()*1.1, X.max()*1.1)#边界扩大1.1倍 plt.ylim(C.min()*1.1,C.max()*1.1)#边界扩大1.1倍 plt.xticks( [-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r'$-\\pi$',r'$-\\pi / 2$',r'$0$',r'$\\pi / 2$',r'$\\pi$'])#设置x轴记号标签,用latex符号替代具体数 plt.yticks([-1, 0, +1])#设置y轴记号标签 ax = plt.gca()#脊柱 ax.spines['right'].set_color('none')#右脊柱设为无色 ax.spines['top'].set_color('none')#上脊柱设为无色 ax.xaxis.set_ticks_position('bottom')#下脊柱设定位置 ax.spines['bottom'].set_position(('data',0)) ax.yaxis.set_ticks_position('left')#左脊柱设定位置 ax.spines['left'].set_position(('data',0)) plt.show() plt.style.use('chinese_support') X = np.linspace(-np.pi, np.pi, 256,endpoint=True) C,S = np.cos(X), np.sin(X) plt.figure(figsize=(8,5), dpi=80)#设置图片大小和dpi plt.subplot(111) plt.plot(X, C, color=\"blue\", linewidth=2.5, linestyle=\"-\",label=u\"余弦\") plt.plot(X, S, color=\"red\", linewidth=2.5, linestyle=\"-\",label=u\"正弦\") plt.legend(loc='upper left')#图例位置 plt.xlim(X.min()*1.1, X.max()*1.1)#边界扩大1.1倍 plt.ylim(C.min()*1.1,C.max()*1.1)#边界扩大1.1倍 plt.xticks( [-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r'$-\\pi$',r'$-\\pi / 2$',r'$0$',r'$\\pi / 2$',r'$\\pi$'])#设置x轴记号标签,用latex符号替代具体数 plt.yticks([-1, 0, +1])#设置y轴记号标签 ax = plt.gca()#脊柱 ax.spines['right'].set_color('none')#右脊柱设为无色 ax.spines['top'].set_color('none')#上脊柱设为无色 ax.xaxis.set_ticks_position('bottom')#下脊柱设定位置 ax.spines['bottom'].set_position(('data',0)) ax.yaxis.set_ticks_position('left')#左脊柱设定位置 ax.spines['left'].set_position(('data',0)) plt.show() matplotlib 对notebook的特殊支持 matplotlib提供了一个backend为jupyter notebook 提供了控件支持 from __future__ import print_function from imp import reload import matplotlib reload(matplotlib) matplotlib.use('nbagg') import matplotlib.backends.backend_nbagg reload(matplotlib.backends.backend_nbagg) 非交互模式 import matplotlib.backends.backend_webagg_core reload(matplotlib.backends.backend_webagg_core) import matplotlib.pyplot as plt plt.interactive(False) fig1 = plt.figure() plt.plot(range(10)) plt.show() 定义了第一张图后,后面的定义就可以不再使用plt.figure() plt.plot([3, 2, 1]) plt.show() 我们可以用connection_info()查看每张图片的ui状态 print(matplotlib.backends.backend_nbagg.connection_info()) Figure 1 - Figure 1 Figure 2 - Figure 2 Figures pending show: 0 也可以关闭一副图的ui plt.close(fig1) 在非交互模式下没有plt.show就不会显示 plt.plot(range(10)) [] 显示以前创建的图 plt.show() plt.figure() plt.plot(range(5)) plt.show() 交互模式 使用plt.interactive(True)开启交互模式,交互模式下不需要show就可以显示图片 plt.interactive(True) plt.figure() plt.plot([3, 2, 1]) [] 后续行应添加到现有图形，而不是创建一个新的图形。 plt.plot(range(3)) [] 在交互模式下调用connection_info不应显示任何未决数字 print(matplotlib.backends.backend_nbagg.connection_info()) Figure 2 - Figure 2 Figure 3 - Figure 3 Figure 4 - Figure 4 Figure 5 - Figure 5 这种模式用来调试不错,并不适合用来做图 plt.interactive(False) 多个显示 plt.gcf().canvas.manager.reshow() 动画 import matplotlib.animation as animation import numpy as np fig, ax = plt.subplots() x = np.arange(0, 2*np.pi, 0.01) # x-array line, = ax.plot(x, np.sin(x)) def animate(i): line.set_ydata(np.sin(x+i/10.0)) # update the data return line, #Init only required for blitting to give a clean slate. def init(): line.set_ydata(np.ma.array(x, mask=True)) return line, ani = animation.FuncAnimation(fig, animate, np.arange(1, 200), init_func=init, interval=32., blit=True) plt.show() 绑定事件动作 按任何键盘键或鼠标按钮（或滚动）应该在图形有焦点时循环线条线。该图在创建时应默认具有焦点，并通过单击画布重新获得。单击图形外的任何位置都应该释放焦点，但将鼠标移出图形不应该释放焦点。 import itertools fig, ax = plt.subplots() x = np.linspace(0,10,10000) y = np.sin(x) ln, = ax.plot(x,y) evt = [] colors = iter(itertools.cycle(['r', 'g', 'b', 'k', 'c'])) def on_event(event): if event.name.startswith('key'): fig.suptitle('%s: %s' % (event.name, event.key)) elif event.name == 'scroll_event': fig.suptitle('%s: %s' % (event.name, event.step)) else: fig.suptitle('%s: %s' % (event.name, event.button)) evt.append(event) ln.set_color(next(colors)) fig.canvas.draw() fig.canvas.draw_idle() fig.canvas.mpl_connect('button_press_event', on_event) fig.canvas.mpl_connect('button_release_event', on_event) fig.canvas.mpl_connect('scroll_event', on_event) fig.canvas.mpl_connect('key_press_event', on_event) fig.canvas.mpl_connect('key_release_event', on_event) plt.show() 计时器 import time fig, ax = plt.subplots() text = ax.text(0.5, 0.5, '', ha='center') def update(text): text.set(text=time.ctime()) text.axes.figure.canvas.draw() timer = fig.canvas.new_timer(500, [(update, [text], {})]) timer.start() plt.show() Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 18:52:40 "},"matplotlib/pyplot/pyplot.html":{"url":"matplotlib/pyplot/pyplot.html","title":"pyplot","keywords":"","body":"绘图工具pyplot matplotlib.pylot是matplotlib的绘图工具 我们将会由一个绘制sin(x)曲线的例子开始,由简单到复杂的学习这个库 最简单的实现 最基本的函数就是plt.plot()了,它会产生一个图形, import matplotlib.pyplot as plt import pylab %matplotlib inline import numpy as np plt.style.use('chinese_support') X = np.linspace(-np.pi, np.pi, 256,endpoint=True) C,S = np.cos(X), np.sin(X) plt.plot(X,C);plt.plot(X,S) [] 修改一些设置 plot接收参数,可以使用color指定线的颜色,用linewidth指定线条粗细,linestyle指定线条形状 plt.figure(figsize=(10,6), dpi=80)#设置图片大小和dpi plt.plot(X, C, color=\"blue\", linewidth=2.5, linestyle=\"-\");plt.plot(X, S, color=\"red\", linewidth=2.5, linestyle=\"--\") [] 边界扩大 我们可以i为plt对象绑定xlim和ylim来指定坐标轴的范围 plt.figure(figsize=(8,5), dpi=80)#设置图片大小和dpi plt.subplot(111) plt.plot(X, C, color=\"blue\", linewidth=2.5, linestyle=\"-\") plt.plot(X, S, color=\"red\", linewidth=2.5, linestyle=\"-\") plt.xlim(X.min()*1.1, X.max()*1.1)#边界扩大1.1倍 plt.ylim(C.min()*1.1,C.max()*1.1)#边界扩大1.1倍 plt.show() 设置y轴记号标签 xtick和ytick则是可以接收一个序列来确定刻度 plt.figure(figsize=(8,5), dpi=80)#设置图片大小和dpi plt.subplot(111) plt.plot(X, C, color=\"blue\", linewidth=2.5, linestyle=\"-\") plt.plot(X, S, color=\"red\", linewidth=2.5, linestyle=\"-\") plt.xlim(X.min()*1.1, X.max()*1.1)#边界扩大1.1倍 plt.ylim(C.min()*1.1,C.max()*1.1)#边界扩大1.1倍 plt.xticks( [-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r'$-\\pi$',r'$-\\pi / 2$',r'$0$',r'$\\pi / 2$',r'$\\pi$'])#设置x轴记号标签,用latex符号替代具体数 plt.yticks([-1, 0, +1])#设置y轴记号标签 plt.show() 移动脊柱 实际上每幅图有四条脊柱（上下左右），为了将脊柱放在图的中间，我们必须将其中的两条（上和右）设置为无色，然后调整剩下的两条到合适的位置——数据空间的 0 点。 脊柱使用对象gca来操作 它有 .spines选择'right','top','bottom','left'来确定要操作的是哪条脊柱 .set_color设置颜色 .set_position设定位置 plt.figure(figsize=(8,5), dpi=80)#设置图片大小和dpi plt.subplot(111) plt.plot(X, C, color=\"blue\", linewidth=2.5, linestyle=\"-\") plt.plot(X, S, color=\"red\", linewidth=2.5, linestyle=\"-\") plt.xlim(X.min()*1.1, X.max()*1.1)#边界扩大1.1倍 plt.ylim(C.min()*1.1,C.max()*1.1)#边界扩大1.1倍 plt.xticks( [-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r'$-\\pi$',r'$-\\pi / 2$',r'$0$',r'$\\pi / 2$',r'$\\pi$'])#设置x轴记号标签,用latex符号替代具体数 plt.yticks([-1, 0, +1])#设置y轴记号标签 ax = plt.gca()#脊柱 ax.spines['right'].set_color('none')#右脊柱设为无色 ax.spines['top'].set_color('none')#上脊柱设为无色 ax.xaxis.set_ticks_position('bottom')#下脊柱设定位置 ax.spines['bottom'].set_position(('data',0)) ax.yaxis.set_ticks_position('left')#左脊柱设定位置 ax.spines['left'].set_position(('data',0)) plt.show() 图例 plt.legend(loc=)可以用来初始化图例位置 plt.figure(figsize=(8,5), dpi=80)#设置图片大小和dpi plt.subplot(111) plt.plot(X, C, color=\"blue\", linewidth=2.5, linestyle=\"-\",label=\"cosine\") plt.plot(X, S, color=\"red\", linewidth=2.5, linestyle=\"-\",label=\"sine\") plt.legend(loc='upper left')#图例位置 plt.xlim(X.min()*1.1, X.max()*1.1)#边界扩大1.1倍 plt.ylim(C.min()*1.1,C.max()*1.1)#边界扩大1.1倍 plt.xticks( [-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r'$-\\pi$',r'$-\\pi / 2$',r'$0$',r'$\\pi / 2$',r'$\\pi$'])#设置x轴记号标签,用latex符号替代具体数 plt.yticks([-1, 0, +1])#设置y轴记号标签 ax = plt.gca()#脊柱 ax.spines['right'].set_color('none')#右脊柱设为无色 ax.spines['top'].set_color('none')#上脊柱设为无色 ax.xaxis.set_ticks_position('bottom')#下脊柱设定位置 ax.spines['bottom'].set_position(('data',0)) ax.yaxis.set_ticks_position('left')#左脊柱设定位置 ax.spines['left'].set_position(('data',0)) plt.show() 给一些特殊点做注释 我们希望在 $2\\pi/3$ 的位置给两条函数曲线加上一个注释。首先，我们在对应的函数图像位置上画一个点；然后，向横轴引一条垂线，以虚线标记；最后，写上标签。 plt.text可以在图上指定位置配上文字 plt.annotate可以用来画出图片上的说明文字 plt.plot用来画直线 plt.scatter 可以用来画交点 plt.figure(figsize=(8,5), dpi=80)#设置图片大小和dpi plt.subplot(111) plt.text(0.25, 0.75, r'$cos(x)$') plt.text(1.25, 0.75, r'$sin(x)$') plt.plot(X, C, color=\"blue\", linewidth=2.5, linestyle=\"-\",label=\"cosine\") plt.plot(X, S, color=\"red\", linewidth=2.5, linestyle=\"-\",label=\"sine\") plt.legend(loc='upper left')#图例位置 plt.xlim(X.min()*1.1, X.max()*1.1)#边界扩大1.1倍 plt.ylim(C.min()*1.1,C.max()*1.1)#边界扩大1.1倍 plt.xticks( [-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r'$-\\pi$',r'$-\\pi / 2$',r'$0$',r'$\\pi / 2$',r'$\\pi$'])#设置x轴记号标签,用latex符号替代具体数 plt.yticks([-1, 0, +1])#设置y轴记号标签 ax = plt.gca()#脊柱 ax.spines['right'].set_color('none')#右脊柱设为无色 ax.spines['top'].set_color('none')#上脊柱设为无色 ax.xaxis.set_ticks_position('bottom')#下脊柱设定位置 ax.spines['bottom'].set_position(('data',0)) ax.yaxis.set_ticks_position('left')#左脊柱设定位置 ax.spines['left'].set_position(('data',0)) t = 2*np.pi/3 #特殊点x轴位置 plt.plot([t,t],[0,np.cos(t)], color ='blue', linewidth=2.5, linestyle=\"--\")#竖线从0到与cos(t)交点,蓝色虚线 plt.scatter([t,],[np.cos(t),], 50, color ='blue')# 画交点 plt.annotate(r'$\\sin(\\frac{2\\pi}{3})=\\frac{\\sqrt{3}}{2}$', xy=(t, np.sin(t)), xycoords='data', xytext=(+10, +30), textcoords='offset points', fontsize=16, arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=.2\"))#指出交点并说明公式 plt.plot([t,t],[0,np.sin(t)], color ='red', linewidth=2.5, linestyle=\"--\")#竖线从0到与sin(t)交点,红色虚线 plt.scatter([t,],[np.sin(t),], 50, color ='red')# 画交点 plt.annotate(r'$\\cos(\\frac{2\\pi}{3})=-\\frac{1}{2}$', xy=(t, np.cos(t)), xycoords='data', xytext=(-90, -50), textcoords='offset points', fontsize=16, arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=.2\"))#指出交点并说明公式 plt.show() 精益求精 坐标轴上的记号标签被曲线挡住了，作为强迫症患者这是不能忍的。我们可以把它们放大，然后添加一个白色的半透明底色。这样可以保证标签和曲线同时可见。 并且我们给图片加上格子 plt.figure(figsize=(8,5), dpi=80)#设置图片大小和dpi plt.subplot(111) plt.plot(X, C, color=\"blue\", linewidth=2.5, linestyle=\"-\",label=\"cosine\") plt.plot(X, S, color=\"red\", linewidth=2.5, linestyle=\"-\",label=\"sine\") plt.legend(loc='upper left')#图例位置 plt.xlim(X.min()*1.1, X.max()*1.1)#边界扩大1.1倍 plt.ylim(C.min()*1.1,C.max()*1.1)#边界扩大1.1倍 plt.xticks( [-np.pi, -np.pi/2, 0, np.pi/2, np.pi], [r'$-\\pi$',r'$-\\pi / 2$',r'$0$',r'$\\pi / 2$',r'$\\pi$'])#设置x轴记号标签,用latex符号替代具体数 plt.yticks([-1, 0, +1])#设置y轴记号标签 ax = plt.gca()#脊柱 ax.spines['right'].set_color('none')#右脊柱设为无色 ax.spines['top'].set_color('none')#上脊柱设为无色 ax.xaxis.set_ticks_position('bottom')#下脊柱设定位置 ax.spines['bottom'].set_position(('data',0)) ax.yaxis.set_ticks_position('left')#左脊柱设定位置 ax.spines['left'].set_position(('data',0)) # 添加一个白色的半透明底色 for label in ax.get_xticklabels() + ax.get_yticklabels(): label.set_fontsize(16) label.set_bbox(dict(facecolor='white', edgecolor='None', alpha=0.65 )) t = 2*np.pi/3 #特殊点x轴位置 plt.plot([t,t],[0,np.cos(t)], color ='blue', linewidth=2.5, linestyle=\"--\")#竖线从0到与cos(t)交点,蓝色虚线 plt.scatter([t,],[np.cos(t),], 50, color ='blue')# 画交点 plt.annotate(r'$\\sin(\\frac{2\\pi}{3})=\\frac{\\sqrt{3}}{2}$', xy=(t, np.sin(t)), xycoords='data', xytext=(+10, +30), textcoords='offset points', fontsize=16, arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=.2\"))#指出交点并说明公式 plt.plot([t,t],[0,np.sin(t)], color ='red', linewidth=2.5, linestyle=\"--\")#竖线从0到与sin(t)交点,红色虚线 plt.scatter([t,],[np.sin(t),], 50, color ='red')# 画交点 plt.annotate(r'$\\cos(\\frac{2\\pi}{3})=-\\frac{1}{2}$', xy=(t, np.cos(t)), xycoords='data', xytext=(-90, -50), textcoords='offset points', fontsize=16, arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=.2\"))#指出交点并说明公式 plt.grid(True) plt.show() 填充颜色 fill_between方法来填充两个线条间的内容 n = 256 X = np.linspace(-np.pi,np.pi,n,endpoint=True) Y = np.sin(2*X) plt.axes([0.025,0.025,0.95,0.95]) plt.plot (X, Y+1, color='blue', alpha=1.00) plt.fill_between(X, 1, Y+1, color='blue', alpha=.25) plt.plot (X, Y-1, color='blue', alpha=1.00) plt.fill_between(X, -1, Y-1, (Y-1) > -1, color='blue', alpha=.25) plt.fill_between(X, -1, Y-1, (Y-1) 图像、子图、坐标轴和记号 到目前为止，我们都用隐式的方法来绘制图像和坐标轴。快速绘图中，这是很方便的。我们也可以显式地控制图像、子图、坐标轴。Matplotlib 中的「图像」指的是用户界面看到的整个窗口内容。在图像里面有所谓「子图」。子图的位置是由坐标网格确定的，而「坐标轴」却不受此限制，可以放在图像的任意位置。我们已经隐式地使用过图像和子图：当我们调用 plot 函数的时候，matplotlib 调用 gca() 函数以及 gcf() 函数来获取当前的坐标轴和图像；如果无法获取图像，则会调用 figure() 函数来创建一个——严格地说，是用 subplot(1,1,1) 创建一个只有一个子图的图像。 子图像 你可以用子图来将图样（plot）放在均匀的坐标网格中。用 subplot 函数的时候，你需要指明网格的行列数量，以及你希望将图样放在哪一个网格区域中。此外，gridspec 的功能更强大，你也可以选择它来实现这个功能。 plt.subplot(2,2,1) plt.xticks([]), plt.yticks([]) plt.text(0.5,0.5, 'subplot(2,2,1)',ha='center',va='center',size=20,alpha=.5) plt.subplot(2,2,2) plt.xticks([]), plt.yticks([]) plt.text(0.5,0.5, 'subplot(2,2,2)',ha='center',va='center',size=20,alpha=.5) plt.subplot(2,2,3) plt.xticks([]),plt.yticks([]) plt.text(0.5,0.5, 'subplot(2,2,3)',ha='center',va='center',size=20,alpha=.5) plt.subplot(2,2,4) plt.xticks([]), plt.yticks([]) plt.text(0.5,0.5, 'subplot(2,2,4)',ha='center',va='center',size=20,alpha=.5) # savefig('../figures/subplot-grid.png', dpi=64) plt.show() 格子grid ax = plt.axes([0.025,0.025,0.95,0.95]) ax.set_xlim(0,4) ax.set_ylim(0,3) ax.xaxis.set_major_locator(plt.MultipleLocator(1.0)) ax.xaxis.set_minor_locator(plt.MultipleLocator(0.1)) ax.yaxis.set_major_locator(plt.MultipleLocator(1.0)) ax.yaxis.set_minor_locator(plt.MultipleLocator(0.1)) ax.grid(which='major', axis='x', linewidth=0.75, linestyle='-', color='0.75') ax.grid(which='minor', axis='x', linewidth=0.25, linestyle='-', color='0.75') ax.grid(which='major', axis='y', linewidth=0.75, linestyle='-', color='0.75') ax.grid(which='minor', axis='y', linewidth=0.25, linestyle='-', color='0.75') ax.set_xticklabels([]) ax.set_yticklabels([]) plt.show() 多重网格 plt.subplot(2,2,1) plt.subplot(2,2,3) plt.subplot(2,2,4) plt.show() fig = plt.figure() fig.subplots_adjust(bottom=0.025, left=0.025, top = 0.975, right=0.975) plt.subplot(2,1,1) plt.xticks([]), plt.yticks([]) plt.subplot(2,3,4) plt.xticks([]), plt.yticks([]) plt.subplot(2,3,5) plt.xticks([]), plt.yticks([]) plt.subplot(2,3,6) plt.xticks([]), plt.yticks([]) plt.show() 坐标轴 坐标轴和子图功能类似，不过它可以放在图像的任意位置。因此，如果你希望在一副图中绘制一个小图，就可以用这个功能。 plt.axes([0.1,0.1,.8,.8]) plt.xticks([]), plt.yticks([]) plt.text(0.6,0.6, 'axes([0.1,0.1,.8,.8])',ha='center',va='center',size=20,alpha=.5) plt.axes([0.2,0.2,.3,.3]) plt.xticks([]), plt.yticks([]) plt.text(0.5,0.5, 'axes([0.2,0.2,.3,.3])',ha='center',va='center',size=16,alpha=.5) #plt.savefig(\"../figures/axes.png\",dpi=64) plt.show() plt.axes([0.1,0.1,.5,.5]) plt.xticks([]), plt.yticks([]) plt.text(0.1,0.1, 'axes([0.1,0.1,.8,.8])',ha='left',va='center',size=16,alpha=.5) plt.axes([0.2,0.2,.5,.5]) plt.xticks([]), plt.yticks([]) plt.text(0.1,0.1, 'axes([0.2,0.2,.5,.5])',ha='left',va='center',size=16,alpha=.5) plt.axes([0.3,0.3,.5,.5]) plt.xticks([]), plt.yticks([]) plt.text(0.1,0.1, 'axes([0.3,0.3,.5,.5])',ha='left',va='center',size=16,alpha=.5) plt.axes([0.4,0.4,.5,.5]) plt.xticks([]), plt.yticks([]) plt.text(0.1,0.1, 'axes([0.4,0.4,.5,.5])',ha='left',va='center',size=16,alpha=.5) # plt.savefig(\"../figures/axes-2.png\",dpi=64) plt.show() 记号 良好的记号是图像的重要组成部分。Matplotlib 里的记号系统里的各个细节都是可以由用户个性化配置的。你可以用 Tick Locators 来指定在那些位置放置记号，用 Tick Formatters 来调整记号的样式。主要和次要的记号可以以不同的方式呈现。默认情况下，每一个次要的记号都是隐藏的，也就是说，默认情况下的次要记号列表是空的——NullLocator。 下面有为不同需求设计的一些 Locators: NullLocator No ticks. IndexLocator Place a tick on every multiple of some base number of points plotted. FixedLocator Tick locations are fixed. LinearLocator Determine the tick locations. MultipleLocator Set a tick on every integer that is multiple of some base. AutoLocator Select no more than n intervals at nice locations. LogLocator Determine the tick locations for log axes. 特殊图形 除了点线等基本工具,还可以直接使用设置好的类型画一些基本图形 散点图scatter n = 1024 X = np.random.normal(0,1,n) Y = np.random.normal(0,1,n) plt.scatter(X,Y) plt.show() n = 1024 X = np.random.normal(0,1,n) Y = np.random.normal(0,1,n) T = np.arctan2(Y,X) # 计算出象限 plt.axes([0.025,0.025,0.95,0.95]) plt.scatter(X,Y, s=75, c=T, alpha=.5) plt.xlim(-1.5,1.5), plt.xticks([]) plt.ylim(-1.5,1.5), plt.yticks([]) plt.show() 栅栏图bar n = 12 X = np.arange(n) Y1 = (1-X/float(n)) * np.random.uniform(0.5,1.0,n) Y2 = (1-X/float(n)) * np.random.uniform(0.5,1.0,n) plt.bar(X, +Y1, facecolor='#9999ff', edgecolor='white') plt.bar(X, -Y2, facecolor='#ff9999', edgecolor='white') for x,y in zip(X,Y1): plt.text(x+0.4, y+0.05, '%.2f' % y, ha='center', va= 'bottom') plt.ylim(-1.25,+1.25) plt.show() n = 12 X = np.arange(n) Y1 = (1-X/float(n)) * np.random.uniform(0.5,1.0,n) Y2 = (1-X/float(n)) * np.random.uniform(0.5,1.0,n) plt.axes([0.025,0.025,0.95,0.95]) plt.bar(X, +Y1, facecolor='#9999ff', edgecolor='white') plt.bar(X, -Y2, facecolor='#ff9999', edgecolor='white') for x,y in zip(X,Y1): plt.text(x+0.4, y+0.05, '%.2f' % y, ha='center', va= 'bottom') for x,y in zip(X,Y2): plt.text(x+0.4, -y-0.05, '%.2f' % y, ha='center', va= 'top') plt.xlim(-.5,n), plt.xticks([]) plt.ylim(-1.25,+1.25), plt.yticks([]) plt.show() 等高线图meshgrid def f(x,y): return (1-x/2+x**5+y**3)*np.exp(-x**2-y**2) n = 256 x = np.linspace(-3,3,n) y = np.linspace(-3,3,n) X,Y = np.meshgrid(x,y) plt.contourf(X, Y, f(X,Y), 8, alpha=.75, cmap='jet') C = plt.contour(X, Y, f(X,Y), 8, colors='black', linewidth=.5) plt.show() def f(x,y): return (1-x/2+x**5+y**3)*np.exp(-x**2-y**2) n = 256 x = np.linspace(-3,3,n) y = np.linspace(-3,3,n) X,Y = np.meshgrid(x,y) plt.axes([0.025,0.025,0.95,0.95]) plt.contourf(X, Y, f(X,Y), 8, alpha=.75, cmap=plt.cm.hot) C = plt.contour(X, Y, f(X,Y), 8, colors='black', linewidth=.5) plt.clabel(C, inline=1, fontsize=10) plt.xticks([]), plt.yticks([]) plt.show() 灰度图（Imshow） def f(x,y): return (1-x/2+x**5+y**3)*np.exp(-x**2-y**2) n = 10 x = np.linspace(-3,3,4*n) y = np.linspace(-3,3,3*n) X,Y = np.meshgrid(x,y) plt.imshow(f(X,Y)) plt.show() def f(x,y): return (1-x/2+x**5+y**3)*np.exp(-x**2-y**2) n = 10 x = np.linspace(-3,3,3.5*n) y = np.linspace(-3,3,3.0*n) X,Y = np.meshgrid(x,y) Z = f(X,Y) plt.axes([0.025,0.025,0.95,0.95]) plt.imshow(Z,interpolation='nearest', cmap='bone', origin='lower') plt.colorbar(shrink=.92) plt.xticks([]), plt.yticks([]) plt.show() 饼状图 n = 20 Z = np.random.uniform(0,1,n) plt.pie(Z) plt.show() n = 20 Z = np.ones(n) Z[-1] *= 2 plt.axes([0.025,0.025,0.95,0.95]) plt.pie(Z, explode=Z*.05, colors = ['%f' % (i/float(n)) for i in range(n)]) plt.gca().set_aspect('equal') plt.xticks([]), plt.yticks([]) plt.show() 柱状图hist mu, sigma = 100, 15 x = mu + sigma * np.random.randn(10000) plt.hist(x, 50, normed=1, facecolor='g', alpha=0.75) plt.xlabel('Smarts') plt.ylabel('Probability') plt.title('Histogram of IQ') plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$') plt.axis([40, 160, 0, 0.03]) plt.grid(True) 量场图--箭头（Quiver Plots） n = 8 X,Y = np.mgrid[0:n,0:n] plt.quiver(X,Y) plt.show() n = 8 X,Y = np.mgrid[0:n,0:n] T = np.arctan2(Y-n/2.0, X-n/2.0) R = 10+np.sqrt((Y-n/2.0)**2+(X-n/2.0)**2) U,V = R*np.cos(T), R*np.sin(T) plt.axes([0.025,0.025,0.95,0.95]) plt.quiver(X,Y,U,V,R, alpha=.5) plt.quiver(X,Y,U,V, edgecolor='k', facecolor='None', linewidth=.5) plt.xlim(-1,n), plt.xticks([]) plt.ylim(-1,n), plt.yticks([]) plt.show() 极轴图 plt.axes([0,0,1,1]) N = 20 theta = np.arange(0.0, 2*np.pi, 2*np.pi/N) radii = 10*np.random.rand(N) width = np.pi/4*np.random.rand(N) bars = plt.bar(theta, radii, width=width, bottom=0.0) for r,bar in zip(radii, bars): bar.set_facecolor( plt.cm.jet(r/10.)) bar.set_alpha(0.5) plt.show() ax = plt.axes([0.025,0.025,0.95,0.95], polar=True) N = 20 theta = np.arange(0.0, 2*np.pi, 2*np.pi/N) radii = 10*np.random.rand(N) width = np.pi/4*np.random.rand(N) bars = plt.bar(theta, radii, width=width, bottom=0.0) for r,bar in zip(radii, bars): bar.set_facecolor( plt.cm.jet(r/10.)) bar.set_alpha(0.5) ax.set_xticklabels([]) ax.set_yticklabels([]) plt.show() 3D 图 from mpl_toolkits.mplot3d import Axes3D fig = plt.figure() ax = Axes3D(fig) X = np.arange(-4, 4, 0.25) Y = np.arange(-4, 4, 0.25) X, Y = np.meshgrid(X, Y) R = np.sqrt(X**2 + Y**2) Z = np.sin(R) ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='hot') plt.show() fig = plt.figure() ax = Axes3D(fig) X = np.arange(-4, 4, 0.25) Y = np.arange(-4, 4, 0.25) X, Y = np.meshgrid(X, Y) R = np.sqrt(X**2 + Y**2) Z = np.sin(R) ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=plt.cm.hot) ax.contourf(X, Y, Z, zdir='z', offset=-2, cmap=plt.cm.hot) ax.set_zlim(-2,2) plt.show() 手稿 eqs = [] eqs.append((r\"$W^{3\\beta}_{\\delta_1 \\rho_1 \\sigma_2} = U^{3\\beta}_{\\delta_1 \\rho_1} + \\frac{1}{8 \\pi 2} \\int^{\\alpha_2}_{\\alpha_2} d \\alpha^\\prime_2 \\left[\\frac{ U^{2\\beta}_{\\delta_1 \\rho_1} - \\alpha^\\prime_2U^{1\\beta}_{\\rho_1 \\sigma_2} }{U^{0\\beta}_{\\rho_1 \\sigma_2}}\\right]$\")) eqs.append((r\"$\\frac{d\\rho}{d t} + \\rho \\vec{v}\\cdot\\nabla\\vec{v} = -\\nabla p + \\mu\\nabla^2 \\vec{v} + \\rho \\vec{g}$\")) eqs.append((r\"$\\int_{-\\infty}^\\infty e^{-x^2}dx=\\sqrt{\\pi}$\")) eqs.append((r\"$E = mc^2 $\")) eqs.append((r\"$F_G = G\\frac{m_1m_2}{r^2}$\")) plt.axes([0.025,0.025,0.95,0.95]) for i in range(24): index = np.random.randint(0,len(eqs)) eq = eqs[index] size = np.random.uniform(12,32) x,y = np.random.uniform(0,1,2) alpha = np.random.uniform(0.25,.75) plt.text(x, y, eq, ha='center', va='center', color=\"#11557c\", alpha=alpha, transform=plt.gca().transAxes, fontsize=size, clip_on=True) plt.xticks([]), plt.yticks([]) # savefig('../figures/text_ex.png',dpi=48) plt.show() 箱形图 箱形图可以用来集中化的体现数据的特点 np.random.seed(937) data = np.random.lognormal(size=(37, 4), mean=1.5, sigma=1.75) labels = list('ABCD') fs = 10 # fontsize # demonstrate how to toggle the display of different elements: fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(6, 6)) axes[0, 0].boxplot(data, labels=labels) axes[0, 0].set_title('Default', fontsize=fs) axes[0, 1].boxplot(data, labels=labels, showmeans=True) axes[0, 1].set_title('showmeans=True', fontsize=fs) axes[0, 2].boxplot(data, labels=labels, showmeans=True, meanline=True) axes[0, 2].set_title('showmeans=True,\\nmeanline=True', fontsize=fs) axes[1, 0].boxplot(data, labels=labels, showbox=False, showcaps=False) axes[1, 0].set_title('Tufte Style \\n(showbox=False,\\nshowcaps=False)', fontsize=fs) axes[1, 1].boxplot(data, labels=labels, notch=True, bootstrap=10000) axes[1, 1].set_title('notch=True,\\nbootstrap=10000', fontsize=fs) axes[1, 2].boxplot(data, labels=labels, showfliers=False) axes[1, 2].set_title('showfliers=False', fontsize=fs) for ax in axes.flatten(): ax.set_yscale('log') ax.set_yticklabels([]) fig.subplots_adjust(hspace=0.4) plt.show() # demonstrate how to customize the display different elements: boxprops = dict(linestyle='--', linewidth=3, color='darkgoldenrod') flierprops = dict(marker='o', markerfacecolor='green', markersize=12, linestyle='none') medianprops = dict(linestyle='-.', linewidth=2.5, color='firebrick') meanpointprops = dict(marker='D', markeredgecolor='black', markerfacecolor='firebrick') meanlineprops = dict(linestyle='--', linewidth=2.5, color='purple') fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(6, 6)) axes[0, 0].boxplot(data, boxprops=boxprops) axes[0, 0].set_title('Custom boxprops', fontsize=fs) axes[0, 1].boxplot(data, flierprops=flierprops, medianprops=medianprops) axes[0, 1].set_title('Custom medianprops\\nand flierprops', fontsize=fs) axes[0, 2].boxplot(data, whis='range') axes[0, 2].set_title('whis=\"range\"', fontsize=fs) axes[1, 0].boxplot(data, meanprops=meanpointprops, meanline=False, showmeans=True) axes[1, 0].set_title('Custom mean\\nas point', fontsize=fs) axes[1, 1].boxplot(data, meanprops=meanlineprops, meanline=True, showmeans=True) axes[1, 1].set_title('Custom mean\\nas line', fontsize=fs) axes[1, 2].boxplot(data, whis=[15, 85]) axes[1, 2].set_title('whis=[15, 85]\\n#percentiles', fontsize=fs) for ax in axes.flatten(): ax.set_yscale('log') ax.set_yticklabels([]) fig.suptitle(\"I never said they'd be pretty\") fig.subplots_adjust(hspace=0.4) plt.show() 更多的图形可以在http://matplotlib.org/api/pyplot_summary.html中查看 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 21:31:44 "},"matplotlib/Sankey_diagram/Sankey_diagram.html":{"url":"matplotlib/Sankey_diagram/Sankey_diagram.html","title":"桑基图","keywords":"","body":"桑基图 桑基图（Sankey diagram），即桑基能量分流图，也叫桑基能量平衡图。一种特定类型的流程图，图中延伸的分支的宽度对应数据流量的大小, 通常应用于能源、材料成分、金融等数据的可视化分析。 因1898年Matthew Henry Phineas Riall Sankey绘制的\"蒸汽机的能源效率图\"而闻名，此后便以其名字命名为“桑基图”。 桑基图最明显的特征就是，始末端的分支宽度总和相等，即所有主支宽度的总和应与所有分出去的分支宽度的总和相等，保持能量的平衡。 import numpy as np import matplotlib.pyplot as plt from matplotlib.sankey import Sankey %matplotlib inline matplotlib.sankey.Sankey(ax=None, scale=1.0, unit='', format='%G', gap=0.25, radius=0.1, shoulder=0.03, offset=0.15, head_angle=100, margin=0.4, tolerance=1e-06, **kwargs)是matplotlib构建桑基图的工具 他有两个方法来构造图形 .add(patchlabel='', flows=None, orientations=None, labels='', trunklength=1.0, pathlengths=0.25, prior=None, connect=(0, 0), rotation=0, **kwargs) flows就是流入的百分比了负数表示为流出 labels是每个流的标签 orientations 的取值范围为[-1,0,1]有效值为1（从顶部到顶部），0（从左到右）或-1（从底部到底部）.如果orientation = 0，输入将从左边突入，输出将向右边突破。 add()返回的还是一个Sankey对象,因此链式操作一直add() .finish()构造结束 S=Sankey() S.add(flows=[0.25, 0.15, 0.60, -0.20, -0.15, -0.05, -0.50, -0.10], labels=['', '', '', 'First', 'Second', 'Third', 'Fourth', 'Fifth'], orientations=[-1, 1, 0, 1, 1, 1, 0, -1]).finish() S 我们也可以直接在构造函数里定义流 Sankey(flows=[0.25, 0.15, 0.60, -0.20, -0.15, -0.05, -0.50, -0.10], labels=['', '', '', 'First', 'Second', 'Third', 'Fourth', 'Fifth'], orientations=[-1, 1, 0, 1, 1, 1, 0, -1]).finish() plt.title(\"The default settings produce a diagram like this.\") 我们可以在finish()之后通过一些针对其中元素的操作做特殊化处理 fig = plt.figure() ax = fig.add_subplot(1, 1, 1, xticks=[], yticks=[], title=\"Flow Diagram of a Widget\") sankey = Sankey(ax=ax, scale=0.01, offset=0.2, head_angle=180, format='%.0f', unit='%')# 单位unit定义 sankey.add(flows=[25, 0, 60, -10, -20, -5, -15, -10, -40], labels=['', '', '', 'First', 'Second', 'Third', 'Fourth', 'Fifth', 'Hurray!'], orientations=[-1, 1, 0, 1, 1, 1, -1, -1, 0], pathlengths=[0.25, 0.25, 0.25, 0.25, 0.25, 0.6, 0.25, 0.25, 0.25], patchlabel=\"Widget\\nA\", alpha=0.2, lw=2.0) # Arguments to matplotlib.patches.PathPatch() diagrams = sankey.finish() diagrams[0].patch.set_facecolor('#37c959') diagrams[0].texts[-1].set_color('r') diagrams[0].text.set_fontweight('bold') 如果有两张图用来表现两个系统的关系,可以像下面这么做 fig = plt.figure() ax = fig.add_subplot(1, 1, 1, xticks=[], yticks=[], title=\"Two Systems\") flows = [0.25, 0.15, 0.60, -0.10, -0.05, -0.25, -0.15, -0.10, -0.35] sankey = Sankey(ax=ax, unit=None) sankey.add(flows=flows, label='one', orientations=[-1, 1, 0, 1, 1, 1, -1, -1, 0]) sankey.add(flows=[-0.25, 0.15, 0.1], fc='#37c959', label='two', orientations=[-1, -1, -1], prior=0, connect=(0, 0)) diagrams = sankey.finish() diagrams[-1].patch.set_hatch('/') plt.legend(loc='best') Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 18:52:40 "},"matplotlib/triangular_grids/triangular_grids.html":{"url":"matplotlib/triangular_grids/triangular_grids.html","title":"非结构图形","keywords":"","body":"非结构网络 非结构网格是没有规则拓扑关系的网格，它通常由多边形三角形组成。 网格中的每个每个元素都可以是二维的多边形或者三维多面体，其中最常见的是二维的三角形以及三维的四面体。 在每个元素之间没有隐含的连通性。 由于结构网格面对复杂几何外形时生成困难，以及耗费大量人工，自动化程度不高等缺点，非结构网格逐渐发展起来.使用它的技术主要有流体分析,空气动力学,有限元分析等细分领域. matplotlib中有针对它的作图工具matplotlib.tri模块 核心类class matplotlib.tri.Triangulation(x, y, triangles=None, mask=None) 由n个point点和n个三角形组成的非结构化三角形网格。三角形可以由用户指定或使用Delaunay三角测量自动生成。 x,y对应网格点的坐标 triangles 对于每个三角形，组成三角形的三个点的索引以逆时针方式排序。如果未指定，则计算Delaunay三角剖分。 mask 指定哪些三角形的屏蔽数组 它的方法有: calculate_plane_coefficients(z) 从点（x，y）坐标和指定的z形阵列（n points）计算所有未屏蔽三角形的平面方程系数。返回的数组具有形状（n points，3）并且允许使用 z = array [tri，0] x array [tri，1] y array [tri，2] edges 返回包含非屏蔽三角形的所有边的整型数组形状（nedges，2）。每个边是起点索引和终点索引。每个边（开始，结束和结束，开始）只出现一次。 get_masked_triangles() 返回未屏蔽的三角形数组。 get_trifinder() 返回此三角剖分的默认matplotlib.tri.TriFinder,如果需要,创建它.这允许轻松共享相同的TriFinder对象。 neighbors 邻点 set_mask(mask) 设置或清除屏蔽数组. 寻找是三角形算法 matplotlib.tri.TriFinder(triangulation) TriFinder类使用来自M.de Berg，M.van Kreveld，M.Overmars和O. Schwarzkopf的书“Computational Geometry，Algorithms and Applications”，第二版中的梯形映射算法来实现。三角测量必须有效，即它不能具有重复的点，由共线点形成的三角形或重叠的三角形。该算法对于由共线点形成的三角形具有一些公差，但是这不应被依赖。 这个类的实例可以被调用 trifinder(x,y),调用后会 返回包含指定x，y点所在的三角形的索引的数组，或者对于不在三角形内的点返回-1。 x，y是相同形状和任意数量维度的类阵列x和y坐标。 返回具有相同形状和x和y的整数数组。 三角形网格线性插值 matplotlib.tri.LinearTriInterpolator(triangulation, z, trifinder=None) LinearTriInterpolator对三角形网格执行线性插值。每个三角形由平面表示，使得点（x，y）处的内插值位于包含（x，y）的三角形的平面上。因此，内插值在三角形上是连续的，但是它们的一阶导数在三角形之间的边缘处是不连续的。 他的实例有方法gradient(x, y),可以返回在指定的x，y点包含插值导数的2个包含屏蔽数组的列表。 而实例被调用会返回在指定的x，y点包含插值的屏蔽数组。 三角形网格执行三次插值 matplotlib.tri.CubicTriInterpolator(triangulation, z, kind='min_E', trifinder=None, dz=None) CubicTriInterpolator对三角形网格执行三次插值。在一维, 一段上 做三次插值,函数由函数的值和其两端的导数定义。这在三角形内的2-d中几乎相同，除了函数的值及其2导数必须在每个三角形节点处定义。CubicTriInterpolator获取每个节点（由用户提供）的函数值，并在内部计算导数的值，从而实现平滑插值。 （作为一个特殊功能，用户还可以在每个节点强加导数的值，但这不应该是常见的用法。） kind 选择平滑算法，以便计算内插导数（默认为“min_E”）：如果'min_E'：（默认）计算每个节点处的导数以最小化弯曲能量。如果'geom'：每个节点的导数被计算为相关三角形法线的加权平均值。用于速度优化（大网格）。如果'user'：用户提供参数dz，因此不需要计算。 trifinder 如果未指定，Triangulation的默认TriFinder将通过调用matplotlib.tri.Triangulation.get_trifinder（）来使用。 dz 仅在kind ='user'时使用。在这种情况下，dz必须提供为（dzdx，dzdy），其中dzdx，dzdy是与z相同形状的数组，并且是三角点处的内插一阶导数。 内插基于三角网格的Clough-Tocher细分方案（为了使其更清楚，网格的每个三角形将被划分为3个子三角形，并且在每个子三角形上，内插函数是2的三次多项式坐标）。这种技术源自FEM（有限元方法）分析;使用的元件是还原的Hsieh-Clough-Tocher（HCT）元件。其形状函数在[R1]中描述。组合函数保证是C1平滑的，即它是连续的，并且其一阶导数也是连续的（这在三角形内容中是容易显示的，但当穿过边缘时也是如此）。 在默认情况下（种类='min_E'），内插器使由HCT元素形状函数生成的函数空间上的曲率能量最小化 - 利用施加的值，但在每个节点处的任意导数。最小化的函数是所谓的总曲率的积分（基于来自[R2] -PCG稀疏求解器的算法的实现）： $ E(z) = {\\frac 1 2 } \\int_\\Omega ((\\frac {\\partial^2 z} {\\partial x^2} )^2 + (\\frac {\\partial^2 z} {\\partial y^2} )^2 +2(\\frac {\\partial^2 z} {\\partial y \\partial x} )^2)dxdy $ 如果用户选择case type ='geom'，则使用简单的几何近似（三角形法线向量的加权平均），这可以在非常大的网格上提高速度。 例子: from matplotlib.tri import Triangulation, UniformTriRefiner,\\ CubicTriInterpolator import matplotlib.pyplot as plt import matplotlib.cm as cm import numpy as np import math # 计算偶极子的电位 def dipole_potential(x, y): \"\"\" The electric dipole potential V \"\"\" r_sq = x**2 + y**2 theta = np.arctan2(y, x) z = np.cos(theta)/r_sq return (np.max(z) - z) / (np.max(z) - np.min(z)) # 创建三角网格 #----------------------------------------------------------------------------- # 首先创建点的x和y坐标 n_angles = 30 n_radii = 10 min_radius = 0.2 radii = np.linspace(min_radius, 0.95, n_radii) angles = np.linspace(0, 2*math.pi, n_angles, endpoint=False) angles = np.repeat(angles[..., np.newaxis], n_radii, axis=1) angles[:, 1::2] += math.pi/n_angles x = (radii*np.cos(angles)).flatten() y = (radii*np.sin(angles)).flatten() V = dipole_potential(x, y) V[:5] array([ 0. , 0.25222984, 0.35123967, 0.40177562, 0.4296875 ]) triang = Triangulation(x, y) # 屏蔽掉不需要的值 xmid = x[triang.triangles].mean(axis=1) ymid = y[triang.triangles].mean(axis=1) mask = np.where(xmid*xmid + ymid*ymid # 精细化数据 - 内插电位V refiner = UniformTriRefiner(triang) tri_refi, z_test_refi = refiner.refine_field(V, subdiv=3) # 计算电场（Ex，Ey）作为电位梯度 tci = CubicTriInterpolator(triang, -V) # 这里,gradient()需要 网格节点，但可以在其他任何地方 (Ex, Ey) = tci.gradient(triang.x, triang.y) E_norm = np.sqrt(Ex**2 + Ey**2) #作图 plt.figure() plt.gca().set_aspect('equal') plt.triplot(triang, color='0.8') levels = np.arange(0., 1., 0.01) cmap = cm.get_cmap(name='hot', lut=None) # 三角等高线 plt.tricontour(tri_refi, z_test_refi, levels=levels, cmap=cmap, linewidths=[2.0, 1.0, 1.0, 1.0]) # 用quiver绘制电矢量场的方向 plt.quiver(triang.x, triang.y, Ex/E_norm, Ey/E_norm, units='xy', scale=10., zorder=3, color='blue', width=0.007, headwidth=3., headlength=4.) plt.title('Gradient plot: an electrical dipole') plt.show() 通过递归细分的均匀网格细化 matplotlib.tri.UniformTriRefiner(triangulation)类 通过递归细分的均匀网格细化。 它有方法 refine_field(z, triinterpolator=None, subdiv=3) 用来优化在封装三角定义上定义的字段 triinterpolator插值器用于场插值。如果未指定，将使用CubicTriInterpolator。 subdiv细分的递归级别。默认为3.每个三角形将被划分为4个**子细分三角形。 refine_triangulation(return_tri_index=False, subdiv=3) 计算封装三角测量的均匀精细三角测量refi_triangulation。此函数通过将每个父三角形递归地（递归细分的水平）分割成在边中间节点上构建的4个子子三角形，来细化封装的三角形。最后，每个三角形因此被划分为4 **个子三角形。 subdiv的默认值为3，从而为初始三角形的每个三角形产生64个精细子三角形。 return_tri_index布尔值，指示是否将返回指示每个点的父三角形索引的索引表。默认值False。 例子:在粗糙的三角形网格（例如，由相对稀疏的测试数据构建的三角测量）上绘制高质量等高线： # 在用户定义的三角网格上演示高分辨率三轴定位用matplotlib.tri.UniformTriRefiner import matplotlib.tri as tri # 要分析测试的function def function_z(x, y): \"\"\" A function of 2 variables \"\"\" r1 = np.sqrt((0.5 - x)**2 + (0.5 - y)**2) theta1 = np.arctan2(0.5 - x, 0.5 - y) r2 = np.sqrt((-x - 0.2)**2 + (-y - 0.2)**2) theta2 = np.arctan2(-x - 0.2, -y - 0.2) z = -(2*(np.exp((r1/10)**2) - 1)*30. * np.cos(7.*theta1) + (np.exp((r2/10)**2) - 1)*30. * np.cos(11.*theta2) + 0.7*(x**2 + y**2)) return (np.max(z) - z)/(np.max(z) - np.min(z)) # 构建三角网络中的点 n_angles = 20 n_radii = 10 min_radius = 0.15 radii = np.linspace(min_radius, 0.95, n_radii) angles = np.linspace(0, 2*math.pi, n_angles, endpoint=False) angles = np.repeat(angles[..., np.newaxis], n_radii, axis=1) angles[:, 1::2] += math.pi/n_angles x = (radii*np.cos(angles)).flatten() y = (radii*np.sin(angles)).flatten() z = function_z(x, y) #开始构建三角网络 triang = tri.Triangulation(x, y) # 屏蔽不要的店 xmid = x[triang.triangles].mean(axis=1) ymid = y[triang.triangles].mean(axis=1) mask = np.where(xmid*xmid + ymid*ymid # 精细化数据 refiner = tri.UniformTriRefiner(triang) tri_refi, z_test_refi = refiner.refine_field(z, subdiv=3) plt.figure() plt.gca().set_aspect('equal') plt.triplot(triang, lw=0.5, color='white') levels = np.arange(0., 1., 0.025) cmap = cm.get_cmap(name='terrain', lut=None) plt.tricontourf(tri_refi, z_test_refi, levels=levels, cmap=cmap) plt.tricontour(tri_refi, z_test_refi, levels=levels, colors=['0.25', '0.5', '0.5', '0.5', '0.5'], linewidths=[1.0, 0.5, 0.5, 0.5, 0.5]) plt.title(\"High-resolution tricontouring\") plt.show() 三角网格分析和改进的基本工具 matplotlib.tri.TriAnalyzer(triangulation) 定义三角网格分析和改进的基本工具。TriAnalizer封装了一个Triangulation对象，并提供了用于网格分析和网格改进的基本工具。 它有三个方法 circle_ratios(rescale=True) 返回三角形的三角形平坦度的度量。 圆周半径与外接圆半径的比率是广泛使用的三角形平坦度的指标。对于等边三角形，它总是 get_flat_tri_mask(min_circle_ratio=0.01, rescale=True) 消除三角测量中过分平坦的边界三角形。返回一个屏蔽数组new_mask(布尔值)，它允许从边界定位的平面三角形（根据他们的circle_ratios（））清除封装的三角剖分。这个屏蔽数组意味着随后应用于使用matplotlib.tri.Triangulation.set_mask（）的三角测量。 new_mask是初始三角形掩模的扩展，在初始掩模的三角形将保持掩蔽的意义上。new_mask数组是递归计算的;在每个步骤，只有当它们与当前网格边界共享一侧时，才移除平面三角形。因此，在三角域中将不产生新的空穴。 + min_circle_ratio 如果内圆/外圆半径比r/R 这个函数的基本原理是Delaunay三角形(一个非结构化的点集合,有时在边界处包含几乎平坦的三角形)，导致绘图中的伪像（特别是对于高分辨率轮廓化）。用计算的new_mask掩蔽，封装的三角剖分将不包含具有低于min_circle_ratio的圆比率的更多未掩蔽的边界三角形，从而改进后续绘图或插值的网格质量。 例子:随机集合的高分辨率定向 本演示的初始数据点和三角网格为： 在[-1,1]×[-1,1]正方形内部实例化一组随机点 然后计算这些点的Delaunay三角剖分，其中a 随机子集的三角形被用户掩盖（基于 init_mask_frac 参数）。 这将模拟无效的数据。 提出的通用程序获得高分辨率轮廓的这种 数据集如下： 使用matplotlib.tri.TriAnalyzer计算扩展屏蔽,从边框中排除形状不好（平）的三角形三角测量。 将屏蔽应用于三角剖分（使用set_mask）。 使用a来细化和内插数据matplotlib.tri.UniformTriRefiner。 用tricontour绘制精制数据。 from matplotlib.tri import Triangulation, TriAnalyzer, UniformTriRefiner #----------------------------------------------------------------------------- # 用于测试的函数 #----------------------------------------------------------------------------- def experiment_res(x, y): \"\"\" 表实验结果的分析函数\"\"\" x = 2.*x r1 = np.sqrt((0.5 - x)**2 + (0.5 - y)**2) theta1 = np.arctan2(0.5 - x, 0.5 - y) r2 = np.sqrt((-x - 0.2)**2 + (-y - 0.2)**2) theta2 = np.arctan2(-x - 0.2, -y - 0.2) z = (4*(np.exp((r1/10)**2) - 1)*30. * np.cos(3*theta1) + (np.exp((r2/10)**2) - 1)*30. * np.cos(5*theta2) + 2*(x**2 + y**2)) return (np.max(z) - z)/(np.max(z) - np.min(z)) #----------------------------------------------------------------------------- # 生成初始数据测试点和演示的三角测量 #----------------------------------------------------------------------------- n_test = 200 # 测试数据点数，对于subdiv = 3从3到5000进行测试 subdiv = 3 # 平滑图的初始网格的递归细分数。 #值> 3可能导致精细网格的三角形数量非常多：new triangles numbering =（4 ** subdiv）* ntri init_mask_frac = 0.0 min_circle_ratio = .01 # 随机点 random_gen = np.random.mtrand.RandomState(seed=127260) x_test = random_gen.uniform(-1., 1., size=n_test) y_test = random_gen.uniform(-1., 1., size=n_test) z_test = experiment_res(x_test, y_test) # 使用Delaunay三角网格划分 tri = Triangulation(x_test, y_test) ntri = tri.triangles.shape[0] # 剔除一些要屏蔽的点 mask_init = np.zeros(ntri, dtype=np.bool) masked_tri = random_gen.randint(0, ntri, int(ntri*init_mask_frac)) mask_init[masked_tri] = True tri.set_mask(mask_init) #----------------------------------------------------------------------------- # 在高分辨率绘图之前改进三角测量：删除平面三角形 #----------------------------------------------------------------------------- # 掩蔽在三角形网格的边界处的不良形状的三角形 mask = TriAnalyzer(tri).get_flat_tri_mask(min_circle_ratio) tri.set_mask(mask) # 精细化数据 refiner = UniformTriRefiner(tri) tri_refi, z_test_refi = refiner.refine_field(z_test, subdiv=subdiv) # 用于与分析进行比较 z_expected = experiment_res(tri_refi.x, tri_refi.y) flat_tri = Triangulation(x_test, y_test) flat_tri.set_mask(~mask) #开始画图 plot_tri = True # plot of base triangulation plot_masked_tri = True # plot of excessively flat excluded triangles plot_refi_tri = False # plot of refined triangulation plot_expected = False # plot of analytical function values for comparison # Graphical options for tricontouring levels = np.arange(0., 1., 0.025) cmap = cm.get_cmap(name='Blues', lut=None) plt.figure() plt.gca().set_aspect('equal') plt.title(\"Filtering a Delaunay mesh\\n\" + \"(application to high-resolution tricontouring)\") # 1) 精确（计算）数据轮廓的图： plt.tricontour(tri_refi, z_test_refi, levels=levels, cmap=cmap, linewidths=[2.0, 0.5, 1.0, 0.5]) # 2) 预期（分析）数据轮廓（虚线）的图： if plot_expected: plt.tricontour(tri_refi, z_expected, levels=levels, cmap=cmap, linestyles='--') # 3) 进行内插的细网格的图： if plot_refi_tri: plt.triplot(tri_refi, color='0.97') # 4) 初始“粗糙”网格的图： if plot_tri: plt.triplot(tri, color='0.7') # 4) 从原生的Delaunay三角形而来的未经验证的三角形的图： if plot_masked_tri: plt.triplot(flat_tri, color='red') plt.show() scale_factors 将三角划分为以平方为单位。 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 18:52:40 "},"matplotlib/load_image/load_image.html":{"url":"matplotlib/load_image/load_image.html","title":"图片加载","keywords":"","body":"图片加载 matplotlib.image模块提供了读取图片和进行简单处理的能力,他的底层是pillow import numpy as np import matplotlib.pyplot as plt import matplotlib.image as mpimg img=mpimg.imread('./source/cat.jpg') 通过imread()方法读取的图片会被转换成像素矩阵(numpy的narray对象),其shape与图像分辨率有关,比如: 上图是342x220的图片,那么 img.shape (220, 342, 3) 其中的3为每个像素表现为一个RGB的三位数组 img array([[[254, 254, 254], [254, 254, 254], [254, 254, 254], ..., [255, 255, 255], [255, 255, 255], [255, 255, 255]], [[254, 254, 254], [254, 254, 254], [254, 254, 254], ..., [255, 255, 255], [255, 255, 255], [255, 255, 255]], [[254, 254, 254], [254, 254, 254], [255, 255, 255], ..., [255, 255, 255], [255, 255, 255], [255, 255, 255]], ..., [[255, 255, 255], [255, 255, 255], [255, 255, 255], ..., [255, 255, 255], [255, 255, 255], [255, 255, 255]], [[255, 255, 255], [255, 255, 255], [255, 255, 255], ..., [255, 255, 255], [255, 255, 255], [255, 255, 255]], [[255, 255, 255], [255, 255, 255], [255, 255, 255], ..., [255, 255, 255], [255, 255, 255], [255, 255, 255]]], dtype=uint8) 我们可以通过plt.imshow(img)将这个数组初始化为一个plot对象 imgplot = plt.imshow(img) plt.show() 当然了只要是相同格式的数组都可以通过这个方式初始化为一个plot对象 将假彩色方案应用于图像绘图 伪彩色可以是一个有用的工具，用于增强对比度和更容易地可视化数据。这在使用投影仪对数据进行演示时尤其有用(它们的对比度通常很差)。假彩色仅与单通道，灰度，光度图像相关。我们目前有一个RGB图像。由于R，G和B都是相似的（见上面或在你的数据中的自己），我们可以只选择一个通道的数据： lum_img_r = img[:,:,0] lum_img_r array([[254, 254, 254, ..., 255, 255, 255], [254, 254, 254, ..., 255, 255, 255], [254, 254, 255, ..., 255, 255, 255], ..., [255, 255, 255, ..., 255, 255, 255], [255, 255, 255, ..., 255, 255, 255], [255, 255, 255, ..., 255, 255, 255]], dtype=uint8) lum_img_r.shape (220, 342) plt.imshow(lum_img_r) plt.show() lum_img_g = img[:,:,1] plt.imshow(lum_img_g) plt.show() lum_img_g = img[:,:,2] plt.imshow(lum_img_g) plt.show() 现在我们以使用R为通道的图片,使用亮度（2D，无颜色）图像，应用默认色彩映射（也称为查找表，LUT）。默认值称为jet。有很多其他的也可以选择。 plt.imshow(lum_img_r, cmap=\"hot\") plt.show() 也还可以使用set_cmap()方法更改现有绘图对象上的颜色 imgplot = plt.imshow(lum_img_r) imgplot.set_cmap('spectral') plt.show() /Users/huangsizhe/LIB/CONDA/anaconda/lib/python3.6/site-packages/matplotlib/cbook.py:136: MatplotlibDeprecationWarning: The spectral and spectral_r colormap was deprecated in version 2.0. Use nipy_spectral and nipy_spectral_r instead. warnings.warn(message, mplDeprecation, stacklevel=1) 色标参考 它有助于了解颜色代表什么值。我们可以通过添加颜色条来做到这一点。 imgplot = plt.imshow(lum_img_r) plt.colorbar() plt.show() 检查特定数据范围 有时，您想要增强图像的对比度，或者在特定区域中扩大对比度，同时牺牲不会变化很大的颜色的细节，或者无关紧要。找到感兴趣区域的好工具是直方图。要创建我们的图像数据的直方图，我们使用hist（）函数。 plt.hist(lum_img_r.ravel(), bins=256,fc='k', ec='k') plt.show() 下图就显示出了各个色值的分布状态,看打出来25x为值的是大多数中的大多数 通常，图像的“有趣”部分在峰值附近，您可以通过剪切峰值上方和/或下方的区域获得额外的对比度。在我们的直方图中，看起来在高端没有太多有用的信息（图像中不是很多白色的东西）。让我们调整上限，以便我们有效地“放大”直方图的一部分。我们通过将clim参数传递给imshow来实现。你也可以通过调用图像绘图对象的set_clim（）方法来做到这一点，但是要确保你在使用IPython Notebook时在plot命令的同一个单元格中这样做 - 它不会改变以前单元格的绘图。 imgplot = plt.imshow(lum_img_r, clim=(0, 200)) plt.show() 阵列插值方案 插值根据不同的数学方案计算像素的“应该”的颜色或值。这种情况发生的一个常见的地方是当你调整图像的大小。像素的数量变化，但你想要相同的信息。由于像素是离散的，因此缺少空间。插值是如何填补这个空间。这就是为什么你的图像有时拉伸会出来看起来像素化。当原始图像和扩展图像之间的差异较大时，效果更加明显。比如windows显示像素如果过分低于你的屏幕像素,那么你拉伸到屏幕那么大,看起来就都是马赛克,就是这个效果. 而插值算法就是拉伸时如何模拟的去显示出缺失信息的技术 from PIL import Image img = Image.open('./source/cat.jpg') img.thumbnail((64, 64), Image.ANTIALIAS) # 将图片压缩到64x64像素 img.height,img.width#41是因为图片比例 (41, 64) imgplot = plt.imshow(img) plt.show() 内置的插值算法有 'nearest', 最近值,也就是马赛克块 'bilinear', 双线性插值 'bicubic',双三次插值 'spline16'/'spline36', 样条插值 'hanning'/'hamming'/'gaussian'/'kaiser'/'bessel'/'sinc' 窗插值算法 'hermite',埃尔米特插值 'quadric',二次曲面插值 'catrom',[Catmull-Rom插值算法]https://en.wikipedia.org/wiki/Centripetal_Catmull%E2%80%93Rom_spline 'mitchell' 'lanczos'Lanczos算法 imgplot = plt.imshow(img, interpolation=\"nearest\") plt.show() 使用双三次插值(bicubic)模糊处理 imgplot = plt.imshow(img, interpolation=\"bicubic\") plt.show() 图片修改分辨率 img模块还提供了一个缩略图的工具 matplotlib.image.thumbnail(infile, thumbfile, scale=0.1, interpolation='bilinear', preview=False) 它可以直接修改文件并保存为另一文件,只是类型限制在png,svg和pdf三种 mpimg.thumbnail(\"./source/cat.jpg\", \"./source/cat_min.png\", scale=0.15, interpolation='bicubic') Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 18:52:40 "},"matplotlib/save_img/save_img.html":{"url":"matplotlib/save_img/save_img.html","title":"图片保存","keywords":"","body":"保存图片 保存图片可以使用matplotlib.pyplot.savefig来实现 from matplotlib import pyplot as plt import numpy as np %matplotlib inline fig = plt.figure(figsize=(40,40)) x=np.linspace(-4,4,30) y=np.sin(x) plt.plot(x,y,'--*b') fig.savefig(\"./source/sin_ex.png\", dpi=15) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 18:52:40 "},"matplotlib/animation/animation.html":{"url":"matplotlib/animation/animation.html","title":"动画","keywords":"","body":"动画 动画说白了就是隔段时间刷新一下画面,matplotlib.animation提供了构建动画的工具主要是这几个方法: 通过函数构建 通过作品构建 通过继承matplotlib.animation.TimedAnimation类制作动画 动画需要后渲染后端,一般使用ffmpeg,安装方法可以看]这里 无论哪种方式构建的动画都可以通过.save方法保存为希望的格式,也可以用.to_html5_video方法输出一份html5可以读取的文件. from __future__ import print_function from imp import reload import matplotlib reload(matplotlib) matplotlib.use('nbagg') import matplotlib.backends.backend_nbagg reload(matplotlib.backends.backend_nbagg) import matplotlib.backends.backend_webagg_core reload(matplotlib.backends.backend_webagg_core) import numpy as np import matplotlib.pyplot as plt import matplotlib.animation as animation plt.interactive(False) 通过函数构建动画 matplotlib.animation.FuncAnimation(fig, func, frames=None, init_func=None, fargs=None, save_count=None, **kwargs) FuncAnimation类是最常用的构建函数. 他的构造函数有这样一些参数 fig 一个figure对象,图像都是基于这个对象相当于一个画板 func(frame)->tuple(axes.plot) 一个构建动画函数,参数是frames传入的每一帧,而返回的是一个由参数构建的plot对象构成的tuple frames 一个可迭代对象,可以是生成器,可以是一个序列,也可以是数字,数字相当于传入一个xrange(n) init_func(frame)->tuple(axes.plot) 初始化函数,第0帧时候调用它构建图形 如果blit = True，func和init_func必须返回一个可迭代的作品对象来重绘 kwargs包括repeat，repeat_delay和interval： interval每隔interval毫秒绘制一个新帧。 repeat控制动画是否应在帧序列完成时重复。 repeat_delay可选地在重复动画之前添加以毫秒为单位的延迟。 from IPython.display import HTML %matplotlib inline plt.style.use(\"animation_support\") 使用数字定义帧 fig, ax = plt.subplots() x = np.arange(0, 2*np.pi, 0.01) line, = ax.plot(x, np.sin(x)) def animate(i): line.set_ydata(np.sin(x + i/10.0)) # update the data return line, # Init only required for blitting to give a clean slate. def init(): line.set_ydata(np.ma.array(x, mask=True)) return line, ani = animation.FuncAnimation(fig, animate, 200, init_func=init, interval=25, blit=True) ani Your browser does not support the video tag. 使用生成器定义帧 # 使用生成器构建每一帧的传入数据 def data_gen(t=0): cnt = 0 while cnt = xmax: ax.set_xlim(xmin, 2*xmax) ax.figure.canvas.draw() line.set_data(xdata, ydata) return line, ani = animation.FuncAnimation(fig, run, data_gen, blit=False, interval=10, repeat=False, init_func=init) ani Your browser does not support the video tag. 通过作品组合构建动画 matplotlib.animation.ArtistAnimation(fig, artists, *args, **kwargs) 这种方式和上面类似,只是先画好每一幅图,之后按顺序和指定的帧率制作动画 fig2 = plt.figure() x = np.arange(-9, 10) y = np.arange(-9, 10).reshape(-1, 1) base = np.hypot(x, y) ims = [] for add in np.arange(15): ims.append((plt.pcolor(x, y, base + add, norm=plt.Normalize(0, 30)),)) im_ani = animation.ArtistAnimation(fig2, ims, interval=50, repeat_delay=3000, blit=True) im_ani Your browser does not support the video tag. 通过继承构建 matplotlib.animation.TimedAnimation是上面俩的基类,我们也可以直接继承它来构造动画,主要要重载的是 __init__()方法 _draw_frame方法,对应func new_frame_seq对应frames _init_draw对应init_func from matplotlib.lines import Line2D class SubplotAnimation(animation.TimedAnimation): def __init__(self): fig = plt.figure() ax1 = fig.add_subplot(1, 2, 1) ax2 = fig.add_subplot(2, 2, 2) ax3 = fig.add_subplot(2, 2, 4) self.t = np.linspace(0, 80, 400) self.x = np.cos(2 * np.pi * self.t / 10.) self.y = np.sin(2 * np.pi * self.t / 10.) self.z = 10 * self.t ax1.set_xlabel('x') ax1.set_ylabel('y') self.line1 = Line2D([], [], color='black') self.line1a = Line2D([], [], color='red', linewidth=2) self.line1e = Line2D( [], [], color='red', marker='o', markeredgecolor='r') ax1.add_line(self.line1) ax1.add_line(self.line1a) ax1.add_line(self.line1e) ax1.set_xlim(-1, 1) ax1.set_ylim(-2, 2) ax1.set_aspect('equal', 'datalim') ax2.set_xlabel('y') ax2.set_ylabel('z') self.line2 = Line2D([], [], color='black') self.line2a = Line2D([], [], color='red', linewidth=2) self.line2e = Line2D( [], [], color='red', marker='o', markeredgecolor='r') ax2.add_line(self.line2) ax2.add_line(self.line2a) ax2.add_line(self.line2e) ax2.set_xlim(-1, 1) ax2.set_ylim(0, 800) ax3.set_xlabel('x') ax3.set_ylabel('z') self.line3 = Line2D([], [], color='black') self.line3a = Line2D([], [], color='red', linewidth=2) self.line3e = Line2D( [], [], color='red', marker='o', markeredgecolor='r') ax3.add_line(self.line3) ax3.add_line(self.line3a) ax3.add_line(self.line3e) ax3.set_xlim(-1, 1) ax3.set_ylim(0, 800) animation.TimedAnimation.__init__(self, fig, interval=50, blit=True) def _draw_frame(self, framedata): i = framedata head = i - 1 head_len = 10 head_slice = (self.t > self.t[i] - 1.0) & (self.t ani = SubplotAnimation() ani Your browser does not support the video tag. 动画的输出 最简单的输出就是直接通过matplotlib输出,直接plt.show()即可,注意这种方式jupyter notebook并不支持.只能在脚本中使用 输出为html5可读的视屏 使用.to_html5_video()方法可以直接输出一段浏览器可以识别的带标签的html5字符串这种可以直接嵌入到网页前端 保存动画 动画保存是通过.save(filename, writer=None, fps=None, dpi=None, codec=None, bitrate=None, extra_args=None, metadata=None, extra_anim=None, savefig_kwargs=None)方法 writer可以自己定义转码工具,默认为ffmpeg fps为帧率 dpi控制动画每帧中的每英寸点数. codec指定保存的格式,默认使用filename的后缀作为格式 bitrate指定压缩影片每秒使用的位数，以千位/秒为单位。更高的数字意味着更高质量的电影，但是以增加的文件大小为代价。如果未指定值，则默认值为rcparam animation.bitrate给出的值。 metadata元数据包括在输出文件中的元数据的键和值的字典。可能有用的一些键包括：标题，艺术家，流派，主题，版权，srcform，注释。 动画生成和转码工具的设置 matplotlib本身就是个作图的工具,本身无法制作动画,但他可以通过其他工具提供了几个参数用来转码和设置,我们可以定义一个主题来实现需要的时候加载 animation.ffmpeg_path : /bin/ffmpeg animation.convert_path: /imagemagick/6.9.7-0/bin/convert animation.html: html5 通过这样的设置可以使用ffmpeg工具转码为常见的格式如MP4,也可以通过指定writer参数来使用imagemagick构建gif动画图片. 第三个参数是为了让jupyter notebook可以直接显示动画,如果不设置也可以使用 from IPython.display import HTML 然后HTML(ani.to_html5())来输出动画 Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 18:52:40 "},"matplotlib/widgets.html":{"url":"matplotlib/widgets.html","title":"matplotlib控件与交互","keywords":"","body":"控件 很神奇的,matplot还提供了简单的可供交互的控件包括 buttons 按钮 check_buttons 选择按钮 radio_buttons 多选按钮 menu 目录 from __future__ import print_function from imp import reload import matplotlib reload(matplotlib) matplotlib.use('nbagg') import matplotlib.backends.backend_nbagg reload(matplotlib.backends.backend_nbagg) import matplotlib.backends.backend_webagg_core reload(matplotlib.backends.backend_webagg_core) import numpy as np import matplotlib.pyplot as plt plt.interactive(False) 按钮bottom 添加按钮可以使用plt.subplots_adjust(bottom=xx)为其在底部留下足够空间 用plt.axes([0.7, 0.05, 0.1, 0.075])为按钮划定大小和位置 添加按钮可以使用Button(ax, label, image=None, color='0.85', hovercolor='0.95') 而为其添加回调函数,则可以用为其绑定on_clicked方法 bnext = Button(axnext, 'Next') bnext.on_clicked(callback.next) 这种形式 from matplotlib.widgets import Button freqs = np.arange(2, 20, 3) fig, ax = plt.subplots() plt.subplots_adjust(bottom=0.2) t = np.arange(0.0, 1.0, 0.001) s = np.sin(2*np.pi*freqs[0]*t) l, = plt.plot(t, s, lw=2) class Index(object): ind = 0 def next(self, event): self.ind += 1 i = self.ind % len(freqs) ydata = np.sin(2*np.pi*freqs[i]*t) l.set_ydata(ydata) plt.draw() def prev(self, event): self.ind -= 1 i = self.ind % len(freqs) ydata = np.sin(2*np.pi*freqs[i]*t) l.set_ydata(ydata) plt.draw() callback = Index() axprev = plt.axes([0.7, 0.05, 0.1, 0.075]) axnext = plt.axes([0.81, 0.05, 0.1, 0.075]) bnext = Button(axnext, 'Next') bnext.on_clicked(callback.next) bprev = Button(axprev, 'Previous') bprev.on_clicked(callback.prev) plt.show() 选择按钮CheckButtons from matplotlib.widgets import CheckButtons t = np.arange(0.0, 2.0, 0.01) s0 = np.sin(2*np.pi*t) s1 = np.sin(4*np.pi*t) s2 = np.sin(6*np.pi*t) fig, ax = plt.subplots() l0, = ax.plot(t, s0, visible=False, lw=2) l1, = ax.plot(t, s1, lw=2) l2, = ax.plot(t, s2, lw=2) plt.subplots_adjust(left=0.2) rax = plt.axes([0.05, 0.4, 0.1, 0.15]) check = CheckButtons(rax, ('2 Hz', '4 Hz', '6 Hz'), (False, True, True)) def func(label): if label == '2 Hz': l0.set_visible(not l0.get_visible()) elif label == '4 Hz': l1.set_visible(not l1.get_visible()) elif label == '6 Hz': l2.set_visible(not l2.get_visible()) plt.draw() check.on_clicked(func) plt.show() 单选框RadioButtons from matplotlib.widgets import RadioButtons t = np.arange(0.0, 2.0, 0.01) s0 = np.sin(2*np.pi*t) s1 = np.sin(4*np.pi*t) s2 = np.sin(8*np.pi*t) fig, ax = plt.subplots() l, = ax.plot(t, s0, lw=2, color='red') plt.subplots_adjust(left=0.3) axcolor = 'lightgoldenrodyellow' rax = plt.axes([0.05, 0.7, 0.15, 0.15], axisbg=axcolor) radio = RadioButtons(rax, ('2 Hz', '4 Hz', '8 Hz')) def hzfunc(label): hzdict = {'2 Hz': s0, '4 Hz': s1, '8 Hz': s2} ydata = hzdict[label] l.set_ydata(ydata) plt.draw() radio.on_clicked(hzfunc) rax = plt.axes([0.05, 0.4, 0.15, 0.15], axisbg=axcolor) radio2 = RadioButtons(rax, ('red', 'blue', 'green')) def colorfunc(label): l.set_color(label) plt.draw() radio2.on_clicked(colorfunc) rax = plt.axes([0.05, 0.1, 0.15, 0.15], axisbg=axcolor) radio3 = RadioButtons(rax, ('-', '--', '-.', 'steps', ':')) def stylefunc(label): l.set_linestyle(label) plt.draw() radio3.on_clicked(stylefunc) plt.show() /Users/huangsizhe/LIB/CONDA/anaconda/lib/python3.6/site-packages/matplotlib/cbook.py:136: MatplotlibDeprecationWarning: The axisbg attribute was deprecated in version 2.0. Use facecolor instead. warnings.warn(message, mplDeprecation, stacklevel=1) 滑块Slider from matplotlib.widgets import Slider, Button, RadioButtons fig, ax = plt.subplots() plt.subplots_adjust(left=0.25, bottom=0.25) t = np.arange(0.0, 1.0, 0.001) a0 = 5 f0 = 3 s = a0*np.sin(2*np.pi*f0*t) l, = plt.plot(t, s, lw=2, color='red') plt.axis([0, 1, -10, 10]) axcolor = 'lightgoldenrodyellow' axfreq = plt.axes([0.25, 0.1, 0.65, 0.03], axisbg=axcolor) axamp = plt.axes([0.25, 0.15, 0.65, 0.03], axisbg=axcolor) sfreq = Slider(axfreq, 'Freq', 0.1, 30.0, valinit=f0) samp = Slider(axamp, 'Amp', 0.1, 10.0, valinit=a0) def update(val): amp = samp.val freq = sfreq.val l.set_ydata(amp*np.sin(2*np.pi*freq*t)) fig.canvas.draw_idle() sfreq.on_changed(update) samp.on_changed(update) resetax = plt.axes([0.8, 0.025, 0.1, 0.04]) button = Button(resetax, 'Reset', color=axcolor, hovercolor='0.975') def reset(event): sfreq.reset() samp.reset() button.on_clicked(reset) rax = plt.axes([0.025, 0.5, 0.15, 0.15], axisbg=axcolor) radio = RadioButtons(rax, ('red', 'blue', 'green'), active=0) def colorfunc(label): l.set_color(label) fig.canvas.draw_idle() radio.on_clicked(colorfunc) plt.show() /Users/huangsizhe/LIB/CONDA/anaconda/lib/python3.6/site-packages/matplotlib/cbook.py:136: MatplotlibDeprecationWarning: The axisbg attribute was deprecated in version 2.0. Use facecolor instead. warnings.warn(message, mplDeprecation, stacklevel=1) 光标Cursor from matplotlib.widgets import Cursor fig = plt.figure(figsize=(8, 6)) ax = fig.add_subplot(111, axisbg='#FFFFCC') x, y = 4*(np.random.rand(2, 100) - .5) ax.plot(x, y, 'o') ax.set_xlim(-2, 2) ax.set_ylim(-2, 2) # set useblit = True on gtkagg for enhanced performance cursor = Cursor(ax, useblit=True, color='red', linewidth=2) plt.show() /Users/huangsizhe/LIB/CONDA/anaconda/lib/python3.6/site-packages/matplotlib/cbook.py:136: MatplotlibDeprecationWarning: The axisbg attribute was deprecated in version 2.0. Use facecolor instead. warnings.warn(message, mplDeprecation, stacklevel=1) 多路光标 from matplotlib.widgets import MultiCursor t = np.arange(0.0, 2.0, 0.01) s1 = np.sin(2*np.pi*t) s2 = np.sin(4*np.pi*t) fig = plt.figure() ax1 = fig.add_subplot(211) ax1.plot(t, s1) ax2 = fig.add_subplot(212, sharex=ax1) ax2.plot(t, s2) multi = MultiCursor(fig.canvas, (ax1, ax2), color='r', lw=1) plt.show() 矩形框 from matplotlib.widgets import RectangleSelector def line_select_callback(eclick, erelease): 'eclick and erelease are the press and release events' x1, y1 = eclick.xdata, eclick.ydata x2, y2 = erelease.xdata, erelease.ydata print(\"(%3.2f, %3.2f) --> (%3.2f, %3.2f)\" % (x1, y1, x2, y2)) print(\" The button you used were: %s %s\" % (eclick.button, erelease.button)) def toggle_selector(event): print(' Key pressed.') if event.key in ['Q', 'q'] and toggle_selector.RS.active: print(' RectangleSelector deactivated.') toggle_selector.RS.set_active(False) if event.key in ['A', 'a'] and not toggle_selector.RS.active: print(' RectangleSelector activated.') toggle_selector.RS.set_active(True) fig, current_ax = plt.subplots() # make a new plotingrange N = 100000 # If N is large one can see x = np.linspace(0.0, 10.0, N) # improvement by use blitting! plt.plot(x, +np.sin(.2*np.pi*x), lw=3.5, c='b', alpha=.7) # plot something plt.plot(x, +np.cos(.2*np.pi*x), lw=3.5, c='r', alpha=.5) plt.plot(x, -np.sin(.2*np.pi*x), lw=3.5, c='g', alpha=.3) print(\"\\n click --> release\") # drawtype is 'box' or 'line' or 'none' toggle_selector.RS = RectangleSelector(current_ax, line_select_callback, drawtype='box', useblit=True, button=[1, 3], # don't use middle button minspanx=5, minspany=5, spancoords='pixels', interactive=True) plt.connect('key_press_event', toggle_selector) plt.show() click --> release 选定区域SpanSelector from matplotlib.widgets import SpanSelector fig = plt.figure(figsize=(8, 6)) ax = fig.add_subplot(211, axisbg='#FFFFCC') x = np.arange(0.0, 5.0, 0.01) y = np.sin(2*np.pi*x) + 0.5*np.random.randn(len(x)) ax.plot(x, y, '-') ax.set_ylim(-2, 2) ax.set_title('Press left mouse button and drag to test') ax2 = fig.add_subplot(212, axisbg='#FFFFCC') line2, = ax2.plot(x, y, '-') def onselect(xmin, xmax): indmin, indmax = np.searchsorted(x, (xmin, xmax)) indmax = min(len(x) - 1, indmax) thisx = x[indmin:indmax] thisy = y[indmin:indmax] line2.set_data(thisx, thisy) ax2.set_xlim(thisx[0], thisx[-1]) ax2.set_ylim(thisy.min(), thisy.max()) fig.canvas.draw() # set useblit True on gtkagg for enhanced performance span = SpanSelector(ax, onselect, 'horizontal', useblit=True, rectprops=dict(alpha=0.5, facecolor='red')) plt.show() /Users/huangsizhe/LIB/CONDA/anaconda/lib/python3.6/site-packages/matplotlib/cbook.py:136: MatplotlibDeprecationWarning: The axisbg attribute was deprecated in version 2.0. Use facecolor instead. warnings.warn(message, mplDeprecation, stacklevel=1) Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 18:52:40 "},"matplotlib/finance/finance.html":{"url":"matplotlib/finance/finance.html","title":"金融信息爬取","keywords":"","body":"finance模块 matplotlib.finance是matplotlib包中唯一和图形图像没啥关系的一个模块 它可以用于收集，分析和绘制财务数据的功能集合 import matplotlib.pyplot as plt from matplotlib.finance import quotes_historical_yahoo_ochl ,fetch_historical_yahoo,quotes_historical_yahoo_ohlc from matplotlib.dates import YearLocator, MonthLocator, DateFormatter ,WeekdayLocator,MONDAY,DayLocator from matplotlib.finance import parse_yahoo_historical_ochl,parse_yahoo_historical_ohlc import datetime import numpy as np /Users/huangsizhe/LIB/CONDA/anaconda/lib/python3.6/site-packages/matplotlib/cbook.py:136: MatplotlibDeprecationWarning: The finance module has been deprecated in mpl 2.0 and will be removed in mpl 2.2. Please use the module mpl_finance instead. warnings.warn(message, mplDeprecation, stacklevel=1) %matplotlib inline plt.style.use('chinese_support') 数据获取: matplotlib.finance.fetch_historical_yahoo(ticker, date1, date2, cachename=None, dividends=False) 在date1和date2之间获取代码的历史数据。date1和date2是日期或datetime实例，或（年，月，日）序列。 其中dividends = True则返回股息而不是价格数据。使用此选项设置，解析函数将不工作.它返回一个打开的file对象,以标普500为例 with fetch_historical_yahoo('^GSPC', (2000, 1, 1), (2001, 12, 31)) as fh: print(fh.readlines()[:5]) ['Date,Open,High,Low,Close,Volume,Adj Close\\n', '2001-12-31,1161.02002,1161.160034,1148.040039,1148.079956,943600000,1148.079956\\n', '2001-12-28,1157.130005,1164.640015,1157.130005,1161.02002,917400000,1161.02002\\n', '2001-12-27,1149.369995,1157.130005,1149.369995,1157.130005,876300000,1157.130005\\n', '2001-12-26,1144.650024,1159.180054,1144.650024,1149.369995,791100000,1149.369995\\n'] 因为获取的是文件类型,finance模块还提供了解析工具 matplotlib.finance.parse_yahoo_historical_ohlc(fh, adjusted=True, asobject=False) 输出对应(时间戳,开市,最高,最低,闭市,成交量) matplotlib.finance.parse_yahoo_historical_ochl(fh, adjusted=True, asobject=False) 输出对应(时间戳,开市,闭市,最高,最低,成交量) with fetch_historical_yahoo('^GSPC', (2015, 12, 20), (2016, 12, 20)) as fh: print(parse_yahoo_historical_ohlc(fh)[:5]) [(735953.0, 2010.2700199999999, 2022.900024, 2005.9300539999999, 2021.150024, 3760280000.0), (735954.0, 2023.150024, 2042.73999, 2020.48999, 2038.969971, 3520860000.0), (735955.0, 2042.1999510000001, 2064.7299800000001, 2042.1999510000001, 2064.290039, 3484090000.0), (735956.0, 2063.5200199999999, 2067.360107, 2058.7299800000001, 2060.98999, 1411860000.0), (735960.0, 2057.7700199999999, 2057.7700199999999, 2044.1999510000001, 2056.5, 2492510000.0)] with fetch_historical_yahoo('^GSPC', (2015, 12, 20), (2016, 12, 20)) as fh: print(parse_yahoo_historical_ochl(fh)[:5]) [(735953.0, 2010.2700199999999, 2021.150024, 2022.900024, 2005.9300539999999, 3760280000.0), (735954.0, 2023.150024, 2038.969971, 2042.73999, 2020.48999, 3520860000.0), (735955.0, 2042.1999510000001, 2064.290039, 2064.7299800000001, 2042.1999510000001, 3484090000.0), (735956.0, 2063.5200199999999, 2060.98999, 2067.360107, 2058.7299800000001, 1411860000.0), (735960.0, 2057.7700199999999, 2056.5, 2057.7700199999999, 2044.1999510000001, 2492510000.0)] 而下两个则是直接返回解析好的结果 matplotlib.finance.quotes_historical_yahoo_ochl(ticker, date1, date2, asobject=False, adjusted=True, cachename=None) matplotlib.finance.quotes_historical_yahoo_ohlc(ticker, date1, date2, asobject=False, adjusted=True, cachename=None) quotes_historical_yahoo_ochl('^GSPC', (2015, 12, 20), (2016, 12, 20))[:2] [(735953.0, 2010.2700199999999, 2021.150024, 2022.900024, 2005.9300539999999, 3760280000.0), (735954.0, 2023.150024, 2038.969971, 2042.73999, 2020.48999, 3520860000.0)] quotes_historical_yahoo_ohlc('^GSPC', (2015, 12, 20), (2016, 12, 20))[:2] [(735953.0, 2010.2700199999999, 2022.900024, 2005.9300539999999, 2021.150024, 3760280000.0), (735954.0, 2023.150024, 2042.73999, 2020.48999, 2038.969971, 3520860000.0)] 绘制k线图 以价格为参数的方法 matplotlib.finance.candlestick2_ochl(ax, opens, closes, highs, lows, width=4, colorup='k', colordown='r', alpha=0.75) 输入对应(时间戳,开市,闭市,最高,最低,成交量) matplotlib.finance.candlestick2_ohlc(ax, opens, highs, lows, closes, width=4, colorup='k', colordown='r', alpha=0.75) 输入对应(时间戳,开市,最高,最低,闭市,成交量) 以解析出来的原始序列为参数 matplotlib.finance.candlestick_ochl(ax, quotes, width=0.2, colorup='k', colordown='r', alpha=1.0) 输入对应(时间戳,开市,闭市,最高,最低,成交量) matplotlib.finance.candlestick_ohlc(ax, quotes, width=0.2, colorup='k', colordown='r', alpha=1.0) 输入对应(时间戳,开市,最高,最低,闭市,成交量) from matplotlib.finance import candlestick2_ochl,candlestick2_ohlc,candlestick_ochl,candlestick_ohlc #设置x轴坐标刻度 mondays = WeekdayLocator(MONDAY) # 主要刻度 alldays = DayLocator() # 次要刻度 mondayFormatter = DateFormatter('%m-%d-%Y') # 如：2-29-2015 dayFormatter = DateFormatter('%d') # 数据处理 quotes_ochl = quotes_historical_yahoo_ochl('^GSPC', (2015, 12, 20), (2016, 6, 20)) ochl = np.array(quotes_ochl).T[1:-1] quotes_ohlc = quotes_historical_yahoo_ohlc('^GSPC', (2015, 12, 20), (2016, 6, 20)) ohlc = np.array(quotes_ohlc).T[1:-1] # 设置x坐标轴 fig, ax = plt.subplots() fig.subplots_adjust(bottom=0.2) ax.xaxis.set_major_locator(mondays) ax.xaxis.set_minor_locator(alldays) ax.xaxis.set_major_formatter(mondayFormatter) # 绘制图形 candlestick_ohlc(ax, quotes_ohlc, width=0.6, colorup='r', colordown='g') ax.xaxis_date() ax.autoscale_view() plt.setp(plt.gca().get_xticklabels(), rotation=45, horizontalalignment='right') ax.grid(True) plt.title(u'标普500') plt.show() # 设置x坐标轴 fig, ax = plt.subplots() fig.subplots_adjust(bottom=0.2) ax.xaxis.set_major_locator(mondays) ax.xaxis.set_minor_locator(alldays) ax.xaxis.set_major_formatter(mondayFormatter) # 绘制图形 o,h,l,c = ohlc candlestick2_ohlc(ax, o,h,l,c , width=0.6, colorup='r', colordown='g') ax.xaxis_date() ax.autoscale_view() plt.setp(plt.gca().get_xticklabels(), rotation=45, horizontalalignment='right') ax.grid(True) plt.title(u'标普500') plt.show() 绘制天的数据 这种图的上下柱是交易的最高最低值,而侧柱则表示开盘价和收盘价 以价格为参数的方法 matplotlib.finance.plot_day_summary2_ochl(ax, opens, closes, highs, lows, ticksize=4, colorup='k', colordown='r') matplotlib.finance.plot_day_summary2_ohlc(ax, opens, highs, lows, closes, ticksize=4, colorup='k', colordown='r') 以解析出来的原始序列为参数 matplotlib.finance.plot_day_summary_oclh(ax, quotes, ticksize=3, colorup='k', colordown='r') matplotlib.finance.plot_day_summary_ohlc(ax, quotes, ticksize=3, colorup='k', colordown='r') from matplotlib.finance import plot_day_summary_oclh # 设置x坐标轴 fig, ax = plt.subplots() fig.subplots_adjust(bottom=0.2) ax.xaxis.set_major_locator(mondays) ax.xaxis.set_minor_locator(alldays) ax.xaxis.set_major_formatter(mondayFormatter) plot_day_summary_oclh(ax,quotes_ochl[:7], ticksize= 10,colorup='r', colordown='g') ax.xaxis_date() ax.autoscale_view() #plt.setp(plt.gca().get_xticklabels(), rotation=45, horizontalalignment='right') ax.grid(True) plt.title(u'标普500') plt.show() 成交量相关的图形 matplotlib.finance.index_bar(ax, vals, facecolor='b', edgecolor='l', width=4, alpha=1.0) matplotlib.finance.volume_overlay(ax, opens, closes, volumes, colorup='k', colordown='r', width=4, alpha=1.0) matplotlib.finance.volume_overlay2(ax, closes, volumes, colorup='k', colordown='r', width=4, alpha=1.0) matplotlib.finance.volume_overlay3(ax, quotes, colorup='k', colordown='r', width=4, alpha=1.0) from matplotlib.finance import index_bar,volume_overlay3 volume = np.array(quotes_ochl).T[-1]/10000000000 #fig = plt.figure(figsize=(12,16)) fig ,subplots=plt.subplots(3,1) plt.title(u'标普500') fig.set_size_inches((12,16)) for i,ax in enumerate(subplots): ax.xaxis.set_major_locator(mondays) ax.xaxis.set_minor_locator(alldays) ax.xaxis.set_major_formatter(mondayFormatter) if i == 0: ax.set_ylabel(u'价格') candlestick_ohlc(ax, quotes_ohlc, width=0.6, colorup='r', colordown='g') elif i ==1: ax.set_ylabel(u'成交量') index_bar(ax,volume,facecolor='b', edgecolor='r') else: ax.set_ylabel(u'成交量面积') ax.set_ylim((0, 1e10)) v = volume_overlay3(ax, quotes_ohlc) ax.xaxis_date() ax.autoscale_view() plt.setp(plt.gca().get_xticklabels(), rotation=45, horizontalalignment='right') ax.grid(True) plt.show() Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 18:52:40 "},"matplotlib/结语.html":{"url":"matplotlib/结语.html","title":"结语","keywords":"","body":"结语 数据可视化与web 数据可视化是数据工程的最后一步,也是最可有可无的一步,因此它也是数据工程师鄙视链的底端. 但却是一般人(主管,老板)最能直观看到也是最容易觉得有价值的步骤.python的数据可视化模块很多,但说到最通用最经典的还是matplotlib. matplotlib的最大优势是可以做出出版级别的图片,因此科技工作者是它的主力用户, 当然了最新的版本中它也已经开始注重与web技术的结合.但如果真的要让可视化部分用于网络甚至带有交互的能力, 甚至要应用化,那么可能其他基于javascript的前端数据可视化工具如d3.js,echarts等更加值得考虑. Copyright © hsz 2017 all right reserved，powered by Gitbook该文件修订时间： 2017-06-18 20:21:14 "}}